#!/usr/bin/env python
"""
å…ƒæ•°æ®æ£€ç´¢åŠŸèƒ½æ¼”ç¤º

å±•ç¤ºå¦‚ä½•ä½¿ç”¨embeddingæ¨¡å—çš„å„ç§å…ƒæ•°æ®æ£€ç´¢åŠŸèƒ½ï¼š
1. æ ¹æ®IDæ£€ç´¢
2. çº¯å…ƒæ•°æ®æ£€ç´¢
3. å…ƒæ•°æ®åŒ…å«æ£€ç´¢
4. å…ƒæ•°æ®èŒƒå›´æ£€ç´¢
5. æ··åˆæ£€ç´¢ï¼ˆå‘é‡+å…ƒæ•°æ®ï¼‰
6. å…ƒæ•°æ®ç»Ÿè®¡
"""

import os
import sys
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.insert(0, project_root)

from coderepoindex.embeddings import (
    create_simple_rag_system,
    search_by_metadata,
    search_by_id,
    search_by_ids,
    search_metadata_contains,
    search_metadata_range,
    hybrid_search,
    get_metadata_info,
    setup_logging
)


def create_sample_documents() -> List[Dict[str, Any]]:
    """åˆ›å»ºç¤ºä¾‹æ–‡æ¡£"""
    return [
        {
            "text": "Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œå…·æœ‰ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½ã€‚",
            "metadata": {
                "doc_id": "doc_001",
                "category": "programming",
                "language": "python",
                "difficulty": "beginner",
                "words": 20,
                "date": "2024-01-15",
                "tags": ["syntax", "features"],
                "author": "å¼ ä¸‰"
            }
        },
        {
            "text": "JavaScriptæ˜¯ä¸€ç§åŠ¨æ€ç¼–ç¨‹è¯­è¨€ï¼Œä¸»è¦ç”¨äºwebå¼€å‘ã€‚",
            "metadata": {
                "doc_id": "doc_002", 
                "category": "programming",
                "language": "javascript",
                "difficulty": "intermediate",
                "words": 18,
                "date": "2024-02-01",
                "tags": ["web", "dynamic"],
                "author": "æå››"
            }
        },
        {
            "text": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œæ¶‰åŠç®—æ³•å’Œç»Ÿè®¡æ¨¡å‹ã€‚",
            "metadata": {
                "doc_id": "doc_003",
                "category": "ai",
                "language": "general",
                "difficulty": "advanced",
                "words": 22,
                "date": "2024-01-30",
                "tags": ["algorithm", "statistics"],
                "author": "ç‹äº”"
            }
        },
        {
            "text": "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œæ¨¡å¼è¯†åˆ«ã€‚",
            "metadata": {
                "doc_id": "doc_004",
                "category": "ai",
                "language": "general", 
                "difficulty": "advanced",
                "words": 25,
                "date": "2024-02-10",
                "tags": ["neural_network", "pattern_recognition"],
                "author": "èµµå…­"
            }
        },
        {
            "text": "Webå¼€å‘æ¶‰åŠå‰ç«¯å’Œåç«¯æŠ€æœ¯ï¼Œéœ€è¦æŒæ¡å¤šç§ç¼–ç¨‹è¯­è¨€å’Œæ¡†æ¶ã€‚",
            "metadata": {
                "doc_id": "doc_005",
                "category": "programming",
                "language": "general",
                "difficulty": "intermediate",
                "words": 24,
                "date": "2024-01-20",
                "tags": ["frontend", "backend"],
                "author": "é’±ä¸ƒ"
            }
        }
    ]


def demo_basic_metadata_search(retriever):
    """æ¼”ç¤ºåŸºç¡€å…ƒæ•°æ®æ£€ç´¢"""
    print("\n" + "="*50)
    print("1. åŸºç¡€å…ƒæ•°æ®æ£€ç´¢æ¼”ç¤º")
    print("="*50)
    
    # 1. æ ¹æ®å•ä¸ªæ¡ä»¶æ£€ç´¢
    print("\nğŸ” æ£€ç´¢æ‰€æœ‰ç¼–ç¨‹ç±»æ–‡æ¡£:")
    nodes = search_by_metadata(retriever, {"category": "programming"})
    for node in nodes:
        print(f"  - {node.metadata['doc_id']}: {node.text[:30]}...")
    
    # 2. æ ¹æ®å¤šä¸ªæ¡ä»¶æ£€ç´¢
    print("\nğŸ” æ£€ç´¢ä¸­çº§éš¾åº¦çš„ç¼–ç¨‹æ–‡æ¡£:")
    nodes = search_by_metadata(retriever, {
        "category": "programming", 
        "difficulty": "intermediate"
    })
    for node in nodes:
        print(f"  - {node.metadata['doc_id']}: {node.text[:30]}...")
    
    # 3. æ ¹æ®ä½œè€…æ£€ç´¢
    print("\nğŸ” æ£€ç´¢å¼ ä¸‰çš„æ–‡æ¡£:")
    nodes = search_by_metadata(retriever, {"author": "å¼ ä¸‰"})
    for node in nodes:
        print(f"  - {node.metadata['doc_id']}: {node.text[:30]}...")


def demo_id_search(retriever):
    """æ¼”ç¤ºIDæ£€ç´¢"""
    print("\n" + "="*50)
    print("2. IDæ£€ç´¢æ¼”ç¤º")
    print("="*50)
    
    # è·å–æ‰€æœ‰èŠ‚ç‚¹IDç”¨äºæ¼”ç¤º
    all_stats = get_metadata_info(retriever)
    print(f"\nğŸ“Š å½“å‰ç´¢å¼•ä¸­å…±æœ‰ {sum(stats['count'] for stats in all_stats.values())} ä¸ªèŠ‚ç‚¹")
    
    # 1. æ ¹æ®å•ä¸ªæ–‡æ¡£IDæ£€ç´¢
    print("\nğŸ” æ£€ç´¢æ–‡æ¡£ doc_002 çš„æ‰€æœ‰èŠ‚ç‚¹:")
    nodes = retriever.retrieve_by_doc_id("doc_002")
    for node in nodes:
        print(f"  - èŠ‚ç‚¹ID: {node.node_id}")
        print(f"    æ–‡æœ¬: {node.text[:50]}...")
    
    # 2. æ ¹æ®èŠ‚ç‚¹IDæ£€ç´¢ï¼ˆå‡è®¾æˆ‘ä»¬çŸ¥é“ä¸€ä¸ªèŠ‚ç‚¹IDï¼‰
    if nodes:
        node_id = nodes[0].node_id
        print(f"\nğŸ” æ ¹æ®èŠ‚ç‚¹IDæ£€ç´¢: {node_id}")
        node = search_by_id(retriever, node_id)
        if node:
            print(f"  æ‰¾åˆ°èŠ‚ç‚¹: {node.text[:50]}...")
        else:
            print("  èŠ‚ç‚¹æœªæ‰¾åˆ°")
    
    # 3. æ‰¹é‡IDæ£€ç´¢
    if len(nodes) > 1:
        node_ids = [node.node_id for node in nodes[:2]]
        print(f"\nğŸ” æ‰¹é‡æ£€ç´¢èŠ‚ç‚¹: {node_ids}")
        batch_nodes = search_by_ids(retriever, node_ids)
        for node in batch_nodes:
            print(f"  - {node.node_id}: {node.text[:30]}...")


def demo_contains_search(retriever):
    """æ¼”ç¤ºåŒ…å«æ£€ç´¢"""
    print("\n" + "="*50)
    print("3. å…ƒæ•°æ®åŒ…å«æ£€ç´¢æ¼”ç¤º")
    print("="*50)
    
    # 1. æœç´¢æ ‡ç­¾åŒ…å«ç‰¹å®šå€¼çš„æ–‡æ¡£
    print("\nğŸ” æœç´¢æ ‡ç­¾åŒ…å«'web'çš„æ–‡æ¡£:")
    nodes = search_metadata_contains(retriever, "tags", "web")
    for node in nodes:
        print(f"  - {node.metadata['doc_id']}: {node.metadata['tags']}")
    
    # 2. æœç´¢ä½œè€…åç§°åŒ…å«ç‰¹å®šå­—ç¬¦çš„æ–‡æ¡£
    print("\nğŸ” æœç´¢ä½œè€…åç§°åŒ…å«'ä¸‰'çš„æ–‡æ¡£:")
    nodes = search_metadata_contains(retriever, "author", "ä¸‰")
    for node in nodes:
        print(f"  - {node.metadata['doc_id']}: ä½œè€… {node.metadata['author']}")
    
    # 3. æœç´¢åˆ†ç±»åŒ…å«ç‰¹å®šè¯çš„æ–‡æ¡£
    print("\nğŸ” æœç´¢åˆ†ç±»åŒ…å«'ai'çš„æ–‡æ¡£:")
    nodes = search_metadata_contains(retriever, "category", "ai")
    for node in nodes:
        print(f"  - {node.metadata['doc_id']}: {node.metadata['category']}")


def demo_range_search(retriever):
    """æ¼”ç¤ºèŒƒå›´æ£€ç´¢"""
    print("\n" + "="*50)
    print("4. å…ƒæ•°æ®èŒƒå›´æ£€ç´¢æ¼”ç¤º")
    print("="*50)
    
    # 1. æŒ‰å­—æ•°èŒƒå›´æ£€ç´¢
    print("\nğŸ” æ£€ç´¢å­—æ•°åœ¨20-25ä¹‹é—´çš„æ–‡æ¡£:")
    nodes = search_metadata_range(retriever, "words", min_value=20, max_value=25)
    for node in nodes:
        print(f"  - {node.metadata['doc_id']}: {node.metadata['words']}å­—")
    
    # 2. æŒ‰æ—¥æœŸèŒƒå›´æ£€ç´¢
    print("\nğŸ” æ£€ç´¢2024å¹´2æœˆçš„æ–‡æ¡£:")
    nodes = search_metadata_range(retriever, "date", min_value="2024-02-01", max_value="2024-02-28")
    for node in nodes:
        print(f"  - {node.metadata['doc_id']}: {node.metadata['date']}")
    
    # 3. åªè®¾ç½®æœ€å°å€¼
    print("\nğŸ” æ£€ç´¢å­—æ•°è¶…è¿‡20çš„æ–‡æ¡£:")
    nodes = search_metadata_range(retriever, "words", min_value=20)
    for node in nodes:
        print(f"  - {node.metadata['doc_id']}: {node.metadata['words']}å­—")


def demo_hybrid_search(retriever):
    """æ¼”ç¤ºæ··åˆæ£€ç´¢"""
    print("\n" + "="*50)
    print("5. æ··åˆæ£€ç´¢æ¼”ç¤ºï¼ˆå‘é‡+å…ƒæ•°æ®ï¼‰")
    print("="*50)
    
    # 1. è¯­ä¹‰æœç´¢ + åˆ†ç±»è¿‡æ»¤
    print("\nğŸ” åœ¨ç¼–ç¨‹ç±»æ–‡æ¡£ä¸­æœç´¢'è¯­è¨€':")
    try:
        results = hybrid_search(
            retriever, 
            query="è¯­è¨€",
            metadata_filter={"category": "programming"},
            top_k=3,
            metadata_weight=0.3,
            vector_weight=0.7
        )
        for result in results:
            print(f"  - {result['node_id']}: æ··åˆåˆ†æ•° {result.get('hybrid_score', 0):.3f}")
            print(f"    å‘é‡åˆ†æ•°: {result.get('vector_score', 0):.3f}, å…ƒæ•°æ®åˆ†æ•°: {result.get('metadata_score', 0):.3f}")
            print(f"    æ–‡æœ¬: {result['text'][:50]}...")
    except Exception as e:
        print(f"  âš ï¸  æ··åˆæ£€ç´¢éœ€è¦æœ‰æ•ˆçš„åµŒå…¥æä¾›å•†: {e}")
    
    # 2. è¯­ä¹‰æœç´¢ + éš¾åº¦è¿‡æ»¤
    print("\nğŸ” åœ¨é«˜çº§éš¾åº¦æ–‡æ¡£ä¸­æœç´¢'å­¦ä¹ ':")
    try:
        results = hybrid_search(
            retriever,
            query="å­¦ä¹ ",
            metadata_filter={"difficulty": "advanced"},
            top_k=3
        )
        for result in results:
            print(f"  - {result['node_id']}: æ··åˆåˆ†æ•° {result.get('hybrid_score', 0):.3f}")
            print(f"    æ–‡æœ¬: {result['text'][:50]}...")
    except Exception as e:
        print(f"  âš ï¸  æ··åˆæ£€ç´¢éœ€è¦æœ‰æ•ˆçš„åµŒå…¥æä¾›å•†: {e}")


def demo_metadata_statistics(retriever):
    """æ¼”ç¤ºå…ƒæ•°æ®ç»Ÿè®¡"""
    print("\n" + "="*50)
    print("6. å…ƒæ•°æ®ç»Ÿè®¡ä¿¡æ¯æ¼”ç¤º")
    print("="*50)
    
    # 1. è·å–æ‰€æœ‰å…ƒæ•°æ®ç»Ÿè®¡
    print("\nğŸ“Š æ‰€æœ‰å…ƒæ•°æ®ç»Ÿè®¡:")
    stats = get_metadata_info(retriever)
    for key, stat in stats.items():
        print(f"  {key}:")
        print(f"    - æ•°é‡: {stat['count']}")
        print(f"    - å”¯ä¸€å€¼: {stat['unique_values']}")
        print(f"    - è¦†ç›–ç‡: {stat['coverage']:.2%}")
        if 'min' in stat:
            print(f"    - èŒƒå›´: {stat['min']} - {stat['max']}")
            print(f"    - å¹³å‡å€¼: {stat['avg']:.2f}")
    
    # 2. è·å–ç‰¹å®šå…ƒæ•°æ®çš„æ‰€æœ‰å€¼
    print("\nğŸ“Š æ‰€æœ‰åˆ†ç±»å€¼:")
    categories = get_metadata_info(retriever, "category")
    print(f"  {categories}")
    
    print("\nğŸ“Š æ‰€æœ‰éš¾åº¦çº§åˆ«:")
    difficulties = get_metadata_info(retriever, "difficulty")
    print(f"  {difficulties}")
    
    print("\nğŸ“Š æ‰€æœ‰ä½œè€…:")
    authors = get_metadata_info(retriever, "author")
    print(f"  {authors}")


def demo_advanced_queries(retriever):
    """æ¼”ç¤ºé«˜çº§æŸ¥è¯¢"""
    print("\n" + "="*50)
    print("7. é«˜çº§æŸ¥è¯¢æ¼”ç¤º")
    print("="*50)
    
    # 1. å¤åˆå…ƒæ•°æ®æŸ¥è¯¢
    print("\nğŸ” æ£€ç´¢å­˜åœ¨ç‰¹å®šå…ƒæ•°æ®é”®çš„æ–‡æ¡£:")
    nodes = retriever.retrieve_by_metadata_exists(["tags", "author"], require_all=True)
    print(f"  æ‰¾åˆ° {len(nodes)} ä¸ªåŒæ—¶åŒ…å«tagså’Œauthorçš„æ–‡æ¡£")
    
    nodes = retriever.retrieve_by_metadata_exists(["tags", "author"], require_all=False)
    print(f"  æ‰¾åˆ° {len(nodes)} ä¸ªåŒ…å«tagsæˆ–authorçš„æ–‡æ¡£")
    
    # 2. ç»„åˆæŸ¥è¯¢ç¤ºä¾‹
    print("\nğŸ” å¤æ‚ç»„åˆæŸ¥è¯¢ç¤ºä¾‹:")
    
    # å…ˆæŒ‰åˆ†ç±»è¿‡æ»¤
    programming_nodes = search_by_metadata(retriever, {"category": "programming"})
    print(f"  ç¼–ç¨‹ç±»æ–‡æ¡£: {len(programming_nodes)} ä¸ª")
    
    # å†åœ¨å…¶ä¸­æŒ‰å­—æ•°è¿‡æ»¤
    if programming_nodes:
        prog_node_ids = [node.node_id for node in programming_nodes]
        # è¿™é‡Œæˆ‘ä»¬æ‰‹åŠ¨ç»„åˆè¿‡æ»¤ï¼Œå®é™…åº”ç”¨ä¸­å¯ä»¥æ‰©å±•æ›´å¤æ‚çš„æŸ¥è¯¢æ¥å£
        long_prog_nodes = [
            node for node in programming_nodes 
            if node.metadata.get('words', 0) > 20
        ]
        print(f"  å…¶ä¸­å­—æ•°>20çš„: {len(long_prog_nodes)} ä¸ª")
        
        for node in long_prog_nodes:
            print(f"    - {node.metadata['doc_id']}: {node.metadata['words']}å­—")


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ å…ƒæ•°æ®æ£€ç´¢åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    # è®¾ç½®æ—¥å¿—
    setup_logging("INFO")
    
    # åˆ›å»ºç¤ºä¾‹æ–‡æ¡£
    documents = create_sample_documents()
    print(f"\nğŸ“š åˆ›å»ºäº† {len(documents)} ä¸ªç¤ºä¾‹æ–‡æ¡£")
    
    try:
        # å°è¯•åˆ›å»ºå¸¦æœ‰æ¨¡æ‹ŸåµŒå…¥æä¾›å•†çš„RAGç³»ç»Ÿ
        print("\nğŸ—ï¸  åˆ›å»ºRAGç³»ç»Ÿ...")
        
        # è¿™é‡Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªä¸éœ€è¦çœŸå®APIçš„ç‰ˆæœ¬ç”¨äºæ¼”ç¤º
        # æ³¨æ„ï¼šæŸäº›åŠŸèƒ½éœ€è¦çœŸå®çš„åµŒå…¥æä¾›å•†æ‰èƒ½å®Œæ•´å·¥ä½œ
        from coderepoindex.embeddings import create_indexer, create_retriever
        
        # ç›´æ¥åˆ›å»ºå­˜å‚¨ç»„ä»¶ï¼Œé¿å…ä¾èµ–åµŒå…¥æä¾›å•†
        from coderepoindex.embeddings import SimpleDocumentStore, SimpleVectorStore, EmbeddingRetriever
        
        # åˆ›å»ºæ–‡æ¡£å­˜å‚¨å’Œå‘é‡å­˜å‚¨
        document_store = SimpleDocumentStore()
        vector_store = SimpleVectorStore()
        
        # åˆ›å»ºæ£€ç´¢å™¨ï¼ˆä¸éœ€è¦åµŒå…¥æä¾›å•†ç”¨äºå…ƒæ•°æ®æ£€ç´¢ï¼‰
        retriever = EmbeddingRetriever(
            embedding_provider=None,  # å…ƒæ•°æ®æ£€ç´¢ä¸éœ€è¦
            document_store=document_store,
            vector_store=vector_store,
            metadata_only=True  # å¯ç”¨å…ƒæ•°æ®æ£€ç´¢æ¨¡å¼
        )
        
        # æ¨¡æ‹Ÿæ„å»ºç´¢å¼•ï¼ˆåªæ„å»ºæ–‡æ¡£å­˜å‚¨éƒ¨åˆ†ï¼‰
        print("ğŸ“š æ„å»ºæ–‡æ¡£ç´¢å¼•...")
        for i, doc in enumerate(documents):
            from coderepoindex.embeddings import Node
            # åˆ›å»ºèŠ‚ç‚¹
            node = Node(
                text=doc["text"],
                metadata=doc["metadata"],
                node_id=f"node_{doc['metadata']['doc_id']}_{i}"
            )
            # æ·»åŠ åˆ°æ–‡æ¡£å­˜å‚¨
            document_store.add_node(node)
        
        print(f"âœ… ç´¢å¼•æ„å»ºå®Œæˆï¼Œå…± {len(document_store._nodes)} ä¸ªèŠ‚ç‚¹")
        
        # æ‰§è¡Œå„ç§æ¼”ç¤º
        demo_basic_metadata_search(retriever)
        demo_id_search(retriever)
        demo_contains_search(retriever)
        demo_range_search(retriever)
        demo_hybrid_search(retriever)
        demo_metadata_statistics(retriever)
        demo_advanced_queries(retriever)
        
        print("\n" + "="*60)
        print("ğŸ‰ å…ƒæ•°æ®æ£€ç´¢åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")
        print("\nğŸ’¡ ä¸»è¦åŠŸèƒ½æ€»ç»“:")
        print("   âœ… åŸºç¡€å…ƒæ•°æ®æ£€ç´¢ - ç²¾ç¡®åŒ¹é…")
        print("   âœ… IDæ£€ç´¢ - å•ä¸ªå’Œæ‰¹é‡")
        print("   âœ… åŒ…å«æ£€ç´¢ - æ¨¡ç³ŠåŒ¹é…")
        print("   âœ… èŒƒå›´æ£€ç´¢ - æ•°å€¼å’Œå­—ç¬¦ä¸²èŒƒå›´")
        print("   âœ… æ··åˆæ£€ç´¢ - å‘é‡+å…ƒæ•°æ®ç»„åˆ")
        print("   âœ… ç»Ÿè®¡ä¿¡æ¯ - å…ƒæ•°æ®åˆ†æ")
        print("   âœ… é«˜çº§æŸ¥è¯¢ - å¤åˆæ¡ä»¶")
        
        print("\nğŸ“ æ³¨æ„äº‹é¡¹:")
        print("   - æ··åˆæ£€ç´¢éœ€è¦æœ‰æ•ˆçš„åµŒå…¥æä¾›å•†")
        print("   - èŒƒå›´æ£€ç´¢æ”¯æŒæ•°å€¼å’Œå­—ç¬¦ä¸²æ¯”è¾ƒ")
        print("   - æ‰€æœ‰æ–¹æ³•éƒ½åŒ…å«é”™è¯¯å¤„ç†")
        print("   - æ”¯æŒå¤æ‚çš„å…ƒæ•°æ®ç»“æ„")
        
    except Exception as e:
        print(f"\nâŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("è¯·æ£€æŸ¥ä¾èµ–é…ç½®å’Œç¯å¢ƒè®¾ç½®")


if __name__ == "__main__":
    main() 