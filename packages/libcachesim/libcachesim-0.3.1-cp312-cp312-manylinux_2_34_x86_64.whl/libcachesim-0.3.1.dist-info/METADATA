Metadata-Version: 2.2
Name: libcachesim
Version: 0.3.1
Summary: Python bindings for libCacheSim
Requires-Python: >=3.9
Provides-Extra: test
Requires-Dist: pytest; extra == "test"
Description-Content-Type: text/markdown

# libCacheSim Python Binding

Python bindings for libCacheSim, a high-performance cache simulator and analysis library.

## Installation

### Quick Install (Recommended)
```bash
# From the libCacheSim root directory
bash scripts/install_python.sh
```

### Manual Install
```bash
# Build the main libCacheSim library first
cmake -G Ninja -B build
ninja -C build

# Install Python binding
cd libCacheSim-python
pip install -e . -v
```

### Testing
```bash
# Run all tests
python -m pytest .

# Test import
python -c "import libcachesim; print('Success!')"
```

## Quick Start

### Basic Usage

```python
import libcachesim as lcs

# Create a cache
cache = lcs.LRU(cache_size=1024*1024)  # 1MB cache

# Process requests
req = lcs.Request()
req.obj_id = 1
req.obj_size = 100

print(cache.get(req))  # False (first access)
print(cache.get(req))  # True (second access)
```

### Trace reading

```python
import libcachesim as lcs

# Open trace and process efficiently
reader = lcs.open_trace("./data/cloudPhysicsIO.oracleGeneral.bin", lcs.TraceType.ORACLE_GENERAL_TRACE)
for idx, req in enumerate(reader):
    print(f"req {idx}: obj_id {req.obj_id}, obj_size {req.obj_size}")
```

### Trace Processing

```python
import libcachesim as lcs

# Open trace and process efficiently
reader = lcs.open_trace("./data/cloudPhysicsIO.oracleGeneral.bin", lcs.TraceType.ORACLE_GENERAL_TRACE)
cache = lcs.S3FIFO(cache_size=1024*1024)

# Process entire trace efficiently (C++ backend)
miss_ratio = cache.process_trace(reader)
print(f"Miss ratio: {miss_ratio:.4f}")
```

## Custom Cache Policies

Implement custom cache replacement algorithms using pure Python functions - no C/C++ compilation required.

### Python Hook Cache Overview

The `PythonHookCachePolicy` allows you to define custom caching behavior through Python callback functions. This is perfect for:
- Prototyping new cache algorithms
- Educational purposes and learning
- Research and experimentation
- Custom business logic implementation

### Hook Functions

You need to implement these callback functions:

- **`init_hook(cache_size: int) -> Any`**: Initialize your data structure
- **`hit_hook(data: Any, obj_id: int, obj_size: int) -> None`**: Handle cache hits
- **`miss_hook(data: Any, obj_id: int, obj_size: int) -> None`**: Handle cache misses
- **`eviction_hook(data: Any, obj_id: int, obj_size: int) -> int`**: Return object ID to evict
- **`remove_hook(data: Any, obj_id: int) -> None`**: Clean up when object removed
- **`free_hook(data: Any) -> None`**: [Optional] Final cleanup

### Example: Custom LRU Implementation

```python
import libcachesim as lcs
from collections import OrderedDict

# Create a Python hook-based cache
cache = lcs.PythonHookCachePolicy(cache_size=1024*1024, cache_name="MyLRU")

# Define LRU policy hooks
def init_hook(cache_size):
    return OrderedDict()  # Track access order

def hit_hook(lru_dict, obj_id, obj_size):
    lru_dict.move_to_end(obj_id)  # Move to most recent

def miss_hook(lru_dict, obj_id, obj_size):
    lru_dict[obj_id] = True  # Add to end

def eviction_hook(lru_dict, obj_id, obj_size):
    return next(iter(lru_dict))  # Return least recent

def remove_hook(lru_dict, obj_id):
    lru_dict.pop(obj_id, None)

# Set the hooks
cache.set_hooks(init_hook, hit_hook, miss_hook, eviction_hook, remove_hook)

# Use it like any other cache
req = lcs.Request()
req.obj_id = 1
req.obj_size = 100
hit = cache.get(req)  # Should be False (miss)
```

### Example: Custom FIFO Implementation

```python
import libcachesim as lcs
from collections import deque

# Create a custom FIFO cache
cache = lcs.PythonHookCachePolicy(cache_size=1024, cache_name="CustomFIFO")

def init_hook(cache_size):
    return deque()  # Use deque for FIFO order

def hit_hook(fifo_queue, obj_id, obj_size):
    pass  # FIFO doesn't reorder on hit

def miss_hook(fifo_queue, obj_id, obj_size):
    fifo_queue.append(obj_id)  # Add to end of queue

def eviction_hook(fifo_queue, obj_id, obj_size):
    return fifo_queue[0]  # Return first item (oldest)

def remove_hook(fifo_queue, obj_id):
    if fifo_queue and fifo_queue[0] == obj_id:
        fifo_queue.popleft()

# Set the hooks and test
cache.set_hooks(init_hook, hit_hook, miss_hook, eviction_hook, remove_hook)

req = lcs.Request()
req.obj_id = 1
req.obj_size = 100
hit = cache.get(req)
print(f"Cache hit: {hit}")  # Should be False (miss)
```

## Available Algorithms

### Built-in Cache Algorithms

#### Basic Algorithms
- **FIFO**: First-In-First-Out
- **LRU**: Least Recently Used
- **LFU**: Least Frequently Used
- **Clock**: Clock/Second-chance algorithm

#### Advanced Algorithms
- **S3FIFO**: Simple, Fast, Fair FIFO (recommended for most workloads)
- **Sieve**: High-performance eviction algorithm
- **ARC**: Adaptive Replacement Cache
- **TwoQ**: Two-Queue algorithm
- **TinyLFU**: TinyLFU with window
- **SLRU**: Segmented LRU

#### Research/ML Algorithms
- **LRB**: Learning-based cache (if enabled)
- **GLCache**: Machine learning-based cache
- **ThreeLCache**: Three-level cache hierarchy (if enabled)

```python
import libcachesim as lcs

# All algorithms use the same unified interface
cache_size = 1024 * 1024  # 1MB

lru_cache = lcs.LRU(cache_size)
s3fifo_cache = lcs.S3FIFO(cache_size)
sieve_cache = lcs.Sieve(cache_size)
arc_cache = lcs.ARC(cache_size)

req = lcs.Request()
req.obj_id = 1
req.obj_size = 100

for cache in [lru_cache, s3fifo_cache, sieve_cache, arc_cache]:
    # All caches work identically
    hit = cache.get(req)
```

## Examples and Testing

### Algorithm Comparison
```python
import libcachesim as lcs

def compare_algorithms(trace_path):
    algorithms = ['LRU', 'S3FIFO', 'Sieve', 'ARC']

    print("Algorithm\tMiss Ratio")
    print("-" * 25)
    for algo_name in algorithms:
        reader = lcs.open_trace(trace_path, lcs.TraceType.ORACLE_GENERAL_TRACE)
        cache = getattr(lcs, algo_name)(cache_size=1024*1024)
        miss_ratio = cache.process_trace(reader)
        print(f"{algo_name}\t\t{miss_ratio:.4f}")

compare_algorithms("./data/cloudPhysicsIO.oracleGeneral.bin")
```

### Performance Benchmarking
```python
import time

import libcachesim as lcs

def benchmark_cache(cache, num_requests=100000):
    """Benchmark cache performance"""
    start_time = time.time()

    for i in range(num_requests):
        req = lcs.Request()
        req.obj_id = i % 1000  # Working set of 1000 objects
        req.obj_size = 100
        cache.get(req)

    end_time = time.time()
    throughput = num_requests / (end_time - start_time)

    print(f"Processed {num_requests} requests in {end_time - start_time:.2f}s")
    print(f"Throughput: {throughput:.0f} requests/sec")

# Compare performance
lru_cache = lcs.LRU(cache_size=1024*1024)
s3fifo_cache = lcs.S3FIFO(cache_size=1024*1024)

print("LRU Performance:")
benchmark_cache(lru_cache)

print("\nS3-FIFO Performance:")
benchmark_cache(s3fifo_cache)
```

### Validate Custom Implementation
```python
def test_custom_vs_builtin():
    """Test custom cache against built-in implementation"""
    cache_size = 1024

    # Your custom LRU implementation
    custom_cache = lcs.PythonHookCachePolicy(cache_size, "CustomLRU")
    # ... set up your LRU hooks here ...

    # Built-in LRU for comparison
    builtin_cache = lcs.LRU(cache_size)

    # Test with same workloads
    reader = open_trace(...)

    for idx, req in enumerate(reader):
        custom_result = custom_cache.get(req)
        builtin_result = builtin_cache.get(req)

        assert custom_result == builtin_result, f"Mismatch when processing req {idx}"
```


## API Reference

### Supported Trace Formats
```python
# Oracle format (binary, fastest)
reader = lcs.open_trace("./data/cloudPhysicsIO.oracleGeneral.bin", lcs.TraceType.ORACLE_GENERAL_TRACE)

# VSCSI format
reader = lcs.open_trace("./data/cloudPhysicsIO.vscsi", lcs.TraceType.VSCSI_TRACE)

# Plain text format
reader = lcs.open_trace("./data/cloudPhysicsIO.txt", lcs.TraceType.PLAIN_TXT_TRACE)
```

### Python Hook Cache Reference

When implementing `PythonHookCachePolicy`, provide these hook functions:

```python
def init_hook(cache_size: int) -> Any:
    """Initialize and return plugin data structure"""
    return {}  # Can be any Python object

def hit_hook(plugin_data: Any, obj_id: int, obj_size: int) -> None:
    """Handle cache hits - update your data structure"""
    pass

def miss_hook(plugin_data: Any, obj_id: int, obj_size: int) -> None:
    """Handle cache misses - add object to your data structure"""
    pass

def eviction_hook(plugin_data: Any, obj_id: int, obj_size: int) -> int:
    """Return object ID to evict when cache is full"""
    return victim_obj_id

def remove_hook(plugin_data: Any, obj_id: int) -> None:
    """Clean up when object is removed from cache"""
    pass

def free_hook(plugin_data: Any) -> None:
    """[Optional] Final cleanup when cache is destroyed"""
    pass

# Set hooks
cache.set_hooks(init_hook, hit_hook, miss_hook, eviction_hook, remove_hook, free_hook)
```

## Troubleshooting

### Common Issues

**Import Error**: Make sure libCacheSim C++ library is built first:
```bash
cmake -G Ninja -B build && ninja -C build
```

**Performance Issues**: Use `process_trace()` for large workloads instead of individual `get()` calls for better performance.

**Memory Usage**: Monitor cache statistics (`cache.occupied_byte`) and ensure proper cache size limits for your system.

**Custom Cache Issues**: Validate your custom implementation against built-in algorithms using the test functions above.

### Getting Help

- Check the [main documentation](../doc/) for detailed guides
- Run tests: `python -m pytest libCacheSim-python/`
- Open issues on [GitHub](https://github.com/1a1a11a/libCacheSim/issues)
- Review [examples](examples) in the main repository
