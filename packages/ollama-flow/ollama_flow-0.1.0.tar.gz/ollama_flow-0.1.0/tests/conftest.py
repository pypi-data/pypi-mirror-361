"""
pytest é…ç½®æ–‡ä»¶
å®šç¾©æ¸¬è©¦å¤¾å…·å’Œå…±äº«è¨­ç½®
"""

import pytest
import os
import tempfile
from unittest.mock import Mock, patch
from typing import Dict, Any

from ollama_flow import OllamaClient, ChatMessage


@pytest.fixture
def mock_ollama_client():
    """å‰µå»ºæ¨¡æ“¬çš„ Ollama å®¢æˆ¶ç«¯"""
    client = OllamaClient(base_url="http://localhost:11434")
    return client


@pytest.fixture
def mock_models_response():
    """å‰µå»ºæ¨¡æ“¬çš„æ¨¡å‹åˆ—è¡¨å›æ‡‰"""
    return {
        "models": [
            {"name": "llama3.2", "size": 1000000},
            {"name": "qwen3:4b", "size": 2000000},
            {"name": "all-minilm", "size": 500000}
        ]
    }


@pytest.fixture
def mock_generate_response():
    """å‰µå»ºæ¨¡æ“¬çš„ç”Ÿæˆå›æ‡‰"""
    return {
        "model": "llama3.2",
        "response": "This is a test response.",
        "done": True,
        "total_duration": 1000000000,
        "load_duration": 500000000,
        "eval_count": 20,
        "eval_duration": 800000000
    }


@pytest.fixture
def mock_chat_response():
    """å‰µå»ºæ¨¡æ“¬çš„èŠå¤©å›æ‡‰"""
    return {
        "model": "llama3.2",
        "message": {
            "role": "assistant",
            "content": "Hello! How can I help you today?"
        },
        "done": True,
        "total_duration": 1500000000
    }


@pytest.fixture
def mock_embed_response():
    """å‰µå»ºæ¨¡æ“¬çš„åµŒå…¥å›æ‡‰"""
    return {
        "embeddings": [
            [0.1, 0.2, 0.3, 0.4, 0.5],
            [0.6, 0.7, 0.8, 0.9, 1.0]
        ]
    }


@pytest.fixture
def sample_chat_messages():
    """å‰µå»ºæ¨£æœ¬èŠå¤©è¨Šæ¯"""
    return [
        ChatMessage(role="system", content="You are a helpful assistant."),
        ChatMessage(role="user", content="Hello"),
        ChatMessage(role="assistant", content="Hi there!"),
        ChatMessage(role="user", content="How are you?")
    ]


@pytest.fixture
def mock_streaming_response():
    """å‰µå»ºæ¨¡æ“¬çš„ä¸²æµå›æ‡‰"""
    return [
        b'{"response": "Hello", "done": false}',
        b'{"response": " there", "done": false}',
        b'{"response": "!", "done": true, "total_duration": 1000000000}'
    ]


@pytest.fixture
def temp_directory():
    """å‰µå»ºè‡¨æ™‚ç›®éŒ„"""
    with tempfile.TemporaryDirectory() as tmp_dir:
        yield tmp_dir


@pytest.fixture
def mock_requests_session():
    """æ¨¡æ“¬ requests.Sessionï¼ˆéè‡ªå‹•ä½¿ç”¨ï¼‰"""
    with patch('requests.Session') as mock_session:
        yield mock_session


@pytest.fixture
def mock_successful_http_response():
    """å‰µå»ºæˆåŠŸçš„ HTTP å›æ‡‰æ¨¡æ“¬"""
    mock_response = Mock()
    mock_response.status_code = 200
    mock_response.raise_for_status.return_value = None
    return mock_response


@pytest.fixture
def mock_error_http_response():
    """å‰µå»ºéŒ¯èª¤çš„ HTTP å›æ‡‰æ¨¡æ“¬"""
    mock_response = Mock()
    mock_response.status_code = 404
    mock_response.raise_for_status.side_effect = Exception("404 Not Found")
    return mock_response


@pytest.fixture(scope="session")
def test_data_dir():
    """æ¸¬è©¦æ•¸æ“šç›®éŒ„"""
    return os.path.join(os.path.dirname(__file__), "test_data")


@pytest.fixture
def json_test_data():
    """JSON æ¸¬è©¦æ•¸æ“š"""
    return {
        "valid_person": {
            "name": "å¼µä¸‰",
            "age": 30,
            "skills": ["Python", "JavaScript"]
        },
        "invalid_person": {
            "name": "æå››",
            "age": "not_a_number",
            "skills": "not_a_list"
        }
    }


# æ¸¬è©¦æ¨™è¨˜
def pytest_configure(config):
    """é…ç½® pytest"""
    config.addinivalue_line(
        "markers", "unit: å–®å…ƒæ¸¬è©¦"
    )
    config.addinivalue_line(
        "markers", "integration: æ•´åˆæ¸¬è©¦"
    )
    config.addinivalue_line(
        "markers", "slow: æ…¢é€Ÿæ¸¬è©¦"
    )
    config.addinivalue_line(
        "markers", "network: éœ€è¦ç¶²çµ¡çš„æ¸¬è©¦"
    )


# æ¸¬è©¦æ”¶é›†é‰¤å­
def pytest_collection_modifyitems(config, items):
    """ä¿®æ”¹æ¸¬è©¦é …ç›®"""
    # ç‚ºæ¸¬è©¦æ·»åŠ æ¨™è¨˜
    for item in items:
        # æ ¹æ“šæ–‡ä»¶åæ·»åŠ æ¨™è¨˜
        if "test_client" in item.nodeid:
            item.add_marker(pytest.mark.unit)
        elif "test_models" in item.nodeid:
            item.add_marker(pytest.mark.unit)
        elif "test_schemas" in item.nodeid:
            item.add_marker(pytest.mark.unit)
        elif "test_integration" in item.nodeid:
            item.add_marker(pytest.mark.integration)
        elif "test_errors" in item.nodeid:
            item.add_marker(pytest.mark.unit)
            
        # æ¨™è¨˜éœ€è¦ç¶²çµ¡çš„æ¸¬è©¦
        if "network" in item.name.lower():
            item.add_marker(pytest.mark.network)
            
        # æ¨™è¨˜æ…¢é€Ÿæ¸¬è©¦
        if "slow" in item.name.lower() or "performance" in item.name.lower():
            item.add_marker(pytest.mark.slow)


# æ¸¬è©¦å ±å‘Šé‰¤å­
def pytest_report_header(config):
    """è‡ªå®šç¾©æ¸¬è©¦å ±å‘Šæ¨™é¡Œ"""
    testpaths = getattr(config.option, 'testpaths', None) or getattr(config, 'testpaths', ['tests'])
    return [
        "Ollama Flow æ¸¬è©¦å¥—ä»¶",
        "=" * 60,
        f"æ¸¬è©¦ç›®éŒ„: {testpaths}",
        f"Pytest ç‰ˆæœ¬: {pytest.__version__}",
        "=" * 60
    ]


# æ¸¬è©¦å¤±æ•—æ™‚çš„é¡å¤–ä¿¡æ¯
@pytest.fixture(autouse=True)
def test_context(request):
    """ç‚ºæ¸¬è©¦æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    # æ¸¬è©¦é–‹å§‹å‰
    test_name = request.node.name
    test_file = request.node.fspath.basename
    
    # å¯ä»¥åœ¨é€™è£¡æ·»åŠ æ¸¬è©¦é–‹å§‹çš„æ—¥èªŒ
    print(f"\né–‹å§‹æ¸¬è©¦: {test_file}::{test_name}")
    
    yield
    
    # æ¸¬è©¦çµæŸå¾Œ
    print(f"çµæŸæ¸¬è©¦: {test_file}::{test_name}")


# åƒæ•¸åŒ–æ¸¬è©¦æ•¸æ“š
@pytest.fixture(params=[
    {"temperature": 0.7, "top_p": 0.9},
    {"temperature": 0.5, "top_p": 0.8},
    {"temperature": 1.0, "top_p": 1.0}
])
def generation_options(request):
    """ç”Ÿæˆé¸é …åƒæ•¸"""
    return request.param


@pytest.fixture(params=[
    "å–®è¡Œæ–‡æœ¬",
    "å¤šè¡Œ\næ–‡æœ¬\næ¸¬è©¦",
    "åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ–‡æœ¬: !@#$%^&*()",
    "Unicode æ–‡æœ¬: ä½ å¥½ä¸–ç•Œ ğŸŒ"
])
def text_inputs(request):
    """æ–‡æœ¬è¼¸å…¥åƒæ•¸"""
    return request.param 