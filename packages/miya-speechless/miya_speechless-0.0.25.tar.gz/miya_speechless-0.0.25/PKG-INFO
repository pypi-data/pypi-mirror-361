Metadata-Version: 2.4
Name: miya-speechless
Version: 0.0.25
Summary: Speechless repo for sales call analysis
Author: Michal Pleva (MIYA Consulting), Niek Mereu (MIYA Consulting)
License-Expression: MIT
Requires-Python: <3.11,>=3.10
Requires-Dist: elevenlabs<3,>=2.3.0
Requires-Dist: google-cloud-speech<3,>=2.33.0
Requires-Dist: librosa<0.12,>=0.11.0
Requires-Dist: litellm<2,>=1.72.2
Requires-Dist: noisereduce<4,>=3.0.3
Requires-Dist: numba<0.62,>=0.61
Requires-Dist: onnx<2,>=1.17.0
Requires-Dist: onnxruntime<2,>=1.20.0
Requires-Dist: openai<2,>=1.51.2
Requires-Dist: pvfalcon<2,>=1.0.2
Requires-Dist: pyannote-audio<4,>=3.3.2
Requires-Dist: pydantic<3,>=2.11.7
Requires-Dist: pydub<0.26,>=0.25.1
Requires-Dist: python-dotenv<2,>=1.0.1
Requires-Dist: pytubefix<8,>=7.4.0
Requires-Dist: silero-vad<6,>=5.1.2
Requires-Dist: streamlit-advanced-audio<0.2,>=0.1.1
Requires-Dist: streamlit-audiorec<0.2,>=0.1.3
Requires-Dist: streamlit-webrtc<0.61,>=0.60.2
Requires-Dist: streamlit~=1.44
Requires-Dist: tiktoken<0.9,>=0.8.0
Requires-Dist: twine<6,>=5.1.1
Requires-Dist: websockets<16,>=15.0.1
Description-Content-Type: text/markdown


# miya-speechless

## Poetry Installation Instructions

To install the dependencies and manage the project, we use Poetry. Follow the steps below to set up your environment with Poetry.

### Step 1: Install Poetry

You can install Poetry by running the official installation script:

```bash
curl -sSL https://install.python-poetry.org | python3 -
```

Alternatively, you can install it via pip:

```bash
pip install poetry
```

### Step 2: Verify Poetry Installation

After installing, verify that Poetry is available by running:

```bash
poetry --version
```

### Step 3: Install Dependencies

Once Poetry is installed, you can install the project dependencies by running the following command in the project root:

```bash
poetry install
```

This will create a virtual environment and install all dependencies specified in the `pyproject.toml` file.

For Poetry >= 2.0.0, add [poetry shell plugin](https://github.com/python-poetry/poetry-plugin-shell), based on how you have installed Poetry, choose one of:
```bash
poetry self add poetry-plugin-shell
pipx inject poetry poetry-plugin-shell
pip install poetry-plugin-shell
```

### Step 4: Run the Project or Tests

You can now run the project or the tests using the Poetry environment:

To activate the Poetry environment:

```bash
poetry shell
```

To run the tests:

```bash
poetry run pytest
```

### Step 4: Convert the model to onnx format
To convert the model to onnx format, run the following command:

```bash
poetry poetry run python export_to_onnx.py --checkpoint /path/to/checkpoint --onnx_model /path/to/onnx_model
```

### Step 5: Run the streamlit app
Place the onnx model in the models directory.

To start the streamlit app, run the following command:

```bash
poetry run streamlit run app/app.py
```

To start debug mode, run:
```bash
poetry run python -m debugpy --listen 5678 -m streamlit run app/app.py
```

In the application, you can set the following parameters:
- overlap: Set the overlap between the transcript and the diaretization (default: 0.1)
- onset_threshold: Set the onset threshold for speaker start (default: 0.1)
- offset_threshold: Set the offset threshold for speaker stop (default: 0.1)

### Step 6: Add OPENAI_API_KEY and/or setup WHISPER_CPP_MODEL
`whisper_1` requires paid OpenAI subscription. An alternative is [whisper.cpp](https://github.com/ggerganov/whisper.cpp)

Download at least one of supported models:
```bash
#Linux
docker run -it --rm -v ./data/models:/models ghcr.io/ggerganov/whisper.cpp:main "./models/download-ggml-model.sh small /models"
# Windows
docker run -it --rm -v "$(pwd -W)/models":/models ghcr.io/ggerganov/whisper.cpp:main "./models/download-ggml-model.sh small /models"
```

When WHISPER_CPP_MODEL set, expect following to happen instead of calling OpenAI:
```bash
ffmpeg -i data/temp_results/uploaded_audio.mp3 -ar 16000 -ac 1 -c:a pcm_s16le data/audio/output.wav
# Linux
docker run -it --rm -v ./data/models:/models -v ./data/audio:/audios ghcr.io/ggerganov/whisper.cpp:main "./build/bin/whisper-cli -m /models/ggml-small.bin -f /audios/output.wav -ml 16 -oj -l en"
# Windows
docker run -it --rm -v "$(pwd -W)/data/models":/models -v "$(pwd -W)/data":/audios ghcr.io/ggerganov/whisper.cpp:main "./build/bin/whisper-cli -m /models/ggml-small.bin -f /audios/output.wav -ml 16 -oj -l en"
```
