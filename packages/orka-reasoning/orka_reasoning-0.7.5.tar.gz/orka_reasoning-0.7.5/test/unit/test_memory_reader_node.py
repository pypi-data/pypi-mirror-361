import time
from unittest.mock import AsyncMock, Mock, patch

import pytest

from orka.nodes.memory_reader_node import MemoryReaderNode


class TestMemoryReaderNodeInitialization:
    """Test MemoryReaderNode initialization scenarios."""

    @patch("orka.memory_logger.create_memory_logger")
    @patch("orka.utils.embedder.get_embedder")
    def test_default_initialization(self, mock_get_embedder, mock_create_logger):
        """Test initialization with default parameters."""
        mock_memory_logger = Mock()
        mock_create_logger.return_value = mock_memory_logger
        mock_embedder = Mock()
        mock_get_embedder.return_value = mock_embedder

        node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])

        assert node.node_id == "test_node"
        assert node.memory_logger == mock_memory_logger
        assert node.namespace == "default"
        assert node.limit == 5
        assert node.similarity_threshold == 0.7
        assert node.ef_runtime == 10
        # Embedder may be None if initialization fails
        mock_create_logger.assert_called_once_with(
            backend="redisstack",
            redis_url="redis://localhost:6380/0",
            embedder=None,  # Embedder fails during initialization
        )

    @patch("orka.utils.embedder.get_embedder")
    def test_initialization_with_custom_memory_logger(self, mock_get_embedder):
        """Test initialization with custom memory logger."""
        mock_memory_logger = Mock()
        mock_embedder = Mock()
        mock_get_embedder.return_value = mock_embedder

        node = MemoryReaderNode(
            node_id="test_node",
            prompt="test_prompt",
            queue=[],
            memory_logger=mock_memory_logger,
            namespace="custom_ns",
            limit=10,
            similarity_threshold=0.8,
            ef_runtime=20,
        )

        assert node.memory_logger == mock_memory_logger
        assert node.namespace == "custom_ns"
        assert node.limit == 10
        assert node.similarity_threshold == 0.8
        assert node.ef_runtime == 20

    @patch("orka.memory_logger.create_memory_logger")
    @patch("orka.utils.embedder.get_embedder")
    def test_initialization_with_embedder_failure(self, mock_get_embedder, mock_create_logger):
        """Test initialization when embedder creation fails."""
        mock_create_logger.return_value = Mock()
        mock_get_embedder.side_effect = Exception("Embedder failed")

        node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])

        assert node.embedder is None

    @patch("orka.memory_logger.create_memory_logger")
    @patch("orka.utils.embedder.get_embedder")
    def test_initialization_with_redis_url(self, mock_get_embedder, mock_create_logger):
        """Test initialization with custom Redis URL."""
        mock_create_logger.return_value = Mock()
        mock_get_embedder.return_value = Mock()

        node = MemoryReaderNode(
            node_id="test_node",
            prompt="test_prompt",
            queue=[],
            redis_url="redis://custom:6379/1",
            embedding_model="custom_model",
        )

        mock_create_logger.assert_called_once_with(
            backend="redisstack",
            redis_url="redis://custom:6379/1",
            embedder=None,  # Embedder fails during initialization
        )
        mock_get_embedder.assert_called_once_with("custom_model")


class TestMemoryReaderNodeRun:
    """Test the main run method of MemoryReaderNode."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.mock_memory_logger = Mock()
            self.mock_embedder = Mock()

            self.node = MemoryReaderNode(
                node_id="test_node",
                prompt="test_prompt",
                queue=[],
                memory_logger=self.mock_memory_logger,
            )
            self.node.embedder = self.mock_embedder

    @pytest.mark.asyncio
    async def test_run_with_empty_query(self):
        """Test run method with empty query."""
        context = {"input": ""}

        result = await self.node.run(context)

        assert result["memories"] == []
        assert result["query"] == ""
        assert result["error"] == "No query provided"

    @pytest.mark.asyncio
    async def test_run_with_no_query(self):
        """Test run method with no query in context."""
        context = {}

        result = await self.node.run(context)

        assert result["memories"] == []
        assert result["query"] == ""
        assert result["error"] == "No query provided"

    @pytest.mark.asyncio
    async def test_run_successful_search(self):
        """Test successful memory search."""
        mock_memories = [
            {
                "content": "Test memory 1",
                "metadata": {"log_type": "memory", "category": "stored"},
                "similarity_score": 0.9,
            },
            {
                "content": "Test memory 2",
                "metadata": {"log_type": "memory", "category": "stored"},
                "similarity_score": 0.8,
            },
        ]
        self.mock_memory_logger.search_memories.return_value = mock_memories

        context = {
            "input": "test query",
            "trace_id": "test_trace",
            "min_importance": 0.5,
        }

        result = await self.node.run(context)

        assert result["memories"] == mock_memories
        assert result["query"] == "test query"
        assert result["backend"] == "redisstack"
        assert result["search_type"] == "enhanced_vector"
        assert result["num_results"] == 2

        self.mock_memory_logger.search_memories.assert_called_once_with(
            query="test query",
            num_results=5,
            trace_id="test_trace",
            node_id=None,
            memory_type=None,
            min_importance=0.5,
            log_type="memory",
            namespace="default",
        )

    @pytest.mark.asyncio
    async def test_run_with_filtering(self):
        """Test run method filters out non-stored memories."""
        mock_memories = [
            {
                "content": "Stored memory",
                "metadata": {"log_type": "memory", "category": "stored"},
                "similarity_score": 0.9,
            },
            {
                "content": "Log entry",
                "metadata": {"log_type": "log", "category": "log"},
                "similarity_score": 0.8,
            },
            {
                "content": "Another stored memory",
                "metadata": {"category": "stored"},
                "similarity_score": 0.7,
            },
        ]
        self.mock_memory_logger.search_memories.return_value = mock_memories

        context = {"input": "test query"}
        result = await self.node.run(context)

        # Should filter out the log entry
        assert len(result["memories"]) == 2
        assert result["memories"][0]["content"] == "Stored memory"
        assert result["memories"][1]["content"] == "Another stored memory"

    @pytest.mark.asyncio
    async def test_run_without_search_memories_method(self):
        """Test run method when memory logger doesn't have search_memories."""
        self.mock_memory_logger.search_memories = None
        delattr(self.mock_memory_logger, "search_memories")

        context = {"input": "test query"}
        result = await self.node.run(context)

        assert result["memories"] == []
        assert result["query"] == "test query"
        assert result["backend"] == "redisstack"

    @pytest.mark.asyncio
    async def test_run_with_exception(self):
        """Test run method when search raises exception."""
        self.mock_memory_logger.search_memories.side_effect = Exception("Search failed")

        context = {"input": "test query"}
        result = await self.node.run(context)

        assert result["memories"] == []
        assert result["query"] == "test query"
        assert result["error"] == "Search failed"
        assert result["backend"] == "redisstack"


class TestMemoryReaderNodeHNSWSearch:
    """Test HNSW hybrid search functionality."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.mock_memory_logger = Mock()

            self.node = MemoryReaderNode(
                node_id="test_node",
                prompt="test_prompt",
                queue=[],
                memory_logger=self.mock_memory_logger,
            )
            # Add optional attributes for enhanced functionality
            self.node.enable_context_search = True
            self.node.enable_temporal_ranking = True

    @pytest.mark.asyncio
    async def test_hnsw_hybrid_search_basic(self):
        """Test basic HNSW hybrid search."""
        mock_results = [
            {"content": "Test result", "similarity_score": 0.9},
        ]
        self.mock_memory_logger.search_memories.return_value = mock_results

        query_embedding = [0.1, 0.2, 0.3]
        conversation_context = []

        results = await self.node._hnsw_hybrid_search(
            query_embedding,
            "test query",
            "test_namespace",
            "test_session",
            conversation_context,
        )

        assert results == mock_results
        self.mock_memory_logger.search_memories.assert_called_once()

    @pytest.mark.asyncio
    async def test_hnsw_hybrid_search_with_context_enhancement(self):
        """Test HNSW search with context enhancement."""
        mock_results = [
            {"content": "Test result", "similarity_score": 0.9},
        ]
        self.mock_memory_logger.search_memories.return_value = mock_results

        conversation_context = [
            {"content": "Previous conversation", "timestamp": time.time()},
        ]

        # Mock the enhancement method
        enhanced_results = [
            {"content": "Test result", "similarity_score": 0.95, "context_score": 0.05},
        ]
        self.node._enhance_with_context_scoring = Mock(return_value=enhanced_results)

        query_embedding = [0.1, 0.2, 0.3]
        results = await self.node._hnsw_hybrid_search(
            query_embedding,
            "test query",
            "test_namespace",
            "test_session",
            conversation_context,
        )

        assert results == enhanced_results
        self.node._enhance_with_context_scoring.assert_called_once_with(
            mock_results,
            conversation_context,
        )

    @pytest.mark.asyncio
    async def test_hnsw_hybrid_search_with_temporal_ranking(self):
        """Test HNSW search with temporal ranking."""
        mock_results = [
            {"content": "Test result", "similarity_score": 0.9, "timestamp": time.time()},
        ]
        self.mock_memory_logger.search_memories.return_value = mock_results

        # Mock the temporal ranking method
        ranked_results = [
            {"content": "Test result", "similarity_score": 0.92, "temporal_factor": 0.8},
        ]
        self.node._apply_temporal_ranking = Mock(return_value=ranked_results)

        query_embedding = [0.1, 0.2, 0.3]
        results = await self.node._hnsw_hybrid_search(
            query_embedding,
            "test query",
            "test_namespace",
            "test_session",
            [],
        )

        assert results == ranked_results
        self.node._apply_temporal_ranking.assert_called_once_with(mock_results)

    @pytest.mark.asyncio
    async def test_hnsw_hybrid_search_without_memory_logger_method(self):
        """Test HNSW search when memory logger doesn't have search_memories."""
        delattr(self.mock_memory_logger, "search_memories")

        query_embedding = [0.1, 0.2, 0.3]
        results = await self.node._hnsw_hybrid_search(
            query_embedding,
            "test query",
            "test_namespace",
            "test_session",
            [],
        )

        assert results == []

    @pytest.mark.asyncio
    async def test_hnsw_hybrid_search_with_exception(self):
        """Test HNSW search exception handling."""
        self.mock_memory_logger.search_memories.side_effect = Exception("Search error")

        query_embedding = [0.1, 0.2, 0.3]
        results = await self.node._hnsw_hybrid_search(
            query_embedding,
            "test query",
            "test_namespace",
            "test_session",
            [],
        )

        assert results == []


class TestMemoryReaderNodeContextScoring:
    """Test context-aware scoring functionality."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])
            self.node.context_weight = 0.2

    def test_enhance_with_context_scoring_no_context(self):
        """Test context scoring with no context."""
        results = [
            {"content": "Test result", "similarity_score": 0.9},
        ]

        enhanced = self.node._enhance_with_context_scoring(results, [])

        assert enhanced == results

    def test_enhance_with_context_scoring_with_context(self):
        """Test context scoring with conversation context."""
        results = [
            {"content": "machine learning algorithms", "similarity_score": 0.8},
            {"content": "weather forecast today", "similarity_score": 0.7},
        ]

        conversation_context = [
            {"content": "Tell me about machine learning and algorithms"},
            {"content": "What are the best algorithms for classification"},
        ]

        enhanced = self.node._enhance_with_context_scoring(results, conversation_context)

        # First result should get context bonus due to word overlap
        assert enhanced[0]["similarity_score"] > 0.8
        assert "context_score" in enhanced[0]
        assert "original_similarity" in enhanced[0]

        # Results should be sorted by enhanced similarity
        assert enhanced[0]["similarity_score"] >= enhanced[1]["similarity_score"]

    def test_enhance_with_context_scoring_exception_handling(self):
        """Test context scoring exception handling."""
        results = [{"content": "test"}]  # Missing similarity_score
        conversation_context = [{"content": "test context"}]

        # Should not raise exception
        enhanced = self.node._enhance_with_context_scoring(results, conversation_context)

        assert len(enhanced) == 1


class TestMemoryReaderNodeTemporalRanking:
    """Test temporal ranking functionality."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])
            self.node.temporal_decay_hours = 24.0
            self.node.temporal_weight = 0.1

    def test_apply_temporal_ranking_with_timestamps(self):
        """Test temporal ranking with valid timestamps."""
        current_time = time.time()
        recent_time = current_time - 3600  # 1 hour ago
        old_time = current_time - 86400  # 24 hours ago

        results = [
            {
                "content": "Old result",
                "similarity_score": 0.9,
                "timestamp": old_time,
            },
            {
                "content": "Recent result",
                "similarity_score": 0.8,
                "timestamp": recent_time,
            },
        ]

        with patch("time.time", return_value=current_time):
            ranked = self.node._apply_temporal_ranking(results)

        # Recent result should be boosted
        assert "temporal_factor" in ranked[0]
        assert "temporal_factor" in ranked[1]

        # Results should be re-sorted by temporal-adjusted similarity
        recent_result = next(r for r in ranked if r["content"] == "Recent result")
        old_result = next(r for r in ranked if r["content"] == "Old result")

        assert recent_result["temporal_factor"] > old_result["temporal_factor"]

    def test_apply_temporal_ranking_with_millisecond_timestamps(self):
        """Test temporal ranking with millisecond timestamps."""
        current_time = time.time()
        timestamp_ms = int(current_time * 1000)  # Convert to milliseconds

        results = [
            {
                "content": "Test result",
                "similarity_score": 0.8,
                "timestamp": timestamp_ms,
            },
        ]

        with patch("time.time", return_value=current_time):
            ranked = self.node._apply_temporal_ranking(results)

        assert "temporal_factor" in ranked[0]
        assert ranked[0]["temporal_factor"] > 0

    def test_apply_temporal_ranking_without_timestamps(self):
        """Test temporal ranking with missing timestamps."""
        results = [
            {"content": "Test result", "similarity_score": 0.8},
        ]

        ranked = self.node._apply_temporal_ranking(results)

        # Should return results unchanged
        assert ranked == results

    def test_apply_temporal_ranking_exception_handling(self):
        """Test temporal ranking exception handling."""
        results = [
            {"content": "Test result", "timestamp": "invalid"},
        ]

        # Should not raise exception
        ranked = self.node._apply_temporal_ranking(results)

        assert ranked == results


class TestMemoryReaderNodeMetrics:
    """Test search metrics functionality."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])
            # Initialize metrics
            self.node._search_metrics = {
                "average_search_time": 0.0,
                "hnsw_searches": 0,
                "legacy_searches": 0,
                "total_results_found": 0,
            }
            self.node.use_hnsw = True
            self.node.hybrid_search_enabled = True

    def test_update_search_metrics_first_search(self):
        """Test updating metrics for first search."""
        self.node._search_metrics["hnsw_searches"] = 1
        self.node._search_metrics["legacy_searches"] = 0

        self.node._update_search_metrics(0.5, 3)

        assert self.node._search_metrics["average_search_time"] == 0.5
        assert self.node._search_metrics["total_results_found"] == 3

    def test_update_search_metrics_multiple_searches(self):
        """Test updating metrics with exponential moving average."""
        self.node._search_metrics["average_search_time"] = 0.4
        self.node._search_metrics["hnsw_searches"] = 5
        self.node._search_metrics["legacy_searches"] = 3

        self.node._update_search_metrics(0.6, 2)

        # Should use exponential moving average: 0.1 * 0.6 + 0.9 * 0.4 = 0.42
        expected_avg = 0.1 * 0.6 + 0.9 * 0.4
        assert abs(self.node._search_metrics["average_search_time"] - expected_avg) < 0.001
        assert self.node._search_metrics["total_results_found"] == 2

    def test_get_search_metrics(self):
        """Test retrieving search metrics."""
        metrics = self.node.get_search_metrics()

        expected_keys = {
            "average_search_time",
            "hnsw_searches",
            "legacy_searches",
            "total_results_found",
            "hnsw_enabled",
            "hybrid_search_enabled",
            "ef_runtime",
            "similarity_threshold",
        }

        assert set(metrics.keys()) == expected_keys
        assert metrics["hnsw_enabled"] == True
        assert metrics["hybrid_search_enabled"] == True
        assert metrics["ef_runtime"] == 10
        assert metrics["similarity_threshold"] == 0.7


class TestMemoryReaderNodeContextExtraction:
    """Test conversation context extraction."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])
            self.node.context_window_size = 5

    def test_extract_conversation_context_from_previous_outputs(self):
        """Test extracting context from previous outputs."""
        context = {
            "previous_outputs": {
                "agent1": {
                    "response": "This is a response from agent1",
                    "confidence": 0.9,
                },
                "agent2": {
                    "result": "Agent2 result",
                    "status": "success",
                },
                "agent3": "Simple string output",
                "agent4": 42,  # Number output
            },
        }

        with patch("time.time", return_value=1000.0):
            conversation_context = self.node._extract_conversation_context(context)

        assert len(conversation_context) == 4

        # Check agent1 output
        agent1_context = next(c for c in conversation_context if c["agent_id"] == "agent1")
        assert agent1_context["content"] == "This is a response from agent1"
        assert agent1_context["field"] == "response"

        # Check agent2 output
        agent2_context = next(c for c in conversation_context if c["agent_id"] == "agent2")
        assert agent2_context["content"] == "Agent2 result"
        assert agent2_context["field"] == "result"

        # Check simple outputs
        agent3_context = next(c for c in conversation_context if c["agent_id"] == "agent3")
        assert agent3_context["content"] == "Simple string output"
        assert agent3_context["field"] == "direct_output"

    def test_extract_conversation_context_from_direct_fields(self):
        """Test extracting context from direct context fields."""
        context = {
            "conversation": [
                {"content": "Message 1", "timestamp": 1000},
                {"content": "Message 2", "timestamp": 2000},
            ],
            "history": "Previous conversation history",
            "context": "Additional context info",
        }

        conversation_context = self.node._extract_conversation_context(context)

        assert len(conversation_context) == 4

        # Check conversation list items
        msg_contexts = [c for c in conversation_context if c.get("source") == "conversation"]
        assert len(msg_contexts) == 2
        assert msg_contexts[0]["content"] == "Message 1"
        assert msg_contexts[0]["timestamp"] == 1000

        # Check string context fields
        history_context = next(c for c in conversation_context if c.get("source") == "history")
        assert history_context["content"] == "Previous conversation history"

    def test_extract_conversation_context_with_size_limit(self):
        """Test context extraction with size limit."""
        self.node.context_window_size = 2

        context = {
            "previous_outputs": {f"agent{i}": {"response": f"Response {i}"} for i in range(5)},
        }

        with patch("time.time", return_value=1000.0):
            conversation_context = self.node._extract_conversation_context(context)

        # Should be limited to context_window_size
        assert len(conversation_context) == 2

    def test_extract_conversation_context_empty(self):
        """Test context extraction with empty context."""
        context = {}

        conversation_context = self.node._extract_conversation_context(context)

        assert conversation_context == []


class TestMemoryReaderNodeQueryVariations:
    """Test query variation generation."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])

    def test_generate_query_variations_single_word(self):
        """Test query variations for single word."""
        variations = self.node._generate_query_variations("machine")

        expected_variations = [
            "machine",
            "about machine",
            "machine information",
            "what is machine",
            "tell me about machine",
        ]

        assert all(var in variations for var in expected_variations)

    def test_generate_query_variations_two_words(self):
        """Test query variations for two words."""
        variations = self.node._generate_query_variations("machine learning")

        assert "machine learning" in variations
        assert "learning machine" in variations  # Reversed
        assert "about machine learning" in variations
        assert "machine and learning" in variations

    def test_generate_query_variations_multiple_words(self):
        """Test query variations for multiple words."""
        variations = self.node._generate_query_variations("deep neural network architecture")

        assert "deep neural network architecture" in variations
        assert "about deep neural network architecture" in variations
        assert "deep architecture" in variations  # First and last words
        assert "deep neural" in variations  # First two words
        assert "network architecture" in variations  # Last two words

    def test_generate_query_variations_empty_query(self):
        """Test query variations for empty query."""
        variations = self.node._generate_query_variations("")
        assert variations == []

        variations = self.node._generate_query_variations("   ")
        assert variations == []

    def test_generate_enhanced_query_variations_with_context(self):
        """Test enhanced query variations with conversation context."""
        conversation_context = [
            {"content": "I'm interested in machine learning algorithms and classification"},
            {"content": "What are the best approaches for neural networks"},
        ]

        variations = self.node._generate_enhanced_query_variations(
            "deep learning",
            conversation_context,
        )

        # Should include original query
        assert "deep learning" in variations

        # Should include more variations when context is provided
        assert len(variations) > 1

        # Should be limited to 8 variations
        assert len(variations) <= 8

        # Context-enhanced variations may or may not be generated depending on word filtering
        # but we should have some additional variations beyond the original
        basic_variations = self.node._generate_query_variations("deep learning")
        assert len(variations) >= len(basic_variations)

    def test_generate_enhanced_query_variations_no_context(self):
        """Test enhanced query variations without context."""
        variations = self.node._generate_enhanced_query_variations("test query", [])

        # Should include original and basic variations
        assert "test query" in variations
        assert len(variations) > 1

    def test_generate_enhanced_query_variations_empty_query(self):
        """Test enhanced query variations with empty query."""
        variations = self.node._generate_enhanced_query_variations("", [])
        assert len(variations) == 1
        assert variations[0] == ""


class TestMemoryReaderNodeEdgeCases:
    """Test edge cases and error handling."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.mock_memory_logger = Mock()
            self.node = MemoryReaderNode(
                node_id="test_node",
                prompt="test_prompt",
                queue=[],
                memory_logger=self.mock_memory_logger,
            )
            # Add required attributes for edge case testing
            self.node.context_window_size = 5

    @pytest.mark.asyncio
    async def test_run_with_malformed_memories(self):
        """Test run method with malformed memory data."""
        malformed_memories = [
            {"content": "Valid memory", "metadata": {"log_type": "memory"}},
            {"content": "Memory without metadata"},  # Missing metadata
            {"metadata": {"log_type": "memory"}},  # Missing content
            # Note: None values are filtered out by the memory logger search, not by our filtering
        ]
        self.mock_memory_logger.search_memories.return_value = malformed_memories

        context = {"input": "test query"}
        result = await self.node.run(context)

        # Should handle malformed data gracefully
        assert "memories" in result
        # Malformed data should be handled - may or may not contain errors

    def test_context_scoring_with_malformed_data(self):
        """Test context scoring with malformed data."""
        results = [
            {"content": "test"},  # Missing similarity_score
            {"similarity_score": "invalid"},  # Invalid similarity_score
            {"content": "valid", "similarity_score": 0.8},
        ]

        conversation_context = [
            {"content": "test context"},
            {"invalid": "data"},  # Missing content
            None,  # Null context
        ]

        # Should not raise exception
        enhanced = self.node._enhance_with_context_scoring(results, conversation_context)
        assert len(enhanced) == len(results)

    def test_temporal_ranking_with_invalid_timestamps(self):
        """Test temporal ranking with invalid timestamps."""
        results = [
            {"content": "test1", "timestamp": "invalid_timestamp"},
            {"content": "test2", "timestamp": -1},  # Negative timestamp
            {"content": "test3", "timestamp": None},  # Null timestamp
        ]

        # Should not raise exception
        ranked = self.node._apply_temporal_ranking(results)
        assert len(ranked) == len(results)

    def test_metrics_update_with_invalid_data(self):
        """Test metrics update with invalid data."""
        self.node._search_metrics = {
            "average_search_time": 0.0,
            "hnsw_searches": 0,
            "legacy_searches": 0,
            "total_results_found": 0,
        }

        # Should handle negative or invalid values
        self.node._update_search_metrics(-1, -5)

        # Metrics should still be updated (even if values are unusual)
        assert self.node._search_metrics["total_results_found"] == -5

    def test_context_extraction_with_circular_references(self):
        """Test context extraction with circular reference data."""
        # Create circular reference
        circular_data = {"key": "value"}
        circular_data["self"] = circular_data

        context = {
            "previous_outputs": {
                "agent1": circular_data,
            },
        }

        # Should handle circular references gracefully
        conversation_context = self.node._extract_conversation_context(context)

        # Should extract what it can without crashing
        assert isinstance(conversation_context, list)


class TestMemoryReaderNodeEnhancedKeywordSearch:
    """Test enhanced keyword search functionality."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])
            # Add missing attributes for enhanced keyword search
            self.node.context_weight = 0.3
            self.node.limit = 5

    @pytest.mark.asyncio
    async def test_enhanced_keyword_search_basic(self):
        """Test basic enhanced keyword search."""
        self.node.redis = AsyncMock()

        # Mock Redis responses
        self.node.redis.keys.return_value = [b"orka:mem:test1", b"orka:mem:test2"]
        self.node.redis.hget.side_effect = [
            b"test_namespace",  # namespace for test1
            b"test content with important keywords",  # content for test1
            b'{"category": "stored"}',  # metadata for test1
            b"test_namespace",  # namespace for test2
            b"different content",  # content for test2
            b'{"category": "temporary"}',  # metadata for test2
        ]

        results = await self.node._enhanced_keyword_search(
            "test_namespace",
            "important keywords",
            [],
        )

        assert len(results) == 1
        assert results[0]["content"] == "test content with important keywords"
        assert results[0]["match_type"] == "enhanced_keyword"
        assert results[0]["query_overlap"] > 0

    @pytest.mark.asyncio
    async def test_enhanced_keyword_search_with_context(self):
        """Test enhanced keyword search with conversation context."""
        self.node.redis = AsyncMock()
        self.node.context_weight = 0.3

        # Mock Redis responses
        self.node.redis.keys.return_value = [b"orka:mem:test1"]
        self.node.redis.hget.side_effect = [
            b"test_namespace",
            b"content with context words and query terms",
            b'{"timestamp": "2023-01-01T00:00:00Z"}',
        ]

        context = [
            {"content": "previous context words"},
            {"content": "more context information"},
        ]

        results = await self.node._enhanced_keyword_search("test_namespace", "query terms", context)

        assert len(results) == 1
        assert results[0]["context_overlap"] > 0
        assert results[0]["similarity"] > results[0]["query_overlap"] / 2

    @pytest.mark.asyncio
    async def test_enhanced_keyword_search_short_words(self):
        """Test enhanced keyword search with short words."""
        self.node.redis = AsyncMock()

        # Mock Redis responses
        self.node.redis.keys.return_value = [b"orka:mem:test1"]
        self.node.redis.hget.side_effect = [
            b"test_namespace",
            b"content with a an the",
            b"{}",
        ]

        # Query with only short words should use all words
        results = await self.node._enhanced_keyword_search("test_namespace", "a an the", [])

        assert len(results) == 1
        assert results[0]["query_overlap"] > 0

    @pytest.mark.asyncio
    async def test_enhanced_keyword_search_redis_error(self):
        """Test enhanced keyword search with Redis errors."""
        self.node.redis = AsyncMock()

        # Mock Redis error
        self.node.redis.keys.side_effect = Exception("Redis connection error")

        results = await self.node._enhanced_keyword_search("test_namespace", "test query", [])

        assert results == []


class TestMemoryReaderNodeContextAwareVectorSearch:
    """Test context-aware vector search functionality."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])
            # Add missing attributes for context-aware vector search
            self.node.context_weight = 0.3
            self.node.limit = 5
            self.node.enable_context_search = True

    @pytest.mark.asyncio
    async def test_context_aware_vector_search_basic(self):
        """Test basic context-aware vector search."""
        self.node.redis = AsyncMock()
        self.node.embedder = AsyncMock()
        self.node.similarity_threshold = 0.5

        # Mock Redis responses
        self.node.redis.keys.return_value = [b"orka:mem:test1"]
        self.node.redis.hget.side_effect = [
            b"test_namespace",
            b"mock_vector_bytes",
            b"test content",
            b'{"category": "stored"}',
        ]

        # Mock vector operations
        query_embedding = [0.1, 0.2, 0.3]
        with patch("orka.nodes.memory_reader_node.from_bytes") as mock_from_bytes:
            mock_from_bytes.return_value = [0.1, 0.2, 0.3]

            with patch.object(self.node, "_cosine_similarity", return_value=0.8):
                results = await self.node._context_aware_vector_search(
                    query_embedding,
                    "test_namespace",
                    [],
                    0.5,
                )

        assert len(results) == 1
        assert results[0]["match_type"] == "context_aware_vector"
        assert results[0]["primary_similarity"] == 0.8

    @pytest.mark.asyncio
    async def test_context_aware_vector_search_with_context(self):
        """Test context-aware vector search with conversation context."""
        self.node.redis = AsyncMock()
        self.node.embedder = AsyncMock()
        self.node.enable_context_search = True
        self.node.context_weight = 0.3

        # Mock Redis responses
        self.node.redis.keys.return_value = [b"orka:mem:test1"]
        self.node.redis.hget.side_effect = [
            b"test_namespace",
            b"mock_vector_bytes",
            b"test content",
            b"{}",
        ]

        context = [{"content": "context information"}]

        with patch("orka.nodes.memory_reader_node.from_bytes") as mock_from_bytes:
            mock_from_bytes.return_value = [0.1, 0.2, 0.3]

            with patch.object(self.node, "_generate_context_vector", return_value=[0.2, 0.3, 0.4]):
                with patch.object(self.node, "_cosine_similarity", side_effect=[0.7, 0.6]):
                    results = await self.node._context_aware_vector_search(
                        [0.1, 0.2, 0.3],
                        "test_namespace",
                        context,
                        0.5,
                    )

        assert len(results) == 1
        assert results[0]["primary_similarity"] == 0.7
        assert results[0]["context_similarity"] == 0.6
        assert results[0]["similarity"] > 0.7

    @pytest.mark.asyncio
    async def test_context_aware_vector_search_below_threshold(self):
        """Test context-aware vector search below similarity threshold."""
        self.node.redis = AsyncMock()
        self.node.similarity_threshold = 0.8

        # Mock Redis responses
        self.node.redis.keys.return_value = [b"orka:mem:test1"]
        self.node.redis.hget.side_effect = [
            b"test_namespace",
            b"mock_vector_bytes",
        ]

        with patch("orka.nodes.memory_reader_node.from_bytes") as mock_from_bytes:
            mock_from_bytes.return_value = [0.1, 0.2, 0.3]

            with patch.object(self.node, "_cosine_similarity", return_value=0.3):
                results = await self.node._context_aware_vector_search(
                    [0.1, 0.2, 0.3],
                    "test_namespace",
                    [],
                    0.8,
                )

        assert results == []


class TestMemoryReaderNodeContextVector:
    """Test context vector generation functionality."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])

    @pytest.mark.asyncio
    async def test_generate_context_vector_basic(self):
        """Test basic context vector generation."""
        self.node.embedder = AsyncMock()
        self.node.embedder.encode.return_value = [0.1, 0.2, 0.3]

        context = [
            {"content": "first context item"},
            {"content": "second context item"},
            {"content": "third context item"},
        ]

        result = await self.node._generate_context_vector(context)

        assert result is not None
        assert result == [0.1, 0.2, 0.3]
        self.node.embedder.encode.assert_called_once()

    @pytest.mark.asyncio
    async def test_generate_context_vector_empty(self):
        """Test context vector generation with empty context."""
        result = await self.node._generate_context_vector([])
        assert result is None

        result = await self.node._generate_context_vector(None)
        assert result is None

    @pytest.mark.asyncio
    async def test_generate_context_vector_limit_recent(self):
        """Test context vector generation limits to recent items."""
        self.node.embedder = AsyncMock()
        self.node.embedder.encode.return_value = [0.1, 0.2, 0.3]

        context = [{"content": f"context item {i}"} for i in range(10)]

        await self.node._generate_context_vector(context)

        # Should combine only the last 3 items
        call_args = self.node.embedder.encode.call_args[0][0]
        assert "context item 7" in call_args
        assert "context item 8" in call_args
        assert "context item 9" in call_args
        assert "context item 0" not in call_args

    @pytest.mark.asyncio
    async def test_generate_context_vector_error(self):
        """Test context vector generation with encoder error."""
        self.node.embedder = AsyncMock()
        self.node.embedder.encode.side_effect = Exception("Encoding failed")

        context = [{"content": "test content"}]

        result = await self.node._generate_context_vector(context)
        assert result is None


class TestMemoryReaderNodeContextAwareStreamSearch:
    """Test context-aware stream search functionality."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])
            self.node.similarity_threshold = 0.5
            self.node.context_weight = 0.3
            self.node.limit = 5

    @pytest.mark.asyncio
    async def test_context_aware_stream_search_basic(self):
        """Test basic context-aware stream search."""
        self.node.redis = AsyncMock()
        self.node.embedder = AsyncMock()

        # Mock stream entries
        stream_entries = [
            (
                b"1234567890-0",
                {b"payload": b'{"content": "test content", "metadata": {}}', b"ts": b"1234567890"},
            ),
            (
                b"1234567891-0",
                {b"payload": b'{"content": "other content", "metadata": {}}', b"ts": b"1234567891"},
            ),
        ]
        self.node.redis.xrange.return_value = stream_entries
        self.node.embedder.encode.side_effect = [[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]]

        query_embedding = [0.1, 0.2, 0.3]

        with patch.object(self.node, "_cosine_similarity", side_effect=[0.8, 0.3]):
            results = await self.node._context_aware_stream_search(
                "test_stream",
                "test query",
                query_embedding,
                [],
                0.5,
            )

        assert len(results) == 1
        assert results[0]["content"] == "test content"
        assert results[0]["match_type"] == "context_aware_stream"
        assert results[0]["primary_similarity"] == 0.8

    @pytest.mark.asyncio
    async def test_context_aware_stream_search_with_context(self):
        """Test context-aware stream search with conversation context."""
        self.node.redis = AsyncMock()
        self.node.embedder = AsyncMock()
        self.node.enable_context_search = True

        stream_entries = [
            (
                b"1234567890-0",
                {b"payload": b'{"content": "test content", "metadata": {}}', b"ts": b"1234567890"},
            ),
        ]
        self.node.redis.xrange.return_value = stream_entries
        self.node.embedder.encode.return_value = [0.1, 0.2, 0.3]

        context = [{"content": "context information"}]

        with patch.object(self.node, "_generate_context_vector", return_value=[0.2, 0.3, 0.4]):
            with patch.object(self.node, "_cosine_similarity", side_effect=[0.7, 0.6]):
                results = await self.node._context_aware_stream_search(
                    "test_stream",
                    "test query",
                    [0.1, 0.2, 0.3],
                    context,
                    0.5,
                )

        assert len(results) == 1
        assert results[0]["context_similarity"] == 0.6
        assert results[0]["similarity"] > 0.7  # Should include context bonus

    @pytest.mark.asyncio
    async def test_context_aware_stream_search_keyword_bonus(self):
        """Test context-aware stream search with keyword matching bonus."""
        self.node.redis = AsyncMock()
        self.node.embedder = AsyncMock()

        stream_entries = [
            (
                b"1234567890-0",
                {
                    b"payload": b'{"content": "exact match content", "metadata": {}}',
                    b"ts": b"1234567890",
                },
            ),
        ]
        self.node.redis.xrange.return_value = stream_entries
        self.node.embedder.encode.return_value = [0.1, 0.2, 0.3]

        with patch.object(
            self.node,
            "_cosine_similarity",
            return_value=0.3,
        ):  # Below threshold normally
            results = await self.node._context_aware_stream_search(
                "test_stream",
                "exact match",
                [0.1, 0.2, 0.3],
                [],
                0.5,
            )

        assert len(results) == 1  # Should still be included due to keyword matches
        assert results[0]["keyword_matches"] == 2  # "exact" and "match"
        assert results[0]["similarity"] > 0.3  # Should include keyword bonus

    @pytest.mark.asyncio
    async def test_context_aware_stream_search_malformed_payload(self):
        """Test context-aware stream search with malformed payload."""
        self.node.redis = AsyncMock()

        stream_entries = [
            (b"1234567890-0", {b"payload": b"invalid_json{", b"ts": b"1234567890"}),
            (
                b"1234567891-0",
                {b"payload": b'{"content": "valid content", "metadata": {}}', b"ts": b"1234567891"},
            ),
        ]
        self.node.redis.xrange.return_value = stream_entries
        self.node.embedder = AsyncMock()
        self.node.embedder.encode.return_value = [0.1, 0.2, 0.3]

        with patch.object(self.node, "_cosine_similarity", return_value=0.8):
            results = await self.node._context_aware_stream_search(
                "test_stream",
                "test query",
                [0.1, 0.2, 0.3],
                [],
                0.5,
            )

        # Should skip malformed entry and return valid one
        assert len(results) == 1
        assert results[0]["content"] == "valid content"

    @pytest.mark.asyncio
    async def test_context_aware_stream_search_redis_error(self):
        """Test context-aware stream search with Redis error."""
        self.node.redis = AsyncMock()
        self.node.redis.xrange.side_effect = Exception("Redis error")

        results = await self.node._context_aware_stream_search(
            "test_stream",
            "test query",
            [0.1, 0.2, 0.3],
            [],
            0.5,
        )

        assert results == []


class TestMemoryReaderNodeHybridScoring:
    """Test hybrid scoring functionality."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])
            self.node.enable_temporal_ranking = True
            self.node.temporal_decay_hours = 24

    def test_apply_hybrid_scoring_basic(self):
        """Test basic hybrid scoring."""
        memories = [
            {
                "content": "medium length content with reasonable amount of text",
                "similarity": 0.8,
                "metadata": {"category": "stored", "field1": "value1", "field2": "value2"},
                "timestamp": str(time.time() - 3600),  # 1 hour ago
            },
        ]

        result = self.node._apply_hybrid_scoring(memories, "test query", [])

        assert len(result) == 1
        # Final similarity may be boosted or reduced depending on factors
        assert result[0]["similarity"] != 0.8  # Should be modified
        assert "length_factor" in result[0]
        assert "recency_factor" in result[0]
        assert "metadata_factor" in result[0]

    def test_apply_hybrid_scoring_length_factors(self):
        """Test hybrid scoring with different content lengths."""
        memories = [
            {"content": "short", "similarity": 0.8, "metadata": {}},  # Too short
            {"content": " ".join(["word"] * 100), "similarity": 0.8, "metadata": {}},  # Sweet spot
            {"content": " ".join(["word"] * 600), "similarity": 0.8, "metadata": {}},  # Too long
        ]

        result = self.node._apply_hybrid_scoring(memories, "test query", [])

        assert len(result) == 3
        # Sweet spot should have highest score
        assert result[0]["length_factor"] == 1.1  # Sweet spot boost
        # Order should be by final similarity (sweet spot first)
        assert result[0]["content"] == " ".join(["word"] * 100)

    def test_apply_hybrid_scoring_temporal_ranking(self):
        """Test hybrid scoring with temporal ranking."""
        current_time = time.time()
        memories = [
            {
                "content": "recent content",
                "similarity": 0.8,
                "metadata": {},
                "timestamp": str(current_time - 1800),  # 30 minutes ago
            },
            {
                "content": "old content",
                "similarity": 0.8,
                "metadata": {},
                "ts": str((current_time - 86400) * 1000),  # 1 day ago (in milliseconds)
            },
        ]

        result = self.node._apply_hybrid_scoring(memories, "test query", [])

        assert len(result) == 2
        # Recent content should have higher recency factor
        recent_memory = next(m for m in result if m["content"] == "recent content")
        old_memory = next(m for m in result if m["content"] == "old content")

        assert recent_memory["recency_factor"] > old_memory["recency_factor"]

    def test_apply_hybrid_scoring_metadata_quality(self):
        """Test hybrid scoring with metadata quality factors."""
        memories = [
            {
                "content": "content with rich metadata",
                "similarity": 0.8,
                "metadata": {
                    "category": "stored",
                    "field1": "value1",
                    "field2": "value2",
                    "field3": "value3",
                    "field4": "value4",
                },
            },
            {
                "content": "content with minimal metadata",
                "similarity": 0.8,
                "metadata": {"category": "temporary"},
            },
        ]

        result = self.node._apply_hybrid_scoring(memories, "test query", [])

        assert len(result) == 2
        rich_metadata_memory = next(m for m in result if "rich metadata" in m["content"])
        minimal_metadata_memory = next(m for m in result if "minimal metadata" in m["content"])

        # Rich metadata should get higher factor
        assert rich_metadata_memory["metadata_factor"] > minimal_metadata_memory["metadata_factor"]
        # Stored category should get additional boost
        assert rich_metadata_memory["metadata_factor"] >= 1.1 * 1.05

    def test_apply_hybrid_scoring_empty_memories(self):
        """Test hybrid scoring with empty memories list."""
        result = self.node._apply_hybrid_scoring([], "test query", [])
        assert result == []

    def test_apply_hybrid_scoring_error_handling(self):
        """Test hybrid scoring with error scenarios."""
        memories = [
            {
                "content": "test content",
                "similarity": 0.8,
                "metadata": "invalid_metadata_not_dict",  # Invalid metadata
                "timestamp": "invalid_timestamp",  # Invalid timestamp
            },
        ]

        # Should handle errors gracefully
        result = self.node._apply_hybrid_scoring(memories, "test query", [])
        assert len(result) == 1
        # Similarity may be modified by length and other factors even with invalid metadata
        assert result[0]["similarity"] != 0.8  # Should be modified by length factor at least


class TestMemoryReaderNodeFilteringMethods:
    """Test memory filtering functionality."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])

    def test_filter_enhanced_relevant_memories_basic(self):
        """Test basic enhanced relevant memory filtering."""
        self.node.similarity_threshold = 0.5

        memories = [
            {"content": "machine learning algorithms", "similarity": 0.8},
            {"content": "weather forecast today", "similarity": 0.3},
            {"content": "deep learning networks", "similarity": 0.6},
        ]

        filtered = self.node._filter_enhanced_relevant_memories(memories, "machine learning", [])

        # Should include memories with keyword overlap or high similarity
        assert len(filtered) >= 2
        assert any("machine learning" in m["content"] for m in filtered)
        assert any("deep learning" in m["content"] for m in filtered)

    def test_filter_enhanced_relevant_memories_with_context(self):
        """Test enhanced filtering with conversation context."""
        self.node.similarity_threshold = 0.5

        memories = [
            {"content": "neural network architecture", "similarity": 0.4},
            {"content": "cooking recipes", "similarity": 0.2},
        ]

        context = [{"content": "Tell me about neural networks and architecture"}]

        filtered = self.node._filter_enhanced_relevant_memories(memories, "deep learning", context)

        # Should include first memory due to context overlap
        assert len(filtered) >= 1
        assert "neural network" in filtered[0]["content"]

    def test_filter_by_category_enabled(self):
        """Test category filtering when enabled."""
        self.node.memory_category_filter = "stored"

        memories = [
            {"content": "stored memory", "metadata": {"category": "stored"}},
            {"content": "temporary memory", "metadata": {"category": "temporary"}},
            {
                "content": "direct category",
                "category": "stored",
            },  # This won't be found due to elif logic
        ]

        filtered = self.node._filter_by_category(memories)

        # Only metadata-based categories are found due to elif logic in implementation
        assert len(filtered) == 1
        assert filtered[0]["content"] == "stored memory"

    def test_filter_by_category_direct_field(self):
        """Test category filtering with direct category field (no metadata dict)."""
        self.node.memory_category_filter = "stored"

        memories = [
            {
                "content": "direct stored",
                "category": "stored",
                "metadata": "not_a_dict",
            },  # metadata is not dict
            {
                "content": "direct temp",
                "category": "temporary",
                "metadata": "not_a_dict",
            },  # metadata is not dict
        ]

        filtered = self.node._filter_by_category(memories)

        assert len(filtered) == 1
        assert filtered[0]["content"] == "direct stored"

    def test_filter_by_category_disabled(self):
        """Test category filtering when disabled."""
        self.node.memory_category_filter = None

        memories = [
            {"content": "memory1", "metadata": {"category": "stored"}},
            {"content": "memory2", "metadata": {"category": "temporary"}},
        ]

        filtered = self.node._filter_by_category(memories)

        assert len(filtered) == 2  # Should return all memories

    def test_filter_expired_memories_disabled(self):
        """Test expired memory filtering when disabled."""
        self.node.decay_config = {"enabled": False}

        memories = [
            {"content": "expired memory", "metadata": {"expiry_time": 1000}},
            {"content": "active memory", "metadata": {"expiry_time": time.time() * 1000 + 10000}},
        ]

        with patch("time.time", return_value=2000):
            filtered = self.node._filter_expired_memories(memories)

        assert len(filtered) == 2  # Should return all memories

    def test_filter_expired_memories_with_expiry_time(self):
        """Test expired memory filtering with explicit expiry times."""
        self.node.decay_config = {"enabled": True}

        current_time = time.time() * 1000
        memories = [
            {"content": "expired memory", "metadata": {"expiry_time": current_time - 1000}},
            {"content": "active memory", "metadata": {"expiry_time": current_time + 10000}},
            {"content": "direct expiry", "expiry_time": current_time + 5000},
        ]

        with patch("time.time", return_value=current_time / 1000):
            filtered = self.node._filter_expired_memories(memories)

        assert len(filtered) == 2
        assert all(m["content"] in ["active memory", "direct expiry"] for m in filtered)

    def test_filter_expired_memories_with_decay_rules(self):
        """Test expired memory filtering with decay rules."""
        self.node.decay_config = {
            "enabled": True,
            "short_term_hours": 1.0,
            "long_term_hours": 24.0,
        }

        current_time = time.time() * 1000
        old_time = current_time - 7200 * 1000  # 2 hours ago

        memories = [
            {
                "content": "expired short term",
                "metadata": {"memory_type": "short_term", "created_at": str(old_time / 1000)},
            },
            {
                "content": "active long term",
                "metadata": {"memory_type": "long_term", "created_at": str(old_time / 1000)},
            },
        ]

        with patch("time.time", return_value=current_time / 1000):
            filtered = self.node._filter_expired_memories(memories)

        assert len(filtered) == 1
        assert filtered[0]["content"] == "active long term"


class TestMemoryReaderNodeLegacyMethods:
    """Test legacy compatibility methods."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])

    @pytest.mark.asyncio
    async def test_legacy_keyword_search(self):
        """Test legacy keyword search method."""
        with patch.object(
            self.node,
            "_enhanced_keyword_search",
            return_value=[{"test": "result"}],
        ) as mock_enhanced:
            result = await self.node._keyword_search("namespace", "query")

            mock_enhanced.assert_called_once_with("namespace", "query", [])
            assert result == [{"test": "result"}]

    @pytest.mark.asyncio
    async def test_legacy_vector_search(self):
        """Test legacy vector search method."""
        with patch.object(
            self.node,
            "_context_aware_vector_search",
            return_value=[{"test": "result"}],
        ) as mock_vector:
            result = await self.node._vector_search([0.1, 0.2], "namespace", 0.5)

            mock_vector.assert_called_once_with([0.1, 0.2], "namespace", [], 0.5)
            assert result == [{"test": "result"}]

    @pytest.mark.asyncio
    async def test_legacy_stream_search(self):
        """Test legacy stream search method."""
        with patch.object(
            self.node,
            "_context_aware_stream_search",
            return_value=[{"test": "result"}],
        ) as mock_stream:
            result = await self.node._stream_search("stream_key", "query", [0.1, 0.2], 0.5)

            mock_stream.assert_called_once_with("stream_key", "query", [0.1, 0.2], [], 0.5)
            assert result == [{"test": "result"}]

    def test_legacy_filter_relevant_memories(self):
        """Test legacy filter relevant memories method."""
        with patch.object(
            self.node,
            "_filter_enhanced_relevant_memories",
            return_value=[{"test": "result"}],
        ) as mock_filter:
            result = self.node._filter_relevant_memories([{"memory": "data"}], "query")

            mock_filter.assert_called_once_with([{"memory": "data"}], "query", [])
            assert result == [{"test": "result"}]


class TestMemoryReaderNodeCosineSimilarity:
    """Test cosine similarity calculation."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])

    def test_cosine_similarity_identical_vectors(self):
        """Test cosine similarity with identical vectors."""
        vec1 = [1.0, 2.0, 3.0]
        vec2 = [1.0, 2.0, 3.0]

        similarity = self.node._cosine_similarity(vec1, vec2)

        assert abs(similarity - 1.0) < 1e-10

    def test_cosine_similarity_orthogonal_vectors(self):
        """Test cosine similarity with orthogonal vectors."""
        vec1 = [1.0, 0.0, 0.0]
        vec2 = [0.0, 1.0, 0.0]

        similarity = self.node._cosine_similarity(vec1, vec2)

        assert abs(similarity - 0.0) < 1e-10

    def test_cosine_similarity_opposite_vectors(self):
        """Test cosine similarity with opposite vectors."""
        vec1 = [1.0, 2.0, 3.0]
        vec2 = [-1.0, -2.0, -3.0]

        similarity = self.node._cosine_similarity(vec1, vec2)

        assert abs(similarity - (-1.0)) < 1e-10

    def test_cosine_similarity_zero_vectors(self):
        """Test cosine similarity with zero vectors."""
        vec1 = [0.0, 0.0, 0.0]
        vec2 = [1.0, 2.0, 3.0]

        similarity = self.node._cosine_similarity(vec1, vec2)

        assert similarity == 0.0

    def test_cosine_similarity_numpy_arrays(self):
        """Test cosine similarity with numpy arrays."""
        import numpy as np

        vec1 = np.array([1.0, 2.0, 3.0])
        vec2 = np.array([2.0, 4.0, 6.0])

        similarity = self.node._cosine_similarity(vec1, vec2)

        assert abs(similarity - 1.0) < 1e-10

    def test_cosine_similarity_error_handling(self):
        """Test cosine similarity error handling."""
        # Test with invalid input that causes numpy error
        with patch("numpy.dot", side_effect=Exception("Numpy error")):
            similarity = self.node._cosine_similarity([1, 2, 3], [4, 5, 6])
            assert similarity == 0.0


class TestMemoryReaderNodeAdditionalEdgeCases:
    """Test additional edge cases to reach 100% coverage."""

    def setup_method(self):
        """Set up test fixtures."""
        with patch("orka.memory_logger.create_memory_logger"), patch(
            "orka.utils.embedder.get_embedder",
        ):
            self.node = MemoryReaderNode(node_id="test_node", prompt="test_prompt", queue=[])
            self.node.similarity_threshold = 0.5
            self.node.context_weight = 0.3
            self.node.limit = 5
            self.node.enable_context_search = True
            self.node.enable_temporal_ranking = True

    @pytest.mark.asyncio
    async def test_generate_context_vector_empty_content_only(self):
        """Test context vector generation with only empty content."""
        self.node.embedder = AsyncMock()

        context = [
            {"content": ""},  # Empty content
            {"content": "   "},  # Only whitespace
            {"other": "no content field"},  # No content field
        ]

        result = await self.node._generate_context_vector(context)
        assert result is None  # Should return None for no valid content

    @pytest.mark.asyncio
    async def test_stream_search_empty_content_handling(self):
        """Test stream search with empty content in payload."""
        self.node.redis = AsyncMock()
        self.node.embedder = AsyncMock()

        stream_entries = [
            (
                b"1234567890-0",
                {b"payload": b'{"content": "", "metadata": {}}', b"ts": b"1234567890"},
            ),  # Empty content
            (
                b"1234567891-0",
                {b"payload": b'{"content": "valid content", "metadata": {}}', b"ts": b"1234567891"},
            ),
        ]
        self.node.redis.xrange.return_value = stream_entries
        self.node.embedder.encode.return_value = [0.1, 0.2, 0.3]

        with patch.object(self.node, "_cosine_similarity", return_value=0.8):
            results = await self.node._context_aware_stream_search(
                "test_stream",
                "test query",
                [0.1, 0.2, 0.3],
                [],
                0.5,
            )

        # Should skip empty content and return only valid one
        assert len(results) == 1
        assert results[0]["content"] == "valid content"

    def test_filter_enhanced_relevant_memories_empty_list(self):
        """Test enhanced filtering with empty memories list."""
        result = self.node._filter_enhanced_relevant_memories([], "query", [])
        assert result == []

    def test_filter_enhanced_relevant_memories_no_relevance(self):
        """Test enhanced filtering with no relevant memories."""
        self.node.similarity_threshold = 0.9  # High threshold

        memories = [
            {"content": "completely unrelated content", "similarity": 0.1},
            {"content": "another unrelated item", "similarity": 0.2},
        ]

        result = self.node._filter_enhanced_relevant_memories(memories, "specific query", [])
        assert result == []  # No memories should be relevant

    @pytest.mark.asyncio
    async def test_enhanced_keyword_search_no_namespace_match(self):
        """Test enhanced keyword search with no namespace matches."""
        self.node.redis = AsyncMock()

        # Mock Redis responses with different namespace
        self.node.redis.keys.return_value = [b"orka:mem:test1"]
        self.node.redis.hget.side_effect = [
            b"different_namespace",  # Different namespace
        ]

        results = await self.node._enhanced_keyword_search("target_namespace", "query", [])
        assert results == []

    @pytest.mark.asyncio
    async def test_context_aware_vector_search_no_vector_data(self):
        """Test context-aware vector search with missing vector data."""
        self.node.redis = AsyncMock()

        # Mock Redis responses with no vector data
        self.node.redis.keys.return_value = [b"orka:mem:test1"]
        self.node.redis.hget.side_effect = [
            b"test_namespace",  # namespace
            None,  # No vector data
        ]

        results = await self.node._context_aware_vector_search(
            [0.1, 0.2, 0.3],
            "test_namespace",
            [],
            0.5,
        )
        assert results == []

    def test_apply_hybrid_scoring_no_timestamp(self):
        """Test hybrid scoring with missing timestamp data."""
        memories = [
            {
                "content": "test content",
                "similarity": 0.8,
                "metadata": {},
                # No timestamp or ts field
            },
        ]

        result = self.node._apply_hybrid_scoring(memories, "test query", [])

        assert len(result) == 1
        assert result[0]["recency_factor"] == 1.0  # Should default to 1.0

    def test_apply_hybrid_scoring_invalid_timestamp_format(self):
        """Test hybrid scoring with invalid timestamp format."""
        memories = [
            {
                "content": "test content",
                "similarity": 0.8,
                "metadata": {},
                "timestamp": "not_a_number",
            },
        ]

        result = self.node._apply_hybrid_scoring(memories, "test query", [])

        assert len(result) == 1
        assert result[0]["recency_factor"] == 1.0  # Should fallback to 1.0

    def test_filter_enhanced_relevant_memories_short_query_handling(self):
        """Test enhanced filtering with short query special handling."""
        self.node.similarity_threshold = 0.9  # High threshold

        memories = [
            {"content": "test content here", "similarity": 0.1},  # Low similarity normally
        ]

        # Short query (≤ 20 chars) with word match should be relevant
        result = self.node._filter_enhanced_relevant_memories(memories, "test", [])

        assert len(result) == 1  # Should be included due to short query + word match
        assert result[0]["content"] == "test content here"

    @pytest.mark.asyncio
    async def test_enhanced_keyword_search_metadata_json_error(self):
        """Test enhanced keyword search with JSON parsing error in metadata."""
        self.node.redis = AsyncMock()

        # Mock Redis responses with invalid JSON
        self.node.redis.keys.return_value = [b"orka:mem:test1"]
        self.node.redis.hget.side_effect = [
            b"test_namespace",
            b"test content with keywords",
            b"invalid_json{[",  # Invalid JSON
        ]

        results = await self.node._enhanced_keyword_search("test_namespace", "keywords", [])

        # Should still work, just with empty metadata
        assert len(results) == 1
        assert results[0]["metadata"] == {}

    def test_apply_hybrid_scoring_various_content_lengths(self):
        """Test hybrid scoring with various content lengths to hit all branches."""
        memories = [
            {"content": "tiny", "similarity": 0.8, "metadata": {}},  # < 10 words
            {"content": " ".join(["word"] * 75), "similarity": 0.8, "metadata": {}},  # 50-200 words
            {"content": " ".join(["word"] * 550), "similarity": 0.8, "metadata": {}},  # > 500 words
            {"content": " ".join(["word"] * 25), "similarity": 0.8, "metadata": {}},  # 10-50 words
        ]

        result = self.node._apply_hybrid_scoring(memories, "test query", [])

        assert len(result) == 4
        # Check different length factors are applied
        tiny_memory = next(m for m in result if m["content"] == "tiny")
        sweet_spot_memory = next(m for m in result if len(m["content"].split()) == 75)
        long_memory = next(m for m in result if len(m["content"].split()) == 550)

        assert tiny_memory["length_factor"] == 0.8  # Too short penalty
        assert sweet_spot_memory["length_factor"] == 1.1  # Sweet spot boost
        assert long_memory["length_factor"] == 0.9  # Too long penalty
