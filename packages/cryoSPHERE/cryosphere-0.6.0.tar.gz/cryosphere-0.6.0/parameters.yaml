name: "cryoSPHERE_run" #Name of the experiment. Especially useful for using weight and biases.
wandb: True #Whether to log the training metrics into weight and biases. Note that it is not mandatory to use wand.
wandb_project: "VAECryoEM" #Name of the weight and biases project into which we log the training metrics.
folder_path: "path/to/folder" #path to the folder containing the star file, mrcs files and the base_structure.pdb
base_structure_path: "base_structure.pdb" #Name of the pdb file of the base structure.
image_yaml: "images.yaml" #Name of the yaml file containing the parameters realted to the images.
particles_path: "/path/to/particles" # path to the folder containing the mrcs files. Note that this will be appended to the paths in the star file.
cs_star_file:
        file: "path/to/star_or_cs_file" #Path to the star or cryosparc file of the experiment.
	abinit: True #Whether or not the dataset has been obtained through ab-initio reconstruction. Only needed when reading data preprocessed by cryoSparc. If not specified, it is set as False. You may want to change this value.
	hetrefine: True #Whether or not the dataset has been obtained through heterogeneous refinement. Only needed when reading data preprocessed by cryoSparc. If not specified, it is set to False. You may want to change this value.
segmentation_config: #Definition of the segmentation
	part1: #There is only one segmentation: the entire protein.
		all_protein: True #If all_protein is set to True, there is only one segmentation: the entire protein. If not present or False, the segmentation is local and the chain and start and end residue need to be specified.
		N_segm: 20 #Number of segments.
    segmentation_start:
      type: "uniform" #Starting values of the segmentation: "uniform" means that the means are evenly spanning the range [0, N_residues], the std is set to N_residues/N_segments and proportions are set to one, on average. See source code, model/vae.py to see how it is initialized. Default work well.
    segmentation_prior:
      type: "uniform" #Prior to set on the segmentation. "uniform" means the same as above
lp_bandwidth:   #Bandwith at which we low pass filter the images: all frequencies > 1/lp_bandwidth are set to 0. 
loss_mask_radius: 1 #Radius of the circular mask used to compute the correlation loss, in percentage of half of the side length: 1 mean the circular mask streches to the edges of the image. Remove if not used. 
input_mask_radius: 1 #Radius of the circular mask used on the images before feeding them to the encoder. Defined the same as loss_mask_radius. Remove if not used.
latent_dimension: 8 #Dimension of the latent space. Default work well.
tau_segmentation: 0.05 #The probability of the residues belonging to each segments in the GMM segmentation are annealed by 1/tau_segmentation. Default work well.
device: "GPU" #Device to use. If set to "GPU" torch will try to use the available gpu. Currently only single GPU is supported.
num_workers: 4 #Number of workers for pyTorch. Default work well.
amortized: True #Whether to use amortized inference or not. Default work well. If set to False, no encoder is used.
N_images: #Number of images in the dataset
N_epochs: 300 #Number of epochs to train.
batch_size: 128 #Size a batch. Default work well.
epsilon_kl: 1e-10 #Default work well. epsilon added in the kl divergence to avoid log(0).
seed: null #If set an integer, will set the torch, cuda, python and numpy seeds to that value. 
deterministic_cuda: False #If true, will enforce deterministic cuda behavior.
encoder: 
    hidden_dimensions: [512, 256, 64, 64] #List of the hidden dimensions of the encoder (from left to right)
decoder:
    hidden_dimensions: [512, 512] #Same as above but for the decoder.
optimizer:
  name: "adam" #Name of the optimizer. Currently only adam is supported.
  learning_rate: 0.00003 #Learning rate for the parameters of the encoder and decoder. Default work well.
  learning_rate_segmentation: 0.0003 #Learning rate for the parameters of the segmentation GMM. Default work well. If removed from the file, the same learning rate as the the encoder and decoder is used.
loss:
  clashing_loss:
    full_clashing_loss: True #Whether to use the full clashing loss. Is False, use the lightweight version of this loss. See cryoSPHERE paper.
    clashing_cutoff: 4 #Threshold in Ã… to determine if two residues are clashing or not during the training.
    min_clashing_cutoff_pairs: 4 #Min threshold to use for the lightweight version of the clashing loss.
    max_clashing_cutoff_pairs: 10 #Max threshold to use for the lightweight version of the clashing loss.
    schedule: "constant" #Schedule for the \beta of this loss. "constant" is constant beta. "linear" is linear increasing. "cyclical" is cyclical evolution. Default work well
    beta: 0.1 #Constant beta value.
  continuity_loss: #Hyperparameters related to the continuity loss.
    schedule: "constant" #Same as above. Default work well.
    beta: 0.1 #Same as above. Default work well.
  KL_prior_latent: #Hyperparameters related to the KL prior on the latent variable.
    schedule: "linear" #Same as above. That you may want to change.
  KL_prior_segmentation_mean: #Hyperparameters related to the segmentation GMM.
    schedule: "linear" # Same as above. You may want to change this value.
  KL_prior_segmentation_std: #Hyperparameters related to the KL of the segmentation
    schedule: "linear" #Same as above.
  KL_prior_segmentation_proportions: #Hyperparameters related to the KL segmentation
    schedule: "cyclical" #Cyclical schedule for the beta value: starts at 8, increases linearly to 1 and is then reset to 0.
    M: 5 #Number of cycles during training
    R: 0.5 #Proportion of time spent during a cycle with beta !=1
  l2_pen:  #Hyperparameters related to the l2 penalty
    schedule: "constant"  #Same as above
    beta: 0.000001   #Same as above
resume_training: 
  model: null #If null, training the neural network is initialized. If set to the path to a .pt file of a previous model, resumes training of this model.
  segmentation: null #If null, the segmentation is initialized. If set to the path of the .pt file of a previous segmentation, resumes the training of this segmentation. 
