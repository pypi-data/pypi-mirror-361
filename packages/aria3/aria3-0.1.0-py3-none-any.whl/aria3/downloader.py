"""
å…·æœ‰é«˜çº§åŠŸèƒ½çš„å¤šçº¿ç¨‹ä¸‹è½½ç®¡ç†å™¨ã€‚

æœ¬æ¨¡å—æä¾›äº†ä¸€ä¸ªå…¨é¢çš„ä¸‹è½½å·¥å…·ï¼Œæ”¯æŒï¼š
- å…·æœ‰å¯é…ç½®å—å¤§å°çš„å¤šçº¿ç¨‹ä¸‹è½½
- å…·æœ‰åŠ¨æ€ä¼˜å…ˆçº§çš„å¤šæºURL
- è‡ªå®šä¹‰è¯·æ±‚å¤´å’ŒCookie
- å¯æ¢å¤ä¸‹è½½
- è¿›åº¦è·Ÿè¸ªå’ŒæŠ¥å‘Š
- è‡ªåŠ¨é€Ÿåº¦ç›‘æ§å’Œæºåˆ‡æ¢
"""

import os
import signal
import sys
import time
import threading
import logging
import hashlib
from typing import List, Dict, Optional, Callable, Any, Tuple
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse
import requests
from tqdm import tqdm


@dataclass
class DownloadConfig:
    """ä¸‹è½½æ“ä½œçš„é…ç½®ã€‚"""
    max_chunk_size: int = 1024 * 1024  # é»˜è®¤1MB
    max_threads: int = 4  # æœ€å¤§çº¿ç¨‹æ•°
    timeout: int = 30  # è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    retry_attempts: int = 3  # é‡è¯•æ¬¡æ•°
    retry_delay: float = 1.0  # é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
    speed_threshold: float = 1024  # å­—èŠ‚æ¯ç§’ - ä½äºæ­¤å€¼çš„æºè¢«è®¤ä¸ºæ˜¯æ…¢é€Ÿçš„
    headers: Dict[str, str] = field(default_factory=dict)  # HTTPè¯·æ±‚å¤´
    cookies: Dict[str, str] = field(default_factory=dict)  # HTTP Cookie
    user_agent: str = "aget/1.0 (Multi-threaded downloader)"  # ç”¨æˆ·ä»£ç†å­—ç¬¦ä¸²

    def __post_init__(self):
        """å¦‚æœæœªæä¾›åˆ™è®¾ç½®é»˜è®¤è¯·æ±‚å¤´ã€‚"""
        if 'User-Agent' not in self.headers:
            self.headers['User-Agent'] = self.user_agent


@dataclass
class SourceInfo:
    """ä¸‹è½½æºçš„ä¿¡æ¯ã€‚"""
    url: str  # æºURL
    priority: float = 1.0  # ä¼˜å…ˆçº§
    speed: float = 0.0  # ä¸‹è½½é€Ÿåº¦ï¼ˆå­—èŠ‚/ç§’ï¼‰
    last_speed_check: float = 0.0  # ä¸Šæ¬¡é€Ÿåº¦æ£€æŸ¥æ—¶é—´
    failures: int = 0  # å¤±è´¥æ¬¡æ•°
    active_chunks: int = 0  # æ´»è·ƒå—æ•°é‡
    total_downloaded: int = 0  # æ€»ä¸‹è½½å­—èŠ‚æ•°


@dataclass
class ChunkInfo:
    """ä¸‹è½½å—çš„ä¿¡æ¯ã€‚"""
    start: int  # èµ·å§‹ä½ç½®
    end: int  # ç»“æŸä½ç½®
    source_url: str  # æºURL
    downloaded: int = 0  # å·²ä¸‹è½½å­—èŠ‚æ•°
    completed: bool = False  # æ˜¯å¦å®Œæˆ
    thread_id: Optional[int] = None  # çº¿ç¨‹ID


class DownloadProgress:
    """çº¿ç¨‹å®‰å…¨çš„è¿›åº¦è·Ÿè¸ªã€‚"""

    def __init__(self, total_size: int):
        self.total_size = total_size  # æ€»å¤§å°
        self.downloaded = 0  # å·²ä¸‹è½½å¤§å°
        self.start_time = time.time()  # å¼€å§‹æ—¶é—´
        self.lock = threading.Lock()  # çº¿ç¨‹é”
        self.progress_bar = None  # è¿›åº¦æ¡

    def update(self, bytes_downloaded: int):
        """çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°è¿›åº¦ã€‚"""
        with self.lock:
            self.downloaded += bytes_downloaded
            if self.progress_bar:
                self.progress_bar.update(bytes_downloaded)

    def get_speed(self) -> float:
        """è·å–å½“å‰ä¸‹è½½é€Ÿåº¦ï¼ˆå­—èŠ‚/ç§’ï¼‰ã€‚"""
        with self.lock:
            elapsed = time.time() - self.start_time
            return self.downloaded / elapsed if elapsed > 0 else 0.0

    def get_eta(self) -> float:
        """è·å–é¢„è®¡å®Œæˆæ—¶é—´ï¼ˆç§’ï¼‰ã€‚"""
        speed = self.get_speed()
        if speed > 0:
            remaining = self.total_size - self.downloaded
            return remaining / speed
        return float('inf')

    def get_progress_percent(self) -> float:
        """è·å–è¿›åº¦ç™¾åˆ†æ¯”ã€‚"""
        return (self.downloaded / self.total_size) * 100 if self.total_size > 0 else 0.0


class MultiThreadDownloader:
    """ä¸»è¦çš„å¤šçº¿ç¨‹ä¸‹è½½ç®¡ç†å™¨ã€‚"""

    def __init__(self, config: Optional[DownloadConfig] = None):
        self.config = config or DownloadConfig()  # é…ç½®
        self.logger = self._setup_logger()  # æ—¥å¿—è®°å½•å™¨
        self.sources: List[SourceInfo] = []  # ä¸‹è½½æºåˆ—è¡¨
        self.chunks: List[ChunkInfo] = []  # ä¸‹è½½å—åˆ—è¡¨
        self.progress: Optional[DownloadProgress] = None  # è¿›åº¦è·Ÿè¸ªå™¨
        self.session = requests.Session()  # HTTPä¼šè¯

        # ä¸­æ–­å¤„ç†ç›¸å…³
        self._interrupt_count = 0  # ä¸­æ–­è®¡æ•°
        self._download_cancelled = False  # ä¸‹è½½å–æ¶ˆæ ‡å¿—
        self._original_sigint_handler = None  # åŸå§‹ä¿¡å·å¤„ç†å™¨

        self._setup_session()

    def _setup_logger(self) -> logging.Logger:
        """è®¾ç½®ä¸‹è½½å™¨çš„æ—¥å¿—è®°å½•ã€‚"""
        logger = logging.getLogger('aget.downloader')
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
            logger.setLevel(logging.INFO)
        return logger

    def _setup_session(self):
        """é…ç½®requestsä¼šè¯ã€‚"""
        self.session.headers.update(self.config.headers)
        if self.config.cookies:
            self.session.cookies.update(self.config.cookies)

        # é…ç½®é€‚é…å™¨ä»¥è·å¾—æ›´å¥½çš„è¿æ¥æ± 
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=self.config.max_threads,
            pool_maxsize=self.config.max_threads * 2,
            max_retries=0  # æˆ‘ä»¬æ‰‹åŠ¨å¤„ç†é‡è¯•
        )
        self.session.mount('http://', adapter)
        self.session.mount('https://', adapter)

    def _setup_signal_handlers(self):
        """è®¾ç½®ä¿¡å·å¤„ç†å™¨ä»¥æ”¯æŒä¼˜é›…ä¸­æ–­ã€‚"""
        def signal_handler(signum, frame):
            self._interrupt_count += 1

            if self._interrupt_count == 1:
                print("\nâš ï¸  æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å· (Ctrl+C)")
                print("ğŸ“‹ æ­£åœ¨å°è¯•ä¼˜é›…åœæ­¢ä¸‹è½½...")
                print("ğŸ’¡ å†æ¬¡æŒ‰ Ctrl+C ç«‹å³å¼ºåˆ¶é€€å‡º")
                self._download_cancelled = True

                # ç»™ä¸€äº›æ—¶é—´è®©ä¸‹è½½çº¿ç¨‹æ£€æŸ¥å–æ¶ˆæ ‡å¿—
                threading.Timer(0.5, self._check_graceful_shutdown).start()

            elif self._interrupt_count >= 2:
                print("\nğŸ›‘ å¼ºåˆ¶é€€å‡ºä¸‹è½½")
                self._restore_signal_handlers()
                # å¼ºåˆ¶é€€å‡º
                os._exit(1)

        # ä¿å­˜åŸå§‹å¤„ç†å™¨å¹¶è®¾ç½®æ–°çš„å¤„ç†å™¨
        self._original_sigint_handler = signal.signal(signal.SIGINT, signal_handler)

    def _check_graceful_shutdown(self):
        """æ£€æŸ¥ä¼˜é›…å…³é—­æ˜¯å¦å®Œæˆã€‚"""
        if self._download_cancelled and self._interrupt_count == 1:
            print("â±ï¸  ç­‰å¾…ä¸‹è½½çº¿ç¨‹å®Œæˆå½“å‰å—...")
            print("ğŸ’¡ å¦‚éœ€ç«‹å³é€€å‡ºï¼Œè¯·å†æ¬¡æŒ‰ Ctrl+C")

    def _restore_signal_handlers(self):
        """æ¢å¤åŸå§‹ä¿¡å·å¤„ç†å™¨ã€‚"""
        if self._original_sigint_handler is not None:
            signal.signal(signal.SIGINT, self._original_sigint_handler)
            self._original_sigint_handler = None
    
    def add_source(self, url: str, priority: float = 1.0):
        """æ·»åŠ ä¸‹è½½æºURLã€‚"""
        source = SourceInfo(url=url, priority=priority)
        self.sources.append(source)
        self.logger.info(f"å·²æ·»åŠ æº: {url}ï¼Œä¼˜å…ˆçº§ {priority}")

    def add_sources(self, urls: List[str], priorities: Optional[List[float]] = None):
        """æ·»åŠ å¤šä¸ªä¸‹è½½æºã€‚"""
        if priorities is None:
            priorities = [1.0] * len(urls)

        for url, priority in zip(urls, priorities):
            self.add_source(url, priority)

    def _get_file_info(self, url: str) -> Tuple[int, bool, Optional[str]]:
        """è·å–æ–‡ä»¶å¤§å°ã€èŒƒå›´è¯·æ±‚æ”¯æŒå’Œæ–‡ä»¶åã€‚"""
        file_name = None

        # é¦–å…ˆå°è¯•HEADè¯·æ±‚
        try:
            response = self.session.head(url, timeout=self.config.timeout)
            response.raise_for_status()

            # è·å–æ–‡ä»¶å¤§å°
            content_length = response.headers.get('content-length')
            file_size = int(content_length) if content_length else 0

            # æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦æ”¯æŒèŒƒå›´è¯·æ±‚
            accept_ranges = response.headers.get('accept-ranges', '').lower()
            supports_ranges = accept_ranges == 'bytes'

            # å°è¯•ä»Content-Dispositionè·å–æ–‡ä»¶å
            file_name = self._extract_filename_from_headers(response.headers)

            if file_size > 0:
                self.logger.info(f"æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚ï¼ŒèŒƒå›´æ”¯æŒ: {supports_ranges}")
                if file_name:
                    self.logger.info(f"æ£€æµ‹åˆ°æ–‡ä»¶å: {file_name}")
                return file_size, supports_ranges, file_name

        except Exception as e:
            self.logger.warning(f"HEADè¯·æ±‚å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨GETè¯·æ±‚è·å–æ–‡ä»¶ä¿¡æ¯")

        # å¦‚æœHEADè¯·æ±‚å¤±è´¥æˆ–æ— æ³•è·å–æ–‡ä»¶å¤§å°ï¼Œä½¿ç”¨GETè¯·æ±‚é…åˆRangeå¤´
        try:
            # ä½¿ç”¨Rangeè¯·æ±‚è·å–ç¬¬ä¸€ä¸ªå­—èŠ‚æ¥æµ‹è¯•èŒƒå›´æ”¯æŒå¹¶è·å–æ–‡ä»¶å¤§å°
            headers = self.config.headers.copy()
            headers['Range'] = 'bytes=0-0'

            response = self.session.get(url, headers=headers, timeout=self.config.timeout)

            # å°è¯•ä»å“åº”å¤´è·å–æ–‡ä»¶å
            if not file_name:
                file_name = self._extract_filename_from_headers(response.headers)

            # æ£€æŸ¥æ˜¯å¦è¿”å›206 Partial Content
            if response.status_code == 206:
                # æœåŠ¡å™¨æ”¯æŒèŒƒå›´è¯·æ±‚
                content_range = response.headers.get('content-range', '')
                if content_range:
                    # è§£æContent-Rangeå¤´è·å–æ–‡ä»¶æ€»å¤§å°
                    # æ ¼å¼: "bytes 0-0/1234" æˆ– "bytes 0-0/*"
                    try:
                        file_size = int(content_range.split('/')[-1])
                        supports_ranges = True
                        self.logger.info(f"æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚ï¼ŒèŒƒå›´æ”¯æŒ: {supports_ranges}")
                        if file_name:
                            self.logger.info(f"æ£€æµ‹åˆ°æ–‡ä»¶å: {file_name}")
                        return file_size, supports_ranges, file_name
                    except (ValueError, IndexError):
                        self.logger.warning(f"æ— æ³•è§£æContent-Rangeå¤´: {content_range}")

            # å¦‚æœä¸æ”¯æŒèŒƒå›´è¯·æ±‚æˆ–è§£æå¤±è´¥ï¼Œå°è¯•ä»Content-Lengthè·å–
            response.raise_for_status()
            content_length = response.headers.get('content-length')
            file_size = int(content_length) if content_length else 0

            # å¦‚æœè¿”å›200è€Œä¸æ˜¯206ï¼Œè¯´æ˜ä¸æ”¯æŒèŒƒå›´è¯·æ±‚
            supports_ranges = response.status_code == 206

            if file_size > 0:
                self.logger.info(f"æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚ï¼ŒèŒƒå›´æ”¯æŒ: {supports_ranges}")
                if file_name:
                    self.logger.info(f"æ£€æµ‹åˆ°æ–‡ä»¶å: {file_name}")
                return file_size, supports_ranges, file_name
            else:
                # å¦‚æœä»ç„¶æ— æ³•è·å–æ–‡ä»¶å¤§å°ï¼Œè¿”å›0è¡¨ç¤ºæœªçŸ¥å¤§å°
                self.logger.warning(f"æ— æ³•ç¡®å®šæ–‡ä»¶å¤§å°ï¼Œå°†ä½¿ç”¨å•çº¿ç¨‹ä¸‹è½½")
                return 0, False, file_name

        except Exception as e:
            self.logger.error(f"ä» {url} è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {e}")
            raise

    def _extract_filename_from_headers(self, headers: Dict[str, str]) -> Optional[str]:
        """ä»HTTPå“åº”å¤´ä¸­æå–æ–‡ä»¶åã€‚"""
        # å°è¯•ä»Content-Dispositionå¤´è·å–æ–‡ä»¶å
        content_disposition = headers.get('content-disposition', '')
        if content_disposition:
            try:
                # è§£æContent-Dispositionå¤´
                # æ ¼å¼å¯èƒ½æ˜¯: attachment; filename="file.txt" æˆ– attachment; filename*=UTF-8''file.txt
                if 'filename=' in content_disposition:
                    # æŸ¥æ‰¾filenameå‚æ•°
                    parts = content_disposition.split('filename=')
                    if len(parts) > 1:
                        filename_part = parts[1].strip()

                        # ç§»é™¤å¼•å·
                        if filename_part.startswith('"') and filename_part.endswith('"'):
                            filename_part = filename_part[1:-1]
                        elif filename_part.startswith("'") and filename_part.endswith("'"):
                            filename_part = filename_part[1:-1]

                        # å¤„ç†ç¼–ç é—®é¢˜
                        try:
                            # å°è¯•ISO-8859-1åˆ°UTF-8çš„è½¬æ¢ï¼ˆå¸¸è§çš„HTTPå¤´ç¼–ç é—®é¢˜ï¼‰
                            filename = filename_part.encode('iso-8859-1').decode('utf-8')
                        except (UnicodeEncodeError, UnicodeDecodeError):
                            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹å­—ç¬¦ä¸²
                            filename = filename_part

                        if filename:
                            return filename

            except Exception as e:
                self.logger.debug(f"è§£æContent-Dispositionå¤´å¤±è´¥: {e}")

        return None

    def _suggest_output_path(self, current_path: str, detected_filename: str) -> str:
        """æ ¹æ®æ£€æµ‹åˆ°çš„æ–‡ä»¶åå»ºè®®è¾“å‡ºè·¯å¾„ã€‚"""
        from pathlib import Path

        current_path_obj = Path(current_path)

        # å¦‚æœå½“å‰è·¯å¾„æ²¡æœ‰æ‰©å±•åï¼Œæˆ–è€…æ‰©å±•åæ˜¯é€šç”¨çš„ï¼ˆå¦‚.binï¼‰ï¼Œè€ƒè™‘ä½¿ç”¨æ£€æµ‹åˆ°çš„æ–‡ä»¶å
        current_ext = current_path_obj.suffix.lower()
        detected_ext = Path(detected_filename).suffix.lower()

        # å¦‚æœå½“å‰è·¯å¾„æ²¡æœ‰æ‰©å±•åï¼Œæˆ–è€…æ˜¯é€šç”¨æ‰©å±•åï¼Œå»ºè®®ä½¿ç”¨æ£€æµ‹åˆ°çš„æ–‡ä»¶å
        generic_extensions = {'.bin', '.dat', '.tmp', ''}

        if current_ext in generic_extensions and detected_ext:
            # ä¿æŒç›®å½•ç»“æ„ï¼Œåªæ›¿æ¢æ–‡ä»¶å
            suggested_path = current_path_obj.parent / detected_filename
            return str(suggested_path)

        return current_path

    def _create_chunks(self, file_size: int, supports_ranges: bool) -> List[ChunkInfo]:
        """æ ¹æ®æ–‡ä»¶å¤§å°å’ŒæœåŠ¡å™¨èƒ½åŠ›åˆ›å»ºä¸‹è½½å—ã€‚"""
        if not supports_ranges or file_size <= self.config.max_chunk_size:
            # å•å—ä¸‹è½½
            source_url = self._select_best_source().url
            return [ChunkInfo(start=0, end=file_size-1, source_url=source_url)]

        chunks = []
        chunk_size = min(self.config.max_chunk_size, file_size // self.config.max_threads)

        for i in range(0, file_size, chunk_size):
            start = i
            end = min(i + chunk_size - 1, file_size - 1)
            source_url = self._select_best_source().url
            chunks.append(ChunkInfo(start=start, end=end, source_url=source_url))

        self.logger.info(f"ä¸ºä¸‹è½½åˆ›å»ºäº† {len(chunks)} ä¸ªå—")
        return chunks

    def _select_best_source(self) -> SourceInfo:
        """æ ¹æ®ä¼˜å…ˆçº§å’Œæ€§èƒ½é€‰æ‹©æœ€ä½³æºã€‚"""
        if not self.sources:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„æº")

        # æŒ‰ä¼˜å…ˆçº§ï¼ˆè¶Šé«˜è¶Šå¥½ï¼‰ç„¶åæŒ‰é€Ÿåº¦æ’åº
        available_sources = [s for s in self.sources if s.failures < self.config.retry_attempts]
        if not available_sources:
            # å¦‚æœæ‰€æœ‰æºéƒ½å¤±è´¥äº†ï¼Œé‡ç½®å¤±è´¥è®¡æ•°
            for source in self.sources:
                source.failures = 0
            available_sources = self.sources

        # è®¡ç®—æœ‰æ•ˆä¼˜å…ˆçº§ï¼ˆä¼˜å…ˆçº§ * é€Ÿåº¦å› å­ï¼‰
        for source in available_sources:
            if source.speed > 0:
                speed_factor = min(source.speed / self.config.speed_threshold, 2.0)
            else:
                speed_factor = 1.0
            source.effective_priority = source.priority * speed_factor

        return max(available_sources, key=lambda s: s.effective_priority)

    def _download_chunk(self, chunk: ChunkInfo, output_file: str) -> bool:
        """ä¸‹è½½å•ä¸ªå—ã€‚"""
        # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
        if self._download_cancelled:
            self.logger.info(f"ä¸‹è½½å·²å–æ¶ˆï¼Œè·³è¿‡å— {chunk.start}-{chunk.end}")
            return False

        chunk.thread_id = threading.get_ident()
        source = next((s for s in self.sources if s.url == chunk.source_url), None)

        if not source:
            self.logger.error(f"æœªæ‰¾åˆ°å— {chunk.start}-{chunk.end} çš„æº")
            return False

        headers = self.config.headers.copy()
        if chunk.start > 0 or chunk.end > 0:
            headers['Range'] = f'bytes={chunk.start}-{chunk.end}'

        start_time = time.time()

        for attempt in range(self.config.retry_attempts):
            try:
                response = self.session.get(
                    chunk.source_url,
                    headers=headers,
                    timeout=self.config.timeout,
                    stream=True
                )
                response.raise_for_status()

                # æ›´æ–°æºæ´»è·ƒå—æ•°
                source.active_chunks += 1

                # å†™å…¥å—æ•°æ®
                with open(output_file, 'r+b') as f:
                    f.seek(chunk.start + chunk.downloaded)

                    for data in response.iter_content(chunk_size=8192):
                        # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
                        if self._download_cancelled:
                            self.logger.info(f"ä¸‹è½½å·²å–æ¶ˆï¼Œåœæ­¢å— {chunk.start}-{chunk.end}")
                            source.active_chunks -= 1
                            return False

                        if data:
                            f.write(data)
                            chunk.downloaded += len(data)
                            source.total_downloaded += len(data)
                            self.progress.update(len(data))

                # æ›´æ–°æºé€Ÿåº¦
                elapsed = time.time() - start_time
                if elapsed > 0:
                    source.speed = chunk.downloaded / elapsed
                    source.last_speed_check = time.time()

                chunk.completed = True
                source.active_chunks -= 1

                self.logger.debug(f"ä» {chunk.source_url} å®Œæˆå— {chunk.start}-{chunk.end}")
                return True

            except Exception as e:
                source.failures += 1
                source.active_chunks = max(0, source.active_chunks - 1)
                self.logger.warning(f"å—ä¸‹è½½å¤±è´¥ï¼ˆå°è¯• {attempt + 1}ï¼‰: {e}")

                if attempt < self.config.retry_attempts - 1:
                    time.sleep(self.config.retry_delay * (attempt + 1))
                    # é‡è¯•æ—¶å°è¯•ä¸åŒçš„æº
                    new_source = self._select_best_source()
                    chunk.source_url = new_source.url
                    source = new_source

        return False

    def _monitor_sources(self):
        """ç›‘æ§æºæ€§èƒ½å¹¶è°ƒæ•´ä¼˜å…ˆçº§ã€‚"""
        while not getattr(threading.current_thread(), 'stop_monitoring', False):
            time.sleep(5)  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡

            current_time = time.time()
            for source in self.sources:
                # æ£€æŸ¥æºæ˜¯å¦æ€§èƒ½ä¸ä½³
                if (source.speed > 0 and
                    source.speed < self.config.speed_threshold and
                    current_time - source.last_speed_check < 10):

                    # é™ä½æ…¢é€Ÿæºçš„ä¼˜å…ˆçº§
                    source.priority = max(0.1, source.priority * 0.8)
                    self.logger.info(f"é™ä½æ…¢é€Ÿæº {source.url} çš„ä¼˜å…ˆçº§: {source.priority:.2f}")

                # å¦‚æœæ²¡æœ‰æœ€è¿‘çš„æ´»åŠ¨ï¼Œé‡ç½®é€Ÿåº¦
                if current_time - source.last_speed_check > 30:
                    source.speed = 0.0

    def download(self, output_path: str, progress_callback: Optional[Callable] = None) -> bool:
        """
        ä½¿ç”¨å¤šä¸ªæºå’Œçº¿ç¨‹ä¸‹è½½æ–‡ä»¶ã€‚

        å‚æ•°:
            output_path: æ–‡ä»¶ä¿å­˜è·¯å¾„
            progress_callback: å¯é€‰çš„è¿›åº¦æ›´æ–°å›è°ƒå‡½æ•°

        è¿”å›:
            ä¸‹è½½æˆåŠŸè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        if not self.sources:
            raise ValueError("æœªæŒ‡å®šä¸‹è½½æº")

        # é‡ç½®ä¸­æ–­çŠ¶æ€
        self._interrupt_count = 0
        self._download_cancelled = False

        # è®¾ç½®ä¿¡å·å¤„ç†å™¨
        self._setup_signal_handlers()

        try:
            self.logger.info(f"å¼€å§‹ä¸‹è½½åˆ° {output_path}")
            return self._do_download(output_path, progress_callback)
        finally:
            # æ¢å¤ä¿¡å·å¤„ç†å™¨
            self._restore_signal_handlers()

    def _do_download(self, output_path: str, progress_callback: Optional[Callable] = None) -> bool:
        """æ‰§è¡Œå®é™…çš„ä¸‹è½½è¿‡ç¨‹ã€‚"""

        # ä»ç¬¬ä¸€ä¸ªå·¥ä½œçš„æºè·å–æ–‡ä»¶ä¿¡æ¯
        file_size = 0
        supports_ranges = False
        detected_filename = None

        for source in self.sources:
            try:
                file_size, supports_ranges, detected_filename = self._get_file_info(source.url)
                break
            except Exception as e:
                self.logger.warning(f"ä» {source.url} è·å–ä¿¡æ¯å¤±è´¥: {e}")
                continue

        if file_size == 0:
            self.logger.error("æ— æ³•ä»ä»»ä½•æºç¡®å®šæ–‡ä»¶å¤§å°")
            return False

        # å¦‚æœæ£€æµ‹åˆ°æ–‡ä»¶åï¼Œæä¾›å»ºè®®
        if detected_filename:
            suggested_path = self._suggest_output_path(output_path, detected_filename)
            if suggested_path != output_path:
                self.logger.info(f"æ£€æµ‹åˆ°æ–‡ä»¶å: {detected_filename}")
                self.logger.info(f"å»ºè®®çš„è¾“å‡ºè·¯å¾„: {suggested_path}")
                # æ³¨æ„ï¼šè¿™é‡Œä¸è‡ªåŠ¨æ›´æ”¹è·¯å¾„ï¼Œåªæ˜¯æä¾›ä¿¡æ¯

        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨å¹¶å¤„ç†å¯æ¢å¤ä¸‹è½½
        resume_position = 0
        if os.path.exists(output_path):
            existing_size = os.path.getsize(output_path)
            if existing_size == file_size:
                self.logger.info("æ–‡ä»¶å·²å®Œå…¨ä¸‹è½½")
                return True
            elif existing_size < file_size and supports_ranges:
                resume_position = existing_size
                self.logger.info(f"ä»ä½ç½® {resume_position} æ¢å¤ä¸‹è½½")
            else:
                self.logger.info("ç°æœ‰æ–‡ä»¶å¤§å°ä¸åŒ¹é…ï¼Œå¼€å§‹å…¨æ–°ä¸‹è½½")
                os.remove(output_path)

        # Create empty file or truncate existing one
        if resume_position == 0:
            with open(output_path, 'wb') as f:
                f.seek(file_size - 1)
                f.write(b'\0')

        # Create chunks for remaining download
        remaining_size = file_size - resume_position
        self.chunks = self._create_chunks_for_resume(resume_position, file_size, supports_ranges)

        # Initialize progress tracking
        self.progress = DownloadProgress(remaining_size)
        if progress_callback is None:
            self.progress.progress_bar = tqdm(
                total=remaining_size,
                unit='B',
                unit_scale=True,
                desc="Downloading"
            )

        # Start source monitoring thread
        monitor_thread = threading.Thread(target=self._monitor_sources, daemon=True)
        monitor_thread.start()

        # Download chunks using thread pool
        success = True
        with ThreadPoolExecutor(max_workers=self.config.max_threads) as executor:
            future_to_chunk = {
                executor.submit(self._download_chunk, chunk, output_path): chunk
                for chunk in self.chunks
            }

            for future in as_completed(future_to_chunk):
                # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
                if self._download_cancelled:
                    self.logger.info("ä¸‹è½½å·²å–æ¶ˆï¼Œåœæ­¢ç­‰å¾…å‰©ä½™å—")
                    # å–æ¶ˆæ‰€æœ‰æœªå®Œæˆçš„ä»»åŠ¡
                    for f in future_to_chunk:
                        f.cancel()
                    success = False
                    break

                chunk = future_to_chunk[future]
                try:
                    result = future.result()
                    if not result:
                        self.logger.error(f"Failed to download chunk {chunk.start}-{chunk.end}")
                        success = False
                except Exception as e:
                    self.logger.error(f"Exception in chunk download: {e}")
                    success = False

        # Stop monitoring
        monitor_thread.stop_monitoring = True

        # Close progress bar
        if self.progress.progress_bar:
            self.progress.progress_bar.close()

        if self._download_cancelled:
            print("\nğŸ›‘ ä¸‹è½½å·²è¢«ç”¨æˆ·å–æ¶ˆ")
            self.logger.info("ä¸‹è½½è¢«ç”¨æˆ·å–æ¶ˆ")
            return False
        elif success:
            self.logger.info(f"ä¸‹è½½æˆåŠŸå®Œæˆ: {output_path}")
            self._log_download_stats()
        else:
            self.logger.error("ä¸‹è½½å¤±è´¥")

        return success

    def _create_chunks_for_resume(self, start_pos: int, file_size: int, supports_ranges: bool) -> List[ChunkInfo]:
        """Create chunks for resumable download."""
        if not supports_ranges or (file_size - start_pos) <= self.config.max_chunk_size:
            source_url = self._select_best_source().url
            return [ChunkInfo(start=start_pos, end=file_size-1, source_url=source_url)]

        chunks = []
        remaining_size = file_size - start_pos
        chunk_size = min(self.config.max_chunk_size, remaining_size // self.config.max_threads)

        for i in range(start_pos, file_size, chunk_size):
            start = i
            end = min(i + chunk_size - 1, file_size - 1)
            source_url = self._select_best_source().url
            chunks.append(ChunkInfo(start=start, end=end, source_url=source_url))

        return chunks

    def _log_download_stats(self):
        """è®°å½•ä¸‹è½½ç»Ÿè®¡ä¿¡æ¯ã€‚"""
        total_time = time.time() - self.progress.start_time
        avg_speed = self.progress.downloaded / total_time if total_time > 0 else 0

        self.logger.info(f"ä¸‹è½½ç»Ÿè®¡:")
        self.logger.info(f"  æ€»æ—¶é—´: {total_time:.2f} ç§’")
        self.logger.info(f"  å¹³å‡é€Ÿåº¦: {avg_speed/1024/1024:.2f} MB/s")
        self.logger.info(f"  æ€»ä¸‹è½½é‡: {self.progress.downloaded/1024/1024:.2f} MB")

        for i, source in enumerate(self.sources):
            self.logger.info(f"  æº {i+1} ({source.url}): {source.total_downloaded/1024/1024:.2f} MB")

    def get_download_info(self) -> Dict[str, Any]:
        """è·å–å½“å‰ä¸‹è½½ä¿¡æ¯ã€‚"""
        if not self.progress:
            return {}

        return {
            'total_size': self.progress.total_size,
            'downloaded': self.progress.downloaded,
            'progress_percent': self.progress.get_progress_percent(),
            'speed': self.progress.get_speed(),
            'eta': self.progress.get_eta(),
            'sources': [
                {
                    'url': source.url,
                    'priority': source.priority,
                    'speed': source.speed,
                    'downloaded': source.total_downloaded,
                    'failures': source.failures
                }
                for source in self.sources
            ]
        }


def download_file(urls: List[str], output_path: str, config: Optional[DownloadConfig] = None,
                 priorities: Optional[List[float]] = None) -> bool:
    """
    ä»å¤šä¸ªæºä¸‹è½½æ–‡ä»¶çš„ä¾¿åˆ©å‡½æ•°ã€‚

    å‚æ•°:
        urls: æºURLåˆ—è¡¨
        output_path: æ–‡ä»¶ä¿å­˜è·¯å¾„
        config: ä¸‹è½½é…ç½®ï¼ˆå¯é€‰ï¼‰
        priorities: æ¯ä¸ªURLçš„ä¼˜å…ˆçº§ï¼ˆå¯é€‰ï¼‰

    è¿”å›:
        ä¸‹è½½æˆåŠŸè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    downloader = MultiThreadDownloader(config)
    downloader.add_sources(urls, priorities)
    return downloader.download(output_path)
