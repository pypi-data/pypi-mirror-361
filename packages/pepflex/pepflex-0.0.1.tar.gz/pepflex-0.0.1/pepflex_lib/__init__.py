# -*- coding: utf-8 -*-
"""PepFlex.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HRHS1493dWycooMW3VMXTubXRewWnDFs

# ---------------- PepFlex ----------------
"""

!pip install rdkit

"""
PepFlex: A modular framework for peptide screening and evolution.

This module provides classes and functions for managing amino acid data,
assembling peptides, applying mutations and crossovers, and processing
evolutionary rounds with a flexible pipeline and evaluation system.
"""

import os
import pandas as pd
import numpy as np
import random
import uuid
import json
import copy
from datetime import datetime
from typing import List, Tuple, Dict, Callable, Optional, Union

try:
    from rdkit import Chem
    from rdkit.Chem import AllChem
    from rdkit.Chem import rdmolops
    from rdkit.Chem import Descriptors
except ImportError:
    print("RDKit is not installed. Please install it to use chemical functionalities.")
    Chem = None
    AllChem = None
    rdmolops = None
    Descriptors = None


# --- Global Amino Acid Data ---
# This DataFrame stores information about amino acids, indexed by their 3-letter code.
# It can be extended with non-canonical or modified amino acids.
AMINO_ACID_DF = pd.DataFrame([
    {"1L": "A", "3L": "Ala", "SMILES": "N[C@@H](C)C(=O)O"},
    {"1L": "R", "3L": "Arg", "SMILES": "N[C@@H](CCCNC(=N)N)C(=O)O"},
    {"1L": "N", "3L": "Asn", "SMILES": "N[C@@H](CC(=O)N)C(=O)O"},
    {"1L": "D", "3L": "Asp", "SMILES": "N[C@@H](CC(=O)O)C(=O)O"},
    {"1L": "C", "3L": "Cys", "SMILES": "N[C@@H](CS)C(=O)O"},
    {"1L": "Q", "3L": "Gln", "SMILES": "N[C@@H](CCC(=O)N)C(=O)O"},
    {"1L": "E", "3L": "Glu", "SMILES": "N[C@@H](CCC(=O)O)C(=O)O"},
    {"1L": "G", "3L": "Gly", "SMILES": "NCC(=O)O"},
    {"1L": "H", "3L": "His", "SMILES": "N[C@@H](CC1=CNC=N1)C(=O)O"},
    {"1L": "I", "3L": "Ile", "SMILES": "N[C@@H](C(C)CC)C(=O)O"},
    {"1L": "L", "3L": "Leu", "SMILES": "N[C@@H](CC(C)C)C(=O)O"},
    {"1L": "K", "3L": "Lys", "SMILES": "N[C@@H](CCCCN)C(=O)O"},
    {"1L": "M", "3L": "Met", "SMILES": "N[C@@H](CCSC)C(=O)O"},
    {"1L": "F", "3L": "Phe", "SMILES": "N[C@@H](CC1=CC=CC=C1)C(=O)O"},
    {"1L": "P", "3L": "Pro", "SMILES": "N1CCC[C@H]1C(=O)O"},
    {"1L": "S", "3L": "Ser", "SMILES": "N[C@@H](CO)C(=O)O"},
    {"1L": "T", "3L": "Thr", "SMILES": "N[C@@H](C(C)O)C(=O)O"},
    {"1L": "W", "3L": "Trp", "SMILES": "N[C@@H](CC1=CNC2=CC=CC=C21)C(=O)O"},
    {"1L": "Y", "3L": "Tyr", "SMILES": "N[C@@H](CC1=CC=C(O)C=C1)C(=O)O"},
    {"1L": "V", "3L": "Val", "SMILES": "N[C@@H](C(C)C)C(=O)O"},
])
AMINO_ACID_DF.set_index("3L", inplace=True)
AMINO_ACID_DF['SMILES_Canon'] = AMINO_ACID_DF['SMILES'].apply(lambda s: _canonicalize_smiles(s) if Chem else "")


def _canonicalize_smiles(smiles: str) -> str:
    """
    Converts a SMILES string to its canonical RDKit form for reliable comparison.
    Returns an empty string if the SMILES is not valid or RDKit is not available.

    Args:
        smiles (str): The SMILES string to canonicalize.

    Returns:
        str: The canonical SMILES string, or an empty string if invalid/RDKit not found.
    """
    if Chem is None:
        return ""
    try:
        mol = Chem.MolFromSmiles(smiles)
        if mol:
            return Chem.MolToSmiles(mol, canonical=True)
        return ""
    except Exception:
        return ""

def add_amino_acid(three_letter_code: str, one_letter_code: str, smiles: str):
    """
    Adds or updates an amino acid (canonical, non-canonical, or modified)
    in the global amino acid DataFrame, using the 3-letter code as the primary key.

    Args:
        three_letter_code (str): The 3-letter code for the amino acid (e.g., "Ala", "Cys").
        one_letter_code (str): The 1-letter code for the amino acid (e.g., "A", "C").
        smiles (str): The SMILES string representation of the amino acid.
    """
    global AMINO_ACID_DF
    canonical_smiles = _canonicalize_smiles(smiles)
    if not canonical_smiles and smiles != "InvalidSMILES":
        print(f"Error: Provided SMILES for '{three_letter_code}' is invalid: {smiles}")
        return

    new_data = {
        "1L": one_letter_code,
        "SMILES": smiles,
        "SMILES_Canon": canonical_smiles
    }

    if three_letter_code in AMINO_ACID_DF.index:
        print(f"Warning: Code '{three_letter_code}' already exists. Updating information.")
        AMINO_ACID_DF.loc[three_letter_code] = new_data
    else:
        AMINO_ACID_DF.loc[three_letter_code] = new_data
    print(f"Amino acid '{three_letter_code}' added/updated successfully.")

def get_smiles_from_3L(three_letter_code: str) -> str:
    """
    Retrieves the original SMILES for a given 3-letter code.

    Args:
        three_letter_code (str): The 3-letter code of the amino acid.

    Returns:
        str: The SMILES string.

    Raises:
        ValueError: If the 3-letter code is not found.
    """
    if three_letter_code in AMINO_ACID_DF.index:
        return AMINO_ACID_DF.loc[three_letter_code, "SMILES"]
    raise ValueError(f"3-letter code '{three_letter_code}' not found in the dictionary.")

def get_1L_from_3L(three_letter_code: str) -> str:
    """
    Retrieves the 1-letter code for a given 3-letter code.

    Args:
        three_letter_code (str): The 3-letter code of the amino acid.

    Returns:
        str: The 1-letter code.

    Raises:
        ValueError: If the 3-letter code is not found.
    """
    if three_letter_code in AMINO_ACID_DF.index:
        return AMINO_ACID_DF.loc[three_letter_code, "1L"]
    raise ValueError(f"3-letter code '{three_letter_code}' not found in the dictionary.")

def get_smiles_from_1L(one_letter_code: str) -> str:
    """
    Retrieves the SMILES for a given 1-letter code.

    Args:
        one_letter_code (str): The 1-letter code of the amino acid.

    Returns:
        str: The SMILES string.

    Raises:
        ValueError: If the 1-letter code is not found.
    """
    result = AMINO_ACID_DF[AMINO_ACID_DF['1L'] == one_letter_code]
    if not result.empty:
        if len(result) > 1:
            print(f"Warning: Multiple matches found for 1L code '{one_letter_code}'. Returning the first one.")
        return result.iloc[0]["SMILES"]
    raise ValueError(f"1-letter code '{one_letter_code}' not found in the dictionary.")

def get_3L_from_1L(one_letter_code: str) -> str:
    """
    Retrieves the 3-letter code for a given 1-letter code.

    Args:
        one_letter_code (str): The 1-letter code of the amino acid.

    Returns:
        str: The 3-letter code.

    Raises:
        ValueError: If the 1-letter code is not found.
    """
    result = AMINO_ACID_DF[AMINO_ACID_DF['1L'] == one_letter_code]
    if not result.empty:
        if len(result) > 1:
            print(f"Warning: Multiple matches found for 1L code '{one_letter_code}'. Returning the first one.")
        return result.index[0]
    raise ValueError(f"1-letter code '{one_letter_code}' not found in the dictionary.")

def get_1L_from_smiles(smiles: str) -> str:
    """
    Retrieves the 1-letter code for a given SMILES (using the canonical form).

    Args:
        smiles (str): The SMILES string of the amino acid.

    Returns:
        str: The 1-letter code.

    Raises:
        ValueError: If the SMILES is invalid or not found.
    """
    canonical_smiles_input = _canonicalize_smiles(smiles)
    if not canonical_smiles_input:
        raise ValueError(f"The provided SMILES is invalid: {smiles}")

    result = AMINO_ACID_DF[AMINO_ACID_DF['SMILES_Canon'] == canonical_smiles_input]
    if not result.empty:
        if len(result) > 1:
            print(f"Warning: Multiple matches found for SMILES '{smiles}'. Returning the first one.")
        return result.iloc[0]["1L"]
    raise ValueError(f"SMILES '{smiles}' not found in the dictionary (or its canonical form).")

def get_3L_from_smiles(smiles: str) -> str:
    """
    Retrieves the 3-letter code for a given SMILES (using the canonical form).

    Args:
        smiles (str): The SMILES string of the amino acid.

    Returns:
        str: The 3-letter code.

    Raises:
        ValueError: If the SMILES is invalid or not found.
    """
    canonical_smiles_input = _canonicalize_smiles(smiles)
    if not canonical_smiles_input:
        raise ValueError(f"The provided SMILES is invalid: {smiles}")

    result = AMINO_ACID_DF[AMINO_ACID_DF['SMILES_Canon'] == canonical_smiles_input]
    if not result.empty:
        if len(result) > 1:
            print(f"Warning: Multiple matches found for SMILES '{smiles}'. Returning the first one.")
        return result.index[0]
    raise ValueError(f"SMILES '{smiles}' not found in the dictionary (or its canonical form).")

def save_amino_acid_data(file_path: str, file_format: str = 'csv'):
    """
    Saves the global amino acid DataFrame to a file.

    Args:
        file_path (str): The path to save the file.
        file_format (str): The format to save the file ('csv' or 'parquet'). Defaults to 'csv'.
    """
    try:
        df_to_save = AMINO_ACID_DF[['1L', 'SMILES']].reset_index()
        df_to_save = df_to_save[['3L', '1L', 'SMILES']]

        if file_format.lower() == 'csv':
            df_to_save.to_csv(file_path, index=False)
            print(f"DataFrame successfully saved in CSV format: {file_path}")
        elif file_format.lower() == 'parquet':
            df_to_save.to_parquet(file_path, index=False)
            print(f"DataFrame successfully saved in Parquet format: {file_path}")
        else:
            print(f"Unsupported file format '{file_format}'. Please use 'csv' or 'parquet'.")
    except Exception as e:
        print(f"Error saving DataFrame: {e}")

def load_amino_acid_data(file_path: str, file_format: str = 'csv', overwrite: bool = True):
    """
    Loads an amino acid DataFrame from a file and updates the global AMINO_ACID_DF.

    Args:
        file_path (str): The path to the file to load.
        file_format (str): The format of the file ('csv' or 'parquet'). Defaults to 'csv'.
        overwrite (bool): If True, overwrites the global DataFrame. If False, merges.
    """
    global AMINO_ACID_DF
    try:
        loaded_df = None
        if file_format.lower() == 'csv':
            loaded_df = pd.read_csv(file_path, index_col='3L')
        elif file_format.lower() == 'parquet':
            loaded_df = pd.read_parquet(file_path)
            if '3L' in loaded_df.columns:
                loaded_df.set_index('3L', inplace=True)
            else:
                raise ValueError("Column '3L' not found in Parquet file for indexing.")
        else:
            print(f"Unsupported file format '{file_format}'. Please use 'csv' or 'parquet'.")
            return

        loaded_df['SMILES_Canon'] = loaded_df['SMILES'].apply(_canonicalize_smiles)
        if (loaded_df['SMILES_Canon'] == "").any():
             print("Warning: Some SMILES in the loaded file are invalid and have not been canonicalized.")

        if overwrite:
            AMINO_ACID_DF = loaded_df
            print(f"DataFrame successfully loaded and overwritten from: {file_path}")
        else:
            combined_df = pd.concat([AMINO_ACID_DF, loaded_df])
            AMINO_ACID_DF = combined_df[~combined_df.index.duplicated(keep='last')]
            print(f"DataFrame successfully loaded and merged from: {file_path}")

    except FileNotFoundError:
        print(f"Error: File '{file_path}' not found.")
    except Exception as e:
        print(f"Error loading DataFrame: {e}")


def assemble_peptide(residue_list: Union[List[str], str], input_type: int = 0) -> Optional[Chem.Mol]:
    """
    Assembles a peptide from a list of amino acid SMILES (N to C order) or a 3-letter code string.
    Each SMILES must have free N and C termini: N[C@@H](R)C(=O)O.

    Args:
        residue_list (Union[List[str], str]): A list of SMILES strings or a string of 3-letter codes
                                              separated by hyphens (e.g., "Ala-Glu-Asp-Gly").
        input_type (int): 0 for SMILES list (default), 1 for 3-letter code string.

    Returns:
        Optional[Chem.Mol]: An RDKit Mol object representing the assembled peptide, or None if input is empty.

    Raises:
        ValueError: If RDKit is not installed, SMILES cannot be parsed, or 3-letter code is not found.
        RuntimeError: If peptide bond formation fails.
    """
    if Chem is None:
        raise ValueError("RDKit is not installed. Cannot assemble peptide.")
    if not residue_list:
        return None

    if input_type == 1:
        if not isinstance(residue_list, str):
            raise TypeError("For input_type=1, residue_list must be a string of 3-letter codes.")
        three_letter_codes = residue_list.split("-")
        residue_smiles_list = [get_smiles_from_3L(aa_code) for aa_code in three_letter_codes]
    elif input_type == 0:
        if not isinstance(residue_list, list):
            raise TypeError("For input_type=0, residue_list must be a list of SMILES strings.")
        residue_smiles_list = residue_list
    else:
        raise ValueError("Invalid input_type. Must be 0 (SMILES list) or 1 (3-letter code string).")

    peptide_bond_reaction = AllChem.ReactionFromSmarts(
        '[C:1](=O)[OH].[N:2]>>[C:1](=O)[N:2]'
    )

    mols = []
    for i, smi in enumerate(residue_smiles_list):
        mol = Chem.MolFromSmiles(smi)
        if mol is None:
            raise ValueError(f"Could not parse SMILES for residue {i+1}: {smi}")
        Chem.SanitizeMol(mol)
        mols.append(mol)

    peptide_mol = mols[0]

    for i in range(1, len(mols)):
        current_amino_acid = mols[i]
        products = peptide_bond_reaction.RunReactants((peptide_mol, current_amino_acid))

        if not products or not products[0]:
            raise RuntimeError(
                f"Peptide bond formation failed between residue {i} (0-indexed) and {i+1}. "
                f"SMILES of peptide_mol: {Chem.MolToSmiles(peptide_mol)} "
                f"SMILES of current_amino_acid: {Chem.MolToSmiles(current_amino_acid)}"
            )
        new_peptide_mol = products[0][0]
        Chem.SanitizeMol(new_peptide_mol)
        peptide_mol = new_peptide_mol

    Chem.SanitizeMol(peptide_mol)
    return peptide_mol

def convert_1L_to_smiles_list(one_letter_str: str) -> List[str]:
    """
    Converts a 1-letter amino acid string to a list of corresponding SMILES strings.

    Args:
        one_letter_str (str): A string of 1-letter amino acid codes (e.g., "AEDG").

    Returns:
        List[str]: A list of SMILES strings.
    """
    return [get_smiles_from_1L(letter) for letter in one_letter_str]

def convert_smiles_list_to_3L(smiles_list: List[str]) -> str:
    """
    Converts a list of SMILES strings to a hyphen-separated 3-letter amino acid string.

    Args:
        smiles_list (List[str]): A list of SMILES strings.

    Returns:
        str: A string of 3-letter amino acid codes (e.g., "Ala-Glu-Asp-Gly").
"""
    return "-".join([get_3L_from_smiles(smi) for smi in smiles_list])

def convert_1L_str_to_3L(one_letter_str: str) -> str:
    """
    Converts a 1-letter amino acid string to a hyphen-separated 3-letter amino acid string.
    Note: This will only work for canonical amino acids present in the global DataFrame.

    Args:
        one_letter_str (str): A string of 1-letter amino acid codes (e.g., "AEDG").

    Returns:
        str: A string of 3-letter amino acid codes (e.g., "Ala-Glu-Asp-Gly").
    """
    return convert_smiles_list_to_3L(convert_1L_to_smiles_list(one_letter_str))

def convert_3L_str_to_1L(three_letter_str: str) -> str:
    """
    Converts a hyphen-separated 3-letter amino acid string to a 1-letter amino acid string.
    Note: This will only work for canonical amino acids present in the global DataFrame.

    Args:
        three_letter_str (str): A string of 3-letter amino acid codes (e.g., "Ala-Glu-Asp-Gly").

    Returns:
        str: A string of 1-letter amino acid codes (e.g., "AEDG").
    """
    return "".join([get_1L_from_3L(aa_code) for aa_code in three_letter_str.split("-")])

def convert_smiles_list_to_1L(smiles_list: List[str]) -> str:
    """
    Converts a list of SMILES strings to a 1-letter amino acid string.
    Note: This will only work for canonical amino acids present in the global DataFrame.

    Args:
        smiles_list (List[str]): A list of SMILES strings.

    Returns:
        str: A string of 1-letter amino acid codes (e.g., "AEDG").
    """
    return "".join([get_1L_from_smiles(smi) for smi in smiles_list])


def peptide_crossover(parent1_smiles: List[str], parent2_smiles: List[str]) -> Tuple[List[str], List[str]]:
    """
    Performs a single-point crossover operation between two parent peptides.
    The cut-off point is determined as the middle of each peptide.
    If a peptide has an odd length, a random choice is made whether the cut
    occurs just before or just after the central amino acid.
    The resulting segments are then exchanged to form two child peptides.

    Args:
        parent1_smiles (List[str]): The SMILES sequence of the first parent peptide.
        parent2_smiles (List[str]): The SMILES sequence of the second parent peptide.

    Returns:
        Tuple[List[str], List[str]]: A tuple containing the SMILES sequences of the two child peptides
                                     resulting from the crossover.
                                     Handles cases where peptides are empty or very short.
    """
    len1 = len(parent1_smiles)
    len2 = len(parent2_smiles)

    if len1 == 0 and len2 == 0:
        return ([], [])
    elif len1 == 0:
        return (list(parent2_smiles), [])
    elif len2 == 0:
        return (list(parent1_smiles), [])

    cut_point1 = len1 // 2 + random.choice([0, 1]) if len1 % 2 != 0 else len1 // 2
    cut_point2 = len2 // 2 + random.choice([0, 1]) if len2 % 2 != 0 else len2 // 2

    child1_smiles = parent1_smiles[:cut_point1] + parent2_smiles[cut_point2:]
    child2_smiles = parent2_smiles[:cut_point2] + parent1_smiles[cut_point1:]

    return (child1_smiles, child2_smiles)


class PeptideMutator:
    """
    Manages and applies various mutation rules to peptide SMILES sequences.
    Supports predefined mutation types and custom user-defined mutation functions.
    """
    def __init__(self):
        self.mutation_rules = []
        self.default_aa_df = AMINO_ACID_DF

    def add_mutation_rule(self, mutation_type: Union[str, Callable], probability: float, **kwargs):
        """
        Adds a mutation rule to the mutator.

        Args:
            mutation_type (Union[str, Callable]): The type of mutation. Can be a string for
                                                   predefined rules (e.g., 'n_terminal_addition')
                                                   or a callable function for custom rules.
                                                   Custom functions should accept `smiles_list: List[str]`
                                                   as the first argument and `**kwargs` for additional parameters,
                                                   returning a `List[str]`.
            probability (float): The probability (0.0 to 1.0) of applying this rule.
            **kwargs: Additional parameters specific to the mutation rule. For predefined rules,
                      these might include 'allowed_amino_acids_df', 'source_amino_acids_df',
                      'target_amino_acids_df', 'min_length', 'max_length'. For custom rules,
                      these will be passed directly to your callable function.

        Raises:
            ValueError: If probability is out of range or mutation type is unknown.
            TypeError: If DataFrame parameters are not pandas.DataFrame.
        """
        if not (0.0 <= probability <= 1.0):
            raise ValueError("Probability must be between 0.0 and 1.0.")

        if isinstance(mutation_type, str):
            supported_types = [
                'intra_sequence_suppression', 'n_terminal_suppression', 'c_terminal_suppression',
                'n_terminal_addition', 'c_terminal_addition', 'intra_sequence_addition',
                'inter_mutation', 'n_terminal_mutation', 'c_terminal_mutation',
                'segment_duplication', 'segment_inversion', 'segment_translocation'
            ]
            if mutation_type not in supported_types:
                raise ValueError(f"Unknown mutation type: {mutation_type}. Supported types: {supported_types} or a callable function.")
            for key in ['allowed_amino_acids_df', 'source_amino_acids_df', 'target_amino_acids_df']:
                if key in kwargs:
                    if not isinstance(kwargs[key], pd.DataFrame):
                        raise TypeError(f"Parameter '{key}' must be a pandas.DataFrame.")
                    if not all(col in kwargs[key].columns for col in ['SMILES', 'SMILES_Canon']):
                        raise ValueError(f"The DataFrame provided for '{key}' must contain 'SMILES' and 'SMILES_Canon' columns.")
                    if '3L' not in kwargs[key].index.names:
                         raise ValueError(f"The DataFrame provided for '{key}' must have '3L' as index.")
        elif not callable(mutation_type):
            raise TypeError("mutation_type must be a string (predefined rule) or a callable function (custom rule).")

        self.mutation_rules.append({
            'type': mutation_type,
            'probability': probability,
            'params': kwargs
        })
        rule_name = mutation_type.__name__ if callable(mutation_type) else mutation_type
        print(f"Rule '{rule_name}' added (probability: {probability}).")

    def _get_eligible_smiles_pool(self, params: dict, param_key: str) -> list:
        """Helper to get canonical SMILES from a specified DataFrame or default."""
        if param_key in params and isinstance(params[param_key], pd.DataFrame):
            eligible_df = params[param_key]
        else:
            eligible_df = self.default_aa_df
        return eligible_df['SMILES_Canon'].tolist()

    def _get_random_target_smiles(self, params: dict, param_key: str) -> str:
        """Helper to get a random SMILES from a specified DataFrame or default."""
        if param_key in params and isinstance(params[param_key], pd.DataFrame):
            target_df = params[param_key]
        else:
            target_df = self.default_aa_df
        if target_df.empty:
            raise ValueError("No target amino acid available in the specified or default DataFrame.")
        return random.choice(target_df['SMILES'].tolist())

    def _apply_intra_sequence_suppression(self, smiles_list: list, params: dict) -> list:
        """Applies intra-sequence amino acid suppression."""
        if not smiles_list or len(smiles_list) <= 1:
            print("  -> Sequence too short for intra-sequence suppression.")
            return smiles_list
        allowed_smiles_canon_pool = self._get_eligible_smiles_pool(params, 'allowed_amino_acids_df')
        eligible_indices = [i for i, smi in enumerate(smiles_list) if _canonicalize_smiles(smi) in allowed_smiles_canon_pool]
        if not eligible_indices:
            print("  -> No eligible amino acid for intra-sequence suppression according to criteria.")
            return smiles_list
        idx_to_remove = random.choice(eligible_indices)
        removed_smiles = smiles_list[idx_to_remove]
        try:
            removed_3L = get_3L_from_smiles(removed_smiles)
            print(f"  -> Intra-sequence suppression of '{removed_3L}' at index {idx_to_remove}.")
        except ValueError:
            print(f"  -> Intra-sequence suppression of an unrecognized SMILES at index {idx_to_remove}: {removed_smiles}.")
        return smiles_list[:idx_to_remove] + smiles_list[idx_to_remove+1:]

    def _apply_terminal_suppression(self, smiles_list: list, params: dict, terminal: str) -> list:
        """Applies N-terminal or C-terminal amino acid suppression."""
        if not smiles_list:
            print(f"  -> Empty sequence for {terminal}-terminal suppression.")
            return smiles_list
        target_smiles = smiles_list[0] if terminal == 'N' else smiles_list[-1]
        allowed_smiles_canon_pool = self._get_eligible_smiles_pool(params, 'allowed_amino_acids_df')
        try:
            if _canonicalize_smiles(target_smiles) not in allowed_smiles_canon_pool:
                current_3L = get_3L_from_smiles(target_smiles)
                print(f"  -> The {terminal}-terminal AA '{current_3L}' is not eligible for suppression according to criteria.")
                return smiles_list
        except ValueError:
            print(f"  -> The {terminal}-terminal AA ({target_smiles}) is not eligible for suppression (unrecognized or unauthorized).")
            return smiles_list
        try:
            removed_3L = get_3L_from_smiles(target_smiles)
            print(f"  -> {terminal}-terminal suppression of '{removed_3L}'.")
        except ValueError:
            print(f"  -> {terminal}-terminal suppression of an unrecognized SMILES: {target_smiles}.")
        return smiles_list[1:] if terminal == 'N' else smiles_list[:-1]

    def _apply_n_terminal_addition(self, smiles_list: list, params: dict) -> list:
        """Applies N-terminal amino acid addition."""
        new_aa_smiles = self._get_random_target_smiles(params, 'target_amino_acids_df')
        try:
            new_aa_3L = get_3L_from_smiles(new_aa_smiles)
            print(f"  -> N-terminal addition of '{new_aa_3L}'.")
        except ValueError:
            print(f"  -> N-terminal addition of an unrecognized SMILES: {new_aa_smiles}.")
        return [new_aa_smiles] + smiles_list

    def _apply_c_terminal_addition(self, smiles_list: list, params: dict) -> list:
        """Applies C-terminal amino acid addition."""
        new_aa_smiles = self._get_random_target_smiles(params, 'target_amino_acids_df')
        try:
            new_aa_3L = get_3L_from_smiles(new_aa_smiles)
            print(f"  -> C-terminal addition of '{new_aa_3L}'.")
        except ValueError:
            print(f"  -> C-terminal addition of an unrecognized SMILES: {new_aa_smiles}.")
        return smiles_list + [new_aa_smiles]

    def _apply_intra_sequence_addition(self, smiles_list: list, params: dict) -> list:
        """Applies intra-sequence amino acid addition."""
        insertion_idx = random.randint(0, len(smiles_list)) if smiles_list else 0
        new_aa_smiles = self._get_random_target_smiles(params, 'target_amino_acids_df')
        try:
            new_aa_3L = get_3L_from_smiles(new_aa_smiles)
            print(f"  -> Intra-sequence addition of '{new_aa_3L}' at index {insertion_idx}.")
        except ValueError:
            print(f"  -> Intra-sequence addition of an unrecognized SMILES at index {insertion_idx}: {new_aa_smiles}.")
        mutated_list = list(smiles_list)
        mutated_list.insert(insertion_idx, new_aa_smiles)
        return mutated_list

    def _apply_inter_mutation(self, smiles_list: list, params: dict) -> list:
        """Applies inter-sequence amino acid mutation (substitution)."""
        if not smiles_list:
            print("  -> Empty sequence for inter-sequence mutation.")
            return smiles_list
        source_smiles_canon_pool = self._get_eligible_smiles_pool(params, 'source_amino_acids_df')
        eligible_indices = [i for i, smi in enumerate(smiles_list) if _canonicalize_smiles(smi) in source_smiles_canon_pool]
        if not eligible_indices:
            print("  -> No eligible amino acid for inter-sequence mutation according to source criteria.")
            return smiles_list
        idx_to_mutate = random.choice(eligible_indices)
        original_smiles = smiles_list[idx_to_mutate]
        new_aa_smiles = self._get_random_target_smiles(params, 'target_amino_acids_df')
        try:
            original_3L = get_3L_from_smiles(original_smiles)
            new_aa_3L = get_3L_from_smiles(new_aa_smiles)
            print(f"  -> Inter-sequence mutation from '{original_3L}' to '{new_aa_3L}' at index {idx_to_mutate}.")
        except ValueError:
            print(f"  -> Inter-sequence mutation at index {idx_to_mutate} from {original_smiles} to {new_aa_smiles}.")
        mutated_list = list(smiles_list)
        mutated_list[idx_to_mutate] = new_aa_smiles
        return mutated_list

    def _apply_terminal_mutation(self, smiles_list: list, params: dict, terminal: str) -> list:
        """Applies N-terminal or C-terminal amino acid mutation (substitution)."""
        if not smiles_list:
            print(f"  -> Empty sequence for {terminal}-terminal mutation.")
            return smiles_list
        target_index = 0 if terminal == 'N' else len(smiles_list) - 1
        original_smiles = smiles_list[target_index]
        source_smiles_canon_pool = self._get_eligible_smiles_pool(params, 'source_amino_acids_df')
        try:
            if _canonicalize_smiles(original_smiles) not in source_smiles_canon_pool:
                current_3L = get_3L_from_smiles(original_smiles)
                print(f"  -> The {terminal}-terminal AA '{current_3L}' is not eligible as a source for mutation.")
                return smiles_list
        except ValueError:
            print(f"  -> The {terminal}-terminal AA ({original_smiles}) is not eligible as a source for mutation.")
            return smiles_list
        new_aa_smiles = self._get_random_target_smiles(params, 'target_amino_acids_df')
        try:
            original_3L = get_3L_from_smiles(original_smiles)
            new_aa_3L = get_3L_from_smiles(new_aa_smiles)
            print(f"  -> {terminal}-terminal mutation from '{original_3L}' to '{new_aa_3L}'.")
        except ValueError:
            print(f"  -> {terminal}-terminal mutation from {original_smiles} to {new_aa_smiles}.")
        mutated_list = list(smiles_list)
        mutated_list[target_index] = new_aa_smiles
        return mutated_list

    def _apply_segment_duplication(self, smiles_list: list, params: dict) -> list:
        """Implements the duplication of a random segment of the sequence."""
        if len(smiles_list) < 2:
            print("  -> Sequence too short for segment duplication.")
            return smiles_list
        min_len = params.get('min_length', 1)
        max_len = params.get('max_length', len(smiles_list) // 2)
        min_len = max(1, min_len)
        max_len = min(max_len, len(smiles_list))
        if min_len > max_len:
            print(f"  -> Minimum length ({min_len}) for duplication is greater than maximum length ({max_len}).")
            return smiles_list
        if len(smiles_list) < min_len:
            print(f"  -> Sequence too short ({len(smiles_list)} AAs) to duplicate a segment of minimum length {min_len}.")
            return smiles_list
        start_idx_max = len(smiles_list) - min_len
        if start_idx_max < 0:
             print(f"  -> No valid starting indices for a segment duplication of minimum length {min_len}.")
             return smiles_list
        start_idx = random.randint(0, start_idx_max)
        actual_max_len = min(max_len, len(smiles_list) - start_idx)
        if actual_max_len < min_len:
            print(f"  -> Cannot find a segment of valid length for duplication from index {start_idx}.")
            return smiles_list
        segment_len = random.randint(min_len, actual_max_len)
        segment_to_duplicate = smiles_list[start_idx : start_idx + segment_len]
        insertion_idx = random.randint(0, len(smiles_list))
        mutated_list = smiles_list[:insertion_idx] + segment_to_duplicate + smiles_list[insertion_idx:]
        try:
            segment_3L = '-'.join([get_3L_from_smiles(s) for s in segment_to_duplicate])
            print(f"  -> Segment duplication '{segment_3L}' (index {start_idx}-{start_idx+segment_len-1}) inserted at index {insertion_idx}.")
        except ValueError:
            print(f"  -> Duplication of an unrecognized segment inserted at index {insertion_idx}.")
        return mutated_list

    def _apply_segment_inversion(self, smiles_list: list, params: dict) -> list:
        """Implements the inversion of a random segment of the sequence."""
        if len(smiles_list) < 2:
            print("  -> Sequence too short for segment inversion.")
            return smiles_list
        min_len = params.get('min_length', 2)
        max_len = params.get('max_length', len(smiles_list))
        min_len = max(1, min_len)
        max_len = min(max_len, len(smiles_list))
        if min_len > max_len:
            print(f"  -> Minimum length ({min_len}) for inversion is greater than maximum length ({max_len}).")
            return smiles_list
        if len(smiles_list) < min_len:
            print(f"  -> Sequence too short ({len(smiles_list)} AAs) to invert a segment of minimum length {min_len}.")
            return smiles_list
        start_idx_max = len(smiles_list) - min_len
        if start_idx_max < 0:
             print(f"  -> No valid starting indices for a segment inversion of minimum length {min_len}.")
             return smiles_list
        start_idx = random.randint(0, start_idx_max)
        actual_max_len = min(max_len, len(smiles_list) - start_idx)
        if actual_max_len < min_len:
            print(f"  -> Cannot find a segment of valid length for inversion from index {start_idx}.")
            return smiles_list
        segment_len = random.randint(min_len, actual_max_len)
        end_idx = start_idx + segment_len
        segment_to_invert = smiles_list[start_idx:end_idx]
        inverted_segment = segment_to_invert[::-1]
        mutated_list = list(smiles_list)
        mutated_list[start_idx:end_idx] = inverted_segment
        try:
            original_segment_3L = '-'.join([get_3L_from_smiles(s) for s in segment_to_invert])
            inverted_segment_3L = '-'.join([get_3L_from_smiles(s) for s in inverted_segment])
            print(f"  -> Segment inversion from '{original_segment_3L}' to '{inverted_segment_3L}' (indices {start_idx}-{end_idx-1}).")
        except ValueError:
            print(f"  -> Inversion of an unrecognized segment (indices {start_idx}-{end_idx-1}).")
        return mutated_list

    def _apply_segment_translocation(self, smiles_list: list, params: dict) -> list:
        """Implements the translocation (movement) of a random segment of the sequence."""
        if len(smiles_list) < 3:
            print("  -> Sequence too short for segment translocation.")
            return smiles_list
        min_len = params.get('min_length', 1)
        max_len = params.get('max_length', len(smiles_list) // 2)
        min_len = max(1, min_len)
        max_len = min(max_len, len(smiles_list))
        if min_len > max_len:
            print(f"  -> Minimum length ({min_len}) for translocation is greater than maximum length ({max_len}).")
            return smiles_list
        if len(smiles_list) < min_len:
            print(f"  -> Sequence too short ({len(smiles_list)} AAs) to translocate a segment of minimum length {min_len}.")
            return smiles_list
        start_idx_max = len(smiles_list) - min_len
        if start_idx_max < 0:
             print(f"  -> No valid starting indices for a segment translocation of minimum length {min_len}.")
             return smiles_list
        start_idx = random.randint(0, start_idx_max)
        actual_max_len = min(max_len, len(smiles_list) - start_idx)
        if actual_max_len < min_len:
            print(f"  -> Cannot find a segment of valid length for translocation from index {start_idx}.")
            return smiles_list
        segment_len = random.randint(min_len, actual_max_len)
        end_idx_segment = start_idx + segment_len
        segment_to_move = smiles_list[start_idx:end_idx_segment]
        temp_list = smiles_list[:start_idx] + smiles_list[end_idx_segment:]
        insertion_idx = random.randint(0, len(temp_list)) if temp_list else 0
        mutated_list = temp_list[:insertion_idx] + segment_to_move + temp_list[insertion_idx:]
        try:
            moved_segment_3L = '-'.join([get_3L_from_smiles(s) for s in segment_to_move])
            print(f"  -> Translocation of segment '{moved_segment_3L}' (from {start_idx}-{end_idx_segment-1}) inserted at new position {insertion_idx}.")
        except ValueError:
            print(f"  -> Translocation of an unrecognized segment (from {start_idx}-{end_idx_segment-1}) inserted at new position {insertion_idx}.")
        return mutated_list


    def apply_mutations(self, initial_smiles_list: list) -> list:
        """
        Applies all configured mutation rules to a given peptide SMILES sequence.

        Args:
            initial_smiles_list (List[str]): The initial SMILES sequence of the peptide.

        Returns:
            List[str]: The mutated SMILES sequence.
        """
        current_smiles_list = list(initial_smiles_list)

        print(f"\n===== Starting mutation application =====")
        try:
            initial_3L_sequence = [get_3L_from_smiles(smi) for smi in initial_smiles_list]
            print(f"Initial sequence (3L): {'-'.join(initial_3L_sequence)}")
        except ValueError:
            print(f"Initial sequence (SMILES): {initial_smiles_list} (contains unrecognized SMILES)")

        for i, rule in enumerate(self.mutation_rules):
            mutation_type = rule['type']
            probability = rule['probability']
            params = rule['params']

            rule_name = mutation_type.__name__ if callable(mutation_type) else mutation_type
            print(f"\n--- Step {i+1}: Processing rule '{rule_name}' (Probability: {probability}) ---")

            try:
                current_3L_sequence = [get_3L_from_smiles(smi) for smi in current_smiles_list]
                print(f"Sequence before '{rule_name}': {'-'.join(current_3L_sequence)}")
            except ValueError:
                print(f"Sequence before '{rule_name}' (SMILES): {current_smiles_list} (contains unrecognized SMILES)")

            if random.random() < probability:
                print(f"  -> Mutation '{rule_name}' triggered.")
                try:
                    if isinstance(mutation_type, str):
                        method_name = f"_apply_{mutation_type.replace(' ', '_')}"
                        if hasattr(self, method_name):
                            current_smiles_list = getattr(self, method_name)(current_smiles_list, params)
                        else:
                            raise ValueError(f"Predefined mutation type '{mutation_type}' not implemented.")
                    elif callable(mutation_type):
                        current_smiles_list = mutation_type(current_smiles_list, **params)
                        print(f"  -> Custom mutation '{rule_name}' applied.")
                    else:
                        raise ValueError(f"Unsupported mutation rule type: {type(mutation_type)}")
                except ValueError as e:
                    print(f"  ! Error applying '{rule_name}': {e}")
                except Exception as e:
                    print(f"  ! Unexpected error applying '{rule_name}': {e}")
            else:
                print(f"  -> Mutation '{rule_name}' not triggered (probability {probability}).")

            try:
                current_3L_sequence_after = [get_3L_from_smiles(smi) for smi in current_smiles_list]
                print(f"Sequence after '{rule_name}': {'-'.join(current_3L_sequence_after)}")
            except ValueError:
                print(f"Sequence after '{rule_name}' (SMILES): {current_smiles_list} (contains unrecognized SMILES)")

        print(f"===== Mutation application finished =====")
        return current_smiles_list


class Peptide:
    """
    Represents a single peptide with its SMILES sequence, metadata, and history.
    """
    def __init__(self, smiles_sequence: list, peptide_id: str = None,
                 creation_date: datetime = None, history: list = None,
                 source_generation_params: dict = None):
        """
        Initializes a Peptide object.

        Args:
            smiles_sequence (list): A list of SMILES strings representing the amino acid sequence.
            peptide_id (str, optional): Unique identifier for the peptide. Generated if None.
            creation_date (datetime, optional): Timestamp of peptide creation. Defaults to now.
            history (list, optional): A list of dictionaries detailing events in the peptide's lifecycle.
            source_generation_params (dict, optional): Parameters related to how the peptide was generated.
        """
        self.peptide_id = peptide_id if peptide_id else str(uuid.uuid4())
        self.smiles_sequence = smiles_sequence
        self.length = len(smiles_sequence)
        self.creation_date = creation_date if creation_date else datetime.now()
        self.history = history if history is not None else []
        self.source_generation_params = source_generation_params if source_generation_params is not None else {}

        self._one_letter_sequence = None
        self._three_letter_sequence = None
        self.set_sequences_from_global_converter()

    def set_sequences_from_global_converter(self):
        """
        Sets the 1-letter and 3-letter sequence representations using global conversion functions.
        Handles cases where SMILES might not be recognized by marking them as "N/A" and logging.
        """
        try:
            self._one_letter_sequence = "".join([get_1L_from_smiles(s) for s in self.smiles_sequence])
            self._three_letter_sequence = "-".join([get_3L_from_smiles(s) for s in self.smiles_sequence])
        except ValueError as e:
            error_message = f"Failed to convert SMILES sequence to 1L/3L: {e}. Sequence: {self.smiles_sequence}"
            self.add_history_entry("conversion_error", {"message": error_message})
            self._one_letter_sequence = "N/A"
            self._three_letter_sequence = "N/A"
            print(f"  ! Warning: Peptide {self.peptide_id[:8]} has invalid amino acids. Marked as N/A.")

    @property
    def one_letter_sequence(self) -> str:
        """Returns the 1-letter code sequence."""
        return self._one_letter_sequence

    @property
    def three_letter_sequence(self) -> str:
        """Returns the 3-letter code sequence."""
        return self._three_letter_sequence

    def add_history_entry(self, event_type: str, details: dict):
        """
        Adds an entry to the peptide's history log.

        Args:
            event_type (str): The type of event (e.g., "mutation", "crossover", "replenishment").
            details (dict): A dictionary containing event-specific details.
        """
        self.history.append({
            "type": event_type,
            "timestamp": datetime.now().isoformat(),
            "original_length": self.length,
            "new_length": len(self.smiles_sequence),
            "details": details
        })
        self.length = len(self.smiles_sequence)

    def to_dict(self) -> Dict:
        """
        Converts the Peptide object to a dictionary representation.

        Returns:
            Dict: A dictionary containing all peptide attributes.
        """
        return {
            "peptide_id": self.peptide_id,
            "smiles_sequence": self.smiles_sequence,
            "one_letter_sequence": self.one_letter_sequence,
            "three_letter_sequence": self.three_letter_sequence,
            "length": self.length,
            "creation_date": self.creation_date.isoformat(),
            "history": self.history,
            "source_generation_params": self.source_generation_params
        }

    @classmethod
    def from_dict(cls, data: Dict) -> 'Peptide':
        """
        Creates a Peptide object from a dictionary representation.

        Args:
            data (Dict): A dictionary containing peptide data.

        Returns:
            Peptide: A new Peptide instance.
        """
        peptide = cls(
            smiles_sequence=data["smiles_sequence"],
            peptide_id=data["peptide_id"],
            creation_date=datetime.fromisoformat(data["creation_date"]),
            history=data.get("history", []),
            source_generation_params=data.get("source_generation_params", {})
        )

        if data.get("one_letter_sequence") is not None:
             peptide._one_letter_sequence = data.get("one_letter_sequence")
        if data.get("three_letter_sequence") is not None:
             peptide._three_letter_sequence = data.get("three_letter_sequence")
        return peptide

    def __repr__(self) -> str:
        return f"Peptide(ID={self.peptide_id[:8]}, 1L={self.one_letter_sequence}, len={self.length})"

    def __eq__(self, other: object) -> bool:
        if not isinstance(other, Peptide):
            return NotImplemented
        return self.peptide_id == other.peptide_id

    def __hash__(self) -> int:
        return hash(self.peptide_id)


class PeptidePoolManager:
    """
    Manages a collection of Peptide objects, providing methods for adding, retrieving,
    removing, and saving/loading the pool.
    """
    def __init__(self):
        self.peptides: Dict[str, Peptide] = {}

    def add_peptide(self, peptide: Peptide):
        """
        Adds a Peptide object to the pool.

        Args:
            peptide (Peptide): The Peptide object to add.

        Raises:
            TypeError: If the object is not a Peptide instance.
        """
        if not isinstance(peptide, Peptide):
            raise TypeError("Only Peptide objects can be added to the pool.")
        self.peptides[peptide.peptide_id] = peptide

    def get_peptide(self, peptide_id: str) -> Optional[Peptide]:
        """
        Retrieves a peptide by its ID.

        Args:
            peptide_id (str): The ID of the peptide.

        Returns:
            Optional[Peptide]: The Peptide object if found, else None.
        """
        return self.peptides.get(peptide_id)

    def get_all_peptides(self) -> List[Peptide]:
        """
        Returns a list of all Peptide objects in the pool.

        Returns:
            List[Peptide]: A list of Peptide objects.
        """
        return list(self.peptides.values())

    def remove_peptide(self, peptide_id: str):
        """
        Removes a peptide from the pool by its ID.

        Args:
            peptide_id (str): The ID of the peptide to remove.
        """
        if peptide_id in self.peptides:
            del self.peptides[peptide_id]

    def clear_pool(self):
        """Clears all peptides from the pool."""
        self.peptides = {}

    def get_pool_size(self) -> int:
        """
        Returns the current number of peptides in the pool.

        Returns:
            int: The number of peptides.
        """
        return len(self.peptides)

    def to_dataframe(self) -> pd.DataFrame:
        """
        Converts the peptide pool into a pandas DataFrame.
        History and source_generation_params are serialized to JSON strings for storage.

        Returns:
            pd.DataFrame: A DataFrame representation of the pool.
        """
        data = [p.to_dict() for p in self.peptides.values()]
        df = pd.DataFrame(data)
        if not df.empty:
            df['history'] = df['history'].apply(json.dumps)
            df['source_generation_params'] = df['source_generation_params'].apply(json.dumps)
        return df

    def from_dataframe(self, df: pd.DataFrame):
        """
        Loads peptides into the pool from a pandas DataFrame.
        History and source_generation_params are deserialized from JSON strings.

        Args:
            df (pd.DataFrame): The DataFrame containing peptide data.
        """
        self.clear_pool()
        for _, row in df.iterrows():
            row_dict = row.to_dict()
            if isinstance(row_dict.get('history'), str):
                row_dict['history'] = json.loads(row_dict['history'])

            if isinstance(row_dict.get('source_generation_params'), str):
                try:
                    row_dict['source_generation_params'] = json.loads(row_dict['source_generation_params'])
                except json.JSONDecodeError:
                    print(f"Warning: Could not decode source_generation_params string: {row_dict['source_generation_params']}. Keeping as is.")

            if isinstance(row_dict.get('smiles_sequence'), str) and row_dict['smiles_sequence'].startswith('[') and row_dict['smiles_sequence'].endswith(']'):
                try:
                    row_dict['smiles_sequence'] = json.loads(row_dict['smiles_sequence'].replace("'", '"'))
                except json.JSONDecodeError:
                    print(f"Warning: Could not decode smiles_sequence string: {row_dict['smiles_sequence']}. Keeping as is.")

            peptide = Peptide.from_dict(row_dict)
            self.add_peptide(peptide)


    def save_pool(self, file_path: str, file_format: str = 'parquet'):
        """
        Saves the current peptide pool to a file.

        Args:
            file_path (str): The path to save the file.
            file_format (str): The format to save the file ('parquet', 'csv', or 'json').
                               Defaults to 'parquet'.
        """
        df = self.to_dataframe()
        if file_format.lower() == 'parquet':
            df.to_parquet(file_path, index=False)
        elif file_format.lower() == 'csv':
            df_to_save = df.copy()
            df_to_save.to_csv(file_path, index=False)
        elif file_format.lower() == 'json':
            df.to_json(file_path, orient='records', indent=4)
        else:
            raise ValueError(f"Unsupported file format: {file_format}")
        print(f"Pool saved to {file_path}")

    def load_pool(self, file_path: str, file_format: str = 'parquet'):
        """
        Loads a peptide pool from a file into the current manager.

        Args:
            file_path (str): The path to the file to load.
            file_format (str): The format of the file ('parquet', 'csv', or 'json').
                               Defaults to 'parquet'.
        """
        if file_format.lower() == 'parquet':
            df = pd.read_parquet(file_path)
        elif file_format.lower() == 'csv':
            df = pd.read_csv(file_path)
        elif file_format.lower() == 'json':
            df = pd.read_json(file_path, orient='records')
        else:
            raise ValueError(f"Unsupported file format: {file_format}")
        self.from_dataframe(df)
        print(f"Pool loaded from {file_path}. Size: {self.get_pool_size()}")


class Evaluator:
    """
    Manages the evaluation pipeline for peptides.
    It converts peptides to DataFrames, applies user-defined processing steps (En),
    and ranks them using a specified ranker function.
    Intermediate DataFrames can be saved for logging and debugging.
    """
    def __init__(self, evaluation_pipeline: List[Callable[[pd.DataFrame], pd.DataFrame]],
                 ranker_function: Callable[[pd.DataFrame], Tuple[List['Peptide'], Optional[List[float]]]]):
        """
        Initializes the Evaluator with a pipeline of evaluation steps and a ranker.

        Args:
            evaluation_pipeline (List[Callable[[pd.DataFrame], pd.DataFrame]]):
                A list of functions (En steps). Each function takes a DataFrame and returns a DataFrame.
                These functions define the sequence of data processing and feature generation.
            ranker_function (Callable[[pd.DataFrame], Tuple[List['Peptide'], Optional[List[float]]]]):
                A function that takes the final processed DataFrame and returns a tuple:
                (List[Peptide] of ranked peptides, Optional[List[float]] of their corresponding scores).
                This function is responsible for the final selection/ordering of peptides.
        """
        self.evaluation_pipeline = evaluation_pipeline
        self.ranker_function = ranker_function

    def _e0_to_dataframe(self, peptides: List['Peptide']) -> pd.DataFrame:
        """
        Converts a list of Peptide objects into the initial DataFrame (E0 step).
        Each row represents a peptide, with its full data.

        Args:
            peptides (List['Peptide']): The list of Peptide objects.

        Returns:
            pd.DataFrame: The initial DataFrame for evaluation.
        """
        data = []
        for p in peptides:
            row = p.to_dict()
            data.append(row)
        df = pd.DataFrame(data)
        return df

    def _save_dataframe(self, df: pd.DataFrame, step_name: str, round_identifier: str = None):
        """
        Saves an intermediate DataFrame to a CSV file.
        Filename includes peptide count, feature count, round identifier, step name, and a hash.

        Args:
            df (pd.DataFrame): The DataFrame to save.
            step_name (str): The name of the evaluation step (for filename).
            round_identifier (str, optional): An identifier for the current round (for filename).
        """
        df_hash = hash(df.head().to_string()) % 100000

        filename_parts = [
            "eval_log",
            f"pep_count_{len(df)}",
            f"feat_count_{len(df.columns)}"
        ]
        if round_identifier:
            filename_parts.append(f"round_{round_identifier}")
        filename_parts.append(f"step_{step_name.replace(' ', '_')}")
        filename_parts.append(f"hash_{df_hash}")
        filename = "_".join(filename_parts) + ".csv"

        try:
            df_to_save = df.copy()
            if 'smiles_sequence' in df_to_save.columns:
                df_to_save['smiles_sequence'] = df_to_save['smiles_sequence'].apply(str)

            df_to_save.to_csv(filename, index=False)
            print(f"    -> Evaluator: DataFrame for step '{step_name}' saved to '{filename}'")
        except Exception as e:
            print(f"    ! Evaluator: Error saving DataFrame for step '{step_name}': {e}")

    def evaluate(self, peptides: List['Peptide'], round_identifier: str = None) -> Tuple[List['Peptide'], Optional[List[float]]]:
        """
        Executes the evaluation pipeline on a list of peptides and returns the ranked peptides.

        Args:
            peptides (List['Peptide']): The list of Peptide objects to evaluate.
            round_identifier (str, optional): An identifier for the current round, used for logging.

        Returns:
            Tuple[List['Peptide'], Optional[List[float]]]:
                A tuple containing:
                - A list of Peptide objects, ranked according to the ranker_function.
                - An optional list of scores corresponding to the ranked peptides (used for truncation).
        """
        print("  --- Starting Evaluator Pipeline ---")
        current_df = self._e0_to_dataframe(peptides)
        self._save_dataframe(current_df, "E0_Initial_Conversion", round_identifier)

        for i, step_func in enumerate(self.evaluation_pipeline):
            step_name = step_func.__name__ if hasattr(step_func, '__name__') else f"En_Step_{i+1}"
            print(f"    -> Evaluator: Executing evaluation step '{step_name}'...")
            try:
                current_df = step_func(current_df)
                self._save_dataframe(current_df, step_name, round_identifier)
            except Exception as e:
                print(f"    ! Evaluator: Error in step '{step_name}': {e}. Returning empty results.")
                return [], None

        print(f"    -> Evaluator: Executing Ranker function...")
        ranked_peptides, scores = self.ranker_function(current_df)
        print("  --- Evaluator Pipeline Finished ---")
        return ranked_peptides, scores


class PoolRoundProcessor:
    """
    Orchestrates a single round of peptide evolution, applying a sequence of
    mutation, crossover, evaluation, replenishment, and truncation steps
    as defined by its pipeline.
    """
    def __init__(self):
        self.round_pipeline = []
        self.generation_function: Optional[Callable] = None
        self._last_selection_scores: Optional[List[float]] = None

    def add_pipeline_step(self, step_type: str, step_function: Callable, name: str, **params):
        """
        Adds a step to the round processing pipeline.

        Args:
            step_type (str): The type of step ('mutation', 'crossover', 'evaluation',
                             'replenishment', 'truncation', 'custom').
            step_function (Callable): The function to execute for this step.
                                      Its signature depends on `step_type`.
            name (str): A descriptive name for the step.
            **params: Parameters specific to the `step_function`.

        Raises:
            TypeError: If `step_function` is not callable.
        """
        if not callable(step_function):
            raise TypeError("step_function must be a callable.")
        self.round_pipeline.append({
            'type': step_type,
            'function': step_function,
            'name': name,
            'params': params
        })
        print(f"Pipeline step '{name}' ({step_type}) added.")

    def set_generation_function(self, gen_func: Callable[[int], list['Peptide']]):
        """
        Sets a function to generate new peptides if the pool is too small (used by replenishment step).

        Args:
            gen_func (Callable[[int], list['Peptide']]): A function that takes the number of peptides
                                                          to generate and returns a list of Peptide objects.
        """
        if not callable(gen_func):
            raise TypeError("Generation function must be a callable.")
        self.generation_function = gen_func
        print("Generation function set for pool replenishment.")

    def _execute_mutation_step(self, peptides: List['Peptide'], mutator: 'PeptideMutator', probability_of_application: float) -> List['Peptide']:
        """Helper to apply mutations to a list of peptides."""
        mutated_peptides = []
        for peptide in peptides:
            if random.random() < probability_of_application:
                original_smiles_at_step = list(peptide.smiles_sequence)
                mutated_peptide_smiles = mutator.apply_mutations(original_smiles_at_step)

                if original_smiles_at_step != mutated_peptide_smiles:
                    new_peptide = copy.deepcopy(peptide)
                    new_peptide.smiles_sequence = mutated_peptide_smiles
                    new_peptide.add_history_entry("round_mutation", {"mutator_applied": mutator.__class__.__name__, "parent_id": peptide.peptide_id})
                    new_peptide.set_sequences_from_global_converter()
                    mutated_peptides.append(new_peptide)
                else:
                    mutated_peptides.append(peptide)
            else:
                mutated_peptides.append(peptide)
        return mutated_peptides

    def _execute_crossover_step(self, peptides: List['Peptide'], num_crossovers: int, crossover_probability_per_pair: float) -> List['Peptide']:
        """Helper to apply crossover to a list of peptides."""
        peptides_after_crossover = list(peptides)
        num_children_generated = 0

        if len(peptides) < 2:
            print("  -> Not enough peptides for crossover. Skipping.")
            return peptides_after_crossover

        available_parents = list(peptides)

        for _ in range(num_crossovers):
            if len(available_parents) < 2:
                print("  -> Not enough peptides for crossover. Skipping remaining crossover attempts.")
                break

            parent1, parent2 = random.sample(available_parents, 2)

            if random.random() < crossover_probability_per_pair:
                child1_smiles, child2_smiles = peptide_crossover(parent1.smiles_sequence, parent2.smiles_sequence)

                child1 = Peptide(smiles_sequence=child1_smiles,
                                 source_generation_params={"type": "crossover", "parent1_id": parent1.peptide_id, "parent2_id": parent2.peptide_id})
                child1.add_history_entry("crossover", {"parents": [parent1.peptide_id, parent2.peptide_id]})
                child1.set_sequences_from_global_converter()

                child2 = Peptide(smiles_sequence=child2_smiles,
                                 source_generation_params={"type": "crossover", "parent1_id": parent1.peptide_id, "parent2_id": parent2.peptide_id})
                child2.add_history_entry("crossover", {"parents": [parent1.peptide_id, parent2.peptide_id]})
                child2.set_sequences_from_global_converter()

                peptides_after_crossover.extend([child1, child2])
                num_children_generated += 2
        print(f"  -> Crossover step generated {num_children_generated} new children.")
        return peptides_after_crossover

    def _execute_evaluation_step(self, peptides: List['Peptide'], evaluator_instance: 'Evaluator', round_identifier: str) -> Tuple[List['Peptide'], Optional[List[float]]]:
        """Helper to execute the evaluation pipeline."""
        print(f"  -> Executing evaluation step with Evaluator instance.")
        ranked_peptides, scores = evaluator_instance.evaluate(peptides, round_identifier)
        print(f"  -> Evaluation completed. {len(ranked_peptides)} peptides returned from ranker.")
        return ranked_peptides, scores

    def _execute_replenishment_step(self, peptides: List['Peptide'], target_size: int, gen_func: Callable) -> List['Peptide']:
        """Helper to replenish the pool to a target size."""
        if gen_func is None:
            print("  ! Warning: Generation function not set for replenishment. Skipping.")
            return peptides

        current_size = len(peptides)
        if current_size < target_size:
            num_to_generate = target_size - current_size
            print(f"  -> Replenishing pool. Generating {num_to_generate} new peptides.")
            new_peptides = gen_func(num_to_generate)
            for p in new_peptides:
                p.source_generation_params['reason'] = 'replenishment'
                p.add_history_entry("replenishment_generation", {"count": 1})
            peptides.extend(new_peptides)
        return peptides

    def _execute_truncation_step(self, peptides: List['Peptide'], max_size: int, scores: Optional[List[float]]) -> List['Peptide']:
        """Helper to truncate the pool to a max size."""
        if len(peptides) > max_size:
            print(f"  -> Truncating pool from {len(peptides)} to {max_size} peptides.")
            if scores and len(scores) == len(peptides):
                combined = sorted(zip(peptides, scores), key=lambda x: x[1], reverse=True)
                peptides = [p for p, s in combined[:max_size]]
            else:
                random.shuffle(peptides)
                peptides = peptides[:max_size]
        return peptides

    def run_round(self,
                  input_pool_manager: 'PeptidePoolManager',
                  round_name: str = "Evolution Round") -> Tuple['PeptidePoolManager', pd.DataFrame]:
        """
        Executes a complete evolutionary round on the peptide pool based on the configured pipeline.

        Args:
            input_pool_manager (PeptidePoolManager): The PeptidePoolManager of the (n-1) pool.
            round_name (str): Name of this round for logs and evaluator logging.

        Returns:
            Tuple[PeptidePoolManager, pd.DataFrame]: The resulting (n) pool and a DataFrame of logs for this round.
        """
        round_logs = []
        start_time = datetime.now()
        print(f"\n--- Starting Round: '{round_name}' (Initial Pool Size: {input_pool_manager.get_pool_size()} peptides) ---")

        current_peptides_for_processing = [copy.deepcopy(p) for p in input_pool_manager.get_all_peptides()]
        previous_pool_peptides = input_pool_manager.get_all_peptides()

        initial_round_size = len(current_peptides_for_processing)
        round_logs.append({
            "round_name": round_name, "stage": "Initial", "timestamp": datetime.now().isoformat(),
            "pool_size_before": initial_round_size, "pool_size_after": initial_round_size,
            "details": "Starting round with input pool."
        })

        self._last_selection_scores = None

        for i, step_config in enumerate(self.round_pipeline):
            step_type = step_config['type']
            step_function = step_config['function']
            step_name = step_config['name']
            step_params = step_config['params']

            print(f"\n--- Executing Step {i+1}: '{step_name}' ({step_type}) ---")
            pool_size_before_step = len(current_peptides_for_processing)

            try:
                if step_type == 'mutation':
                    current_peptides_for_processing = step_function(current_peptides_for_processing, **step_params)
                elif step_type == 'crossover':
                    current_peptides_for_processing = step_function(current_peptides_for_processing, **step_params)
                elif step_type == 'evaluation':
                    current_peptides_for_processing, self._last_selection_scores = step_function(current_peptides_for_processing, round_identifier=round_name, **step_params)
                elif step_type == 'replenishment':
                    current_peptides_for_processing = step_function(current_peptides_for_processing, gen_func=self.generation_function, **step_params)
                elif step_type == 'truncation':
                    current_peptides_for_processing = step_function(current_peptides_for_processing, scores=self._last_selection_scores, **step_params)
                elif step_type == 'custom':
                    current_peptides_for_processing = step_function(current_peptides_for_processing, **step_params)
                else:
                    print(f"  ! Warning: Unknown step type '{step_type}'. Skipping.")

                pool_size_after_step = len(current_peptides_for_processing)
                round_logs.append({
                    "round_name": round_name,
                    "stage": f"Step_{i+1}_{step_name}",
                    "timestamp": datetime.now().isoformat(),
                    "pool_size_before": pool_size_before_step,
                    "pool_size_after": pool_size_after_step,
                    "details": f"Step '{step_name}' applied. {pool_size_before_step} -> {pool_size_after_step} peptides."
                })
                print(f"  -> Pool size after '{step_name}': {pool_size_after_step}")

            except Exception as e:
                print(f"  ! Error executing step '{step_name}': {e}")
                round_logs.append({
                    "round_name": round_name,
                    "stage": f"Step_{i+1}_{step_name}_Error",
                    "timestamp": datetime.now().isoformat(),
                    "pool_size_before": pool_size_before_step,
                    "pool_size_after": pool_size_before_step,
                    "details": f"Error during step '{step_name}': {e}"
                })

        output_pool_manager = PeptidePoolManager()
        for p in current_peptides_for_processing:
            output_pool_manager.add_peptide(p)

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        round_logs.append({
            "round_name": round_name,
            "stage": "Round_End",
            "timestamp": end_time.isoformat(),
            "pool_size_before": output_pool_manager.get_pool_size(),
            "pool_size_after": output_pool_manager.get_pool_size(),
            "details": f"Round completed in {duration:.2f} seconds."
        })

        print(f"--- Round '{round_name}' Completed (Final Pool Size: {output_pool_manager.get_pool_size()} peptides) ---")
        return output_pool_manager, pd.DataFrame(round_logs)


class PeptideGenerator:
    """
    Generates random peptide SMILES sequences.
    """
    def __init__(self):
        self.default_amino_acids = AMINO_ACID_DF['SMILES'].tolist()

    def generate_random_peptides(self, num_peptides: int, min_length: int, max_length: int) -> List[List[str]]:
        """
        Generates a list of random peptide SMILES sequences.

        Args:
            num_peptides (int): The number of peptides to generate.
            min_length (int): The minimum length for generated peptides.
            max_length (int): The maximum length for generated peptides.

        Returns:
            List[List[str]]: A list where each element is a list of SMILES strings
                             representing a peptide sequence.
        """
        generated_smiles_lists = []
        for _ in range(num_peptides):
            length = random.randint(min_length, max_length)
            smiles_sequence = random.choices(self.default_amino_acids, k=length)
            generated_smiles_lists.append(smiles_sequence)
        return generated_smiles_lists

# The following functions are basically a set of test function for the mutator, round stuff and evaluator, we actually don't give a fuck about it in production but it's still usefull for testing
def custom_reverse_segment(smiles_list: List[str], start_idx: int = 0, end_idx: Optional[int] = None) -> List[str]:
    """
    Custom mutation rule: Reverses a segment of the peptide.
    This function illustrates how a user can define their own mutation logic.
    It takes a list of SMILES and parameters, and returns a new list of SMILES.

    Args:
        smiles_list (List[str]): The SMILES sequence of the peptide.
        start_idx (int): The starting index of the segment to reverse.
        end_idx (Optional[int]): The ending index (exclusive) of the segment to reverse.
                                 Defaults to the end of the list.

    Returns:
        List[str]: The peptide SMILES sequence with the specified segment reversed.
    """
    if not smiles_list:
        print("  -> Custom mutation: Empty sequence, no inversion.")
        return smiles_list

    if end_idx is None:
        end_idx = len(smiles_list)

    start_idx = max(0, start_idx)
    end_idx = min(len(smiles_list), end_idx)
    if start_idx >= end_idx:
        print("  -> Custom mutation: Invalid segment for inversion (start >= end).")
        return smiles_list

    segment_to_reverse = smiles_list[start_idx:end_idx]
    reversed_segment = segment_to_reverse[::-1]

    mutated_list = list(smiles_list)
    mutated_list[start_idx:end_idx] = reversed_segment

    try:
        original_segment_3L = '-'.join([get_3L_from_smiles(s) for s in segment_to_reverse])
        reversed_segment_3L = '-'.join([get_3L_from_smiles(s) for s in reversed_segment])
        print(f"  -> Custom mutation 'reverse_segment': '{original_segment_3L}' inverted to '{reversed_segment_3L}' (indices {start_idx}-{end_idx-1}).")
    except ValueError:
        print(f"  -> Custom mutation 'reverse_segment': Unrecognized segment (indices {start_idx}-{end_idx-1}) inverted.")

    return mutated_list


def add_length_feature(df: pd.DataFrame) -> pd.DataFrame:
    """
    Evaluator pipeline step: Adds a 'length' column to the DataFrame based on smiles_sequence length.

    Args:
        df (pd.DataFrame): The input DataFrame.

    Returns:
        pd.DataFrame: The DataFrame with the 'length' column added.
    """
    df['length'] = df['smiles_sequence'].apply(len)
    print("    -> Evaluator Step: Added 'length' feature.")
    return df

def add_dummy_score_feature(df: pd.DataFrame) -> pd.DataFrame:
    """
    Evaluator pipeline step: Adds a 'dummy_score' column for demonstration.
    This simulates calculating a score based on peptide properties or external models.

    Args:
        df (pd.DataFrame): The input DataFrame.

    Returns:
        pd.DataFrame: The DataFrame with the 'dummy_score' column added.
    """
    if 'dummy_score' not in df.columns:
        df['dummy_score'] = np.random.rand(len(df))
    print("    -> Evaluator Step: Added 'dummy_score' feature.")
    return df

def filter_by_length_in_df(df: pd.DataFrame, min_len: int = 7) -> pd.DataFrame:
    """
    Evaluator pipeline step: Filters the DataFrame to keep peptides above a minimum length.

    Args:
        df (pd.DataFrame): The input DataFrame.

    Returns:
        pd.DataFrame: The filtered DataFrame.
    """
    initial_count = len(df)
    filtered_df = df[df['length'] >= min_len].copy()
    print(f"    -> Evaluator Step: Filtered by length (min {min_len}). Kept {len(filtered_df)}/{initial_count} peptides.")
    return filtered_df


def rank_by_dummy_score_and_reconstruct(df: pd.DataFrame, n_to_keep: int = 20) -> Tuple[List['Peptide'], Optional[List[float]]]:
    """
    Ranker function: Ranks peptides by 'dummy_score' and reconstructs Peptide objects.
    Returns the top N peptides and their scores.

    Args:
        df (pd.DataFrame): The final processed DataFrame from the evaluation pipeline.
        n_to_keep (int): The number of top peptides to return.

    Returns:
        Tuple[List['Peptide'], Optional[List[float]]]:
            A tuple containing:
            - A list of Peptide objects, ranked by score.
            - A list of their corresponding scores.
    """
    if 'dummy_score' not in df.columns:
        print("    ! Ranker: 'dummy_score' column not found. Cannot rank. Returning all peptides with no scores.")
        reconstructed_peptides = [Peptide.from_dict(row.to_dict()) for _, row in df.iterrows()]
        return reconstructed_peptides, None

    df_sorted = df.sort_values(by='dummy_score', ascending=False)
    df_top_n = df_sorted.head(n_to_keep)

    ranked_peptides = [Peptide.from_dict(row.to_dict()) for _, row in df_top_n.iterrows()]
    scores = df_top_n['dummy_score'].tolist()

    print(f"    -> Ranker: Ranked by dummy score. Returning top {len(ranked_peptides)} peptides.")
    return ranked_peptides, scores