# Interactive Feedback MCP
# Developed by FÃ¡bio Ferreira (https://x.com/fabiomlferreira)
# Inspired by/related to dotcursorrules.com (https://dotcursorrules.com/)
# Enhanced by pawa (https://github.com/pawaovo) with ideas from https://github.com/noopstudios/interactive-feedback-mcp
import os
import sys
import json
import tempfile
import subprocess
import base64

# from typing import Annotated # Annotated æœªåœ¨æ­¤æ–‡ä»¶ä¸­ç›´æ¥ä½¿ç”¨ (Annotated not directly used in this file)
from typing import (
    Dict,
    List,
    Any,
    Optional,
    Tuple,
    Union,
)  # ç®€åŒ–å¯¼å…¥ (Simplified imports)

from fastmcp import FastMCP, Image
from pydantic import (
    Field,
)  # Field ç”± FastMCP å†…éƒ¨ä½¿ç”¨ (Field is used internally by FastMCP)

from .utils import get_config, resolve_final_options, get_display_mode

# é”™è¯¯æ¶ˆæ¯å¸¸é‡
ERROR_MESSAGES = {
    "missing_both_params": "[é”™è¯¯] AIå¿…é¡»åŒæ—¶æä¾›messageå’Œfull_responseä¸¤ä¸ªå‚æ•°ï¼Œä¸èƒ½ä¸ºç©º",
    "no_user_feedback": "[ç”¨æˆ·æœªæä¾›åé¦ˆ]",
}


def _is_valid_param(param: Optional[str]) -> bool:
    """æ£€æŸ¥å‚æ•°æ˜¯å¦æœ‰æ•ˆï¼ˆéç©ºä¸”éçº¯ç©ºç™½ï¼‰"""
    return param and param.strip()


def _process_ui_output(ui_output_dict: Dict[str, Any]) -> List[Union[str, Image]]:
    """
    å¤„ç†UIè¾“å‡ºå†…å®¹ï¼Œæå–æ–‡æœ¬ã€å›¾ç‰‡å’Œæ–‡ä»¶å¼•ç”¨

    Args:
        ui_output_dict: UIè¿”å›çš„è¾“å‡ºå­—å…¸

    Returns:
        List[Union[str, Image]]: å¤„ç†åçš„å†…å®¹åˆ—è¡¨
    """
    processed_content: List[Union[str, Image]] = []

    if not (
        ui_output_dict
        and "content" in ui_output_dict
        and isinstance(ui_output_dict["content"], list)
    ):
        return processed_content

    for item in ui_output_dict.get("content", []):
        if not isinstance(item, dict):
            print(f"è­¦å‘Š: æ— æ•ˆçš„å†…å®¹é¡¹æ ¼å¼: {item}", file=sys.stderr)
            continue

        item_type = item.get("type")
        if item_type == "text":
            text_content = item.get("text", "")
            if text_content:
                processed_content.append(text_content)
        elif item_type == "image":
            _process_image_item(item, processed_content)
        elif item_type == "file_reference":
            _process_file_reference_item(item, processed_content)
        else:
            print(f"è­¦å‘Š: æœªçŸ¥çš„å†…å®¹é¡¹ç±»å‹: {item_type}", file=sys.stderr)

    return processed_content


def _process_image_item(
    item: Dict[str, Any], processed_content: List[Union[str, Image]]
) -> None:
    """å¤„ç†å›¾ç‰‡é¡¹"""
    base64_data = item.get("data")
    mime_type = item.get("mimeType")
    if base64_data and mime_type:
        try:
            image_format_str = mime_type.split("/")[-1].lower()
            if image_format_str == "jpeg":
                image_format_str = "jpg"

            image_bytes = base64.b64decode(base64_data)
            mcp_image = Image(data=image_bytes, format=image_format_str)
            processed_content.append(mcp_image)
        except Exception as e:
            print(f"é”™è¯¯: å¤„ç†å›¾åƒå¤±è´¥: {e}", file=sys.stderr)
            processed_content.append(f"[å›¾åƒå¤„ç†å¤±è´¥: {mime_type or 'unknown type'}]")


def _process_file_reference_item(
    item: Dict[str, Any], processed_content: List[Union[str, Image]]
) -> None:
    """å¤„ç†æ–‡ä»¶å¼•ç”¨é¡¹"""
    display_name = item.get("display_name", "")
    file_path = item.get("path", "")
    if display_name and file_path:
        file_info = f"å¼•ç”¨æ–‡ä»¶: {display_name} [è·¯å¾„: {file_path}]"
        processed_content.append(file_info)


def get_system_prompts():
    """
    è·å–ç³»ç»Ÿæç¤ºè¯ï¼ˆä»é…ç½®è¯»å–ï¼Œä½¿ç”¨config_managerä¸­çš„é»˜è®¤å€¼ï¼‰
    Get system prompts (read from config, use defaults from config_manager)

    Returns:
        dict: åŒ…å«optimizeå’Œreinforceæç¤ºè¯çš„å­—å…¸
    """
    try:
        config = get_config()
        optimizer_config = config.get("expression_optimizer", {})
        return optimizer_config.get("prompts", {})
    except Exception:
        # å›é€€åˆ°config_managerä¸­çš„é»˜è®¤é…ç½®
        from .utils.config_manager import DEFAULT_CONFIG

        return DEFAULT_CONFIG["expression_optimizer"]["prompts"]


def format_prompt_for_mode(
    original_text: str, mode: str, reinforcement_prompt: str = None
) -> str:
    """
    æ ¹æ®æ¨¡å¼æ ¼å¼åŒ–æç¤ºè¯
    Format prompt based on mode

    Args:
        original_text: åŸå§‹æ–‡æœ¬
        mode: ä¼˜åŒ–æ¨¡å¼
        reinforcement_prompt: å¼ºåŒ–æŒ‡ä»¤ï¼ˆå¯é€‰ï¼‰

    Returns:
        str: æ ¼å¼åŒ–åçš„æç¤ºè¯
    """
    if mode == "reinforce" and reinforcement_prompt:
        return f"å¼ºåŒ–æŒ‡ä»¤: '{reinforcement_prompt}'\n\nåŸå§‹æ–‡æœ¬: '{original_text}'"
    else:
        return original_text


print(f"Server.py å¯åŠ¨ - Pythonè§£é‡Šå™¨è·¯å¾„: {sys.executable}")
print(f"Server.py å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")


mcp = FastMCP("Interactive Feedback MCP", log_level="ERROR")


def detect_uvx_environment() -> bool:
    """æ£€æµ‹æ˜¯å¦åœ¨ uvx ç¯å¢ƒä¸­è¿è¡Œ"""
    return (
        'UV_PROJECT_ENVIRONMENT' in os.environ or
        'UV_CACHE_DIR' in os.environ or
        'UV_TOOL_DIR' in os.environ
    )


def detect_mcp_environment() -> bool:
    """æ£€æµ‹æ˜¯å¦åœ¨ MCP æœåŠ¡ç¯å¢ƒä¸­è¿è¡Œ"""
    return (
        not sys.stdin.isatty() or  # æ²¡æœ‰äº¤äº’å¼ç»ˆç«¯
        'MCP_SERVER' in os.environ or
        hasattr(sys.stdin, 'closed') and sys.stdin.closed
    )


def launch_feedback_ui_via_module(
    summary: str, predefined_options_list: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    é€šè¿‡ç›´æ¥æ¨¡å—è°ƒç”¨å¯åŠ¨ feedback UIï¼ˆuvx å…¼å®¹æ¨¡å¼ï¼‰
    Launch feedback UI via direct module call (uvx compatible mode)
    """
    tmp_file_path = None
    try:
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶
        with tempfile.NamedTemporaryFile(
            suffix=".json", delete=False, mode="w", encoding="utf-8"
        ) as tmp:
            tmp_file_path = tmp.name

        options_str = (
            "|||".join(predefined_options_list) if predefined_options_list else ""
        )

        # å°è¯•ç›´æ¥å¯¼å…¥å¹¶è°ƒç”¨ feedback_ui
        try:
            # æ£€æŸ¥PySide6æ˜¯å¦å¯ç”¨
            try:
                import PySide6
                print(f"PySide6 ç‰ˆæœ¬: {PySide6.__version__}", file=sys.stderr)

                # åœ¨MCPç¯å¢ƒä¸­ï¼Œå³ä½¿PySide6å¯ç”¨ä¹Ÿä¸èƒ½å¯åŠ¨GUI
                if detect_mcp_environment():
                    print("æ£€æµ‹åˆ°MCPç¯å¢ƒï¼Œè·³è¿‡GUIå¯åŠ¨", file=sys.stderr)
                    raise ImportError("MCPç¯å¢ƒä¸æ”¯æŒGUI")

            except ImportError as pyside_error:
                print(f"è­¦å‘Š: PySide6 ä¸å¯ç”¨æˆ–ä¸é€‚ç”¨: {pyside_error}", file=sys.stderr)
                print("å°†ä½¿ç”¨é™çº§æ¨¡å¼", file=sys.stderr)
                raise ImportError("PySide6 ä¸å¯ç”¨")

            from feedback_ui.cli import start_feedback_tool

            options_list = [
                opt.strip() for opt in options_str.split("|||") if opt.strip()
            ] if options_str else None

            print(f"ä½¿ç”¨æ¨¡å—ç›´æ¥è°ƒç”¨æ¨¡å¼å¯åŠ¨ UI", file=sys.stderr)
            result = start_feedback_tool(summary, options_list, tmp_file_path)

            # è¯»å–ç»“æœæ–‡ä»¶
            with open(tmp_file_path, "r", encoding="utf-8") as f:
                ui_result_data = json.load(f)

            return ui_result_data

        except ImportError as import_error:
            print(f"æ¨¡å—å¯¼å…¥å¤±è´¥: {import_error}", file=sys.stderr)
            print("å¯èƒ½åŸå› : PySide6ä¾èµ–åœ¨uvxç¯å¢ƒä¸­ä¸å®Œæ•´æˆ–MCPç¯å¢ƒä¸æ”¯æŒGUI", file=sys.stderr)
            # é™çº§åˆ°å‘½ä»¤è¡Œæ¨¡å¼
            raise Exception("æ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œéœ€è¦é™çº§å¤„ç†")

    except Exception as e:
        print(f"é”™è¯¯: launch_feedback_ui_via_module å¼‚å¸¸: {e}", file=sys.stderr)
        raise
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if tmp_file_path and os.path.exists(tmp_file_path):
            try:
                os.unlink(tmp_file_path)
            except OSError as e_unlink:
                print(
                    f"è­¦å‘Š: åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ '{tmp_file_path}': {e_unlink}",
                    file=sys.stderr,
                )


def launch_feedback_ui_fallback(
    summary: str, predefined_options_list: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    é™çº§æ¨¡å¼ï¼šä½¿ç”¨ç®€åŒ–çš„å‘½ä»¤è¡Œäº¤äº’æˆ–MCPå…¼å®¹æ¨¡å¼
    Fallback mode: use simplified command line interaction or MCP compatible mode
    """
    # æ£€æµ‹æ˜¯å¦åœ¨MCPç¯å¢ƒä¸­
    is_mcp = detect_mcp_environment()

    if is_mcp:
        # MCPç¯å¢ƒï¼šæ— æ³•è¿›è¡Œäº¤äº’å¼è¾“å…¥ï¼Œè¿”å›é»˜è®¤é€‰é¡¹æˆ–æç¤º
        print("ğŸ”„ MCPç¯å¢ƒæ£€æµ‹ï¼šæ— äº¤äº’å¼ç»ˆç«¯ï¼Œä½¿ç”¨æ™ºèƒ½é»˜è®¤é€‰æ‹©", file=sys.stderr)

        options_list = predefined_options_list or []

        if options_list:
            # å¦‚æœæœ‰é¢„å®šä¹‰é€‰é¡¹ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ªä½œä¸ºé»˜è®¤
            user_input = options_list[0]
            print(f"ğŸ“‹ è‡ªåŠ¨é€‰æ‹©ç¬¬ä¸€ä¸ªé€‰é¡¹: {user_input}", file=sys.stderr)
        else:
            # æ²¡æœ‰é¢„å®šä¹‰é€‰é¡¹ï¼Œè¿”å›ä¸€ä¸ªé€šç”¨çš„ç¡®è®¤
            user_input = "ç»§ç»­æ‰§è¡Œ"
            print(f"ğŸ“ AIè¯·æ±‚: {summary}", file=sys.stderr)
            print(f"âœ… è‡ªåŠ¨ç¡®è®¤: {user_input}", file=sys.stderr)

        result = {
            "content": [
                {
                    "type": "text",
                    "text": user_input
                }
            ],
            "metadata": {
                "mode": "mcp_auto",
                "environment": "mcp_fallback",
                "version": "2.5.6",
                "auto_selected": True
            }
        }

        return result

    # éMCPç¯å¢ƒï¼šä½¿ç”¨äº¤äº’å¼å‘½ä»¤è¡Œ
    print("\n" + "="*60, file=sys.stderr)
    print("ğŸ”„ uvx å…¼å®¹æ¨¡å¼ï¼šç®€åŒ–å‘½ä»¤è¡Œäº¤äº’", file=sys.stderr)
    print("ğŸ’¡ æç¤ºï¼šGUIç•Œé¢åœ¨uvxç¯å¢ƒä¸­ä¸å¯ç”¨ï¼Œä½¿ç”¨å‘½ä»¤è¡Œäº¤äº’", file=sys.stderr)
    print("="*60, file=sys.stderr)

    # è§£æé€‰é¡¹
    options_list = predefined_options_list or []

    # åˆ›å»ºç®€åŒ–çš„äº¤äº’
    print(f"\nğŸ“ AIåŠ©æ‰‹è¯·æ±‚:", file=sys.stderr)
    print(f"   {summary}", file=sys.stderr)

    if options_list:
        print(f"\nğŸ“‹ å¯é€‰é€‰é¡¹:", file=sys.stderr)
        for i, option in enumerate(options_list, 1):
            print(f"   {i}. {option}", file=sys.stderr)
        print(f"   {len(options_list) + 1}. ğŸ’¬ è‡ªå®šä¹‰è¾“å…¥", file=sys.stderr)

        try:
            choice = input(f"\nğŸ‘† è¯·é€‰æ‹© (1-{len(options_list) + 1}): ").strip()
            choice_num = int(choice)

            if 1 <= choice_num <= len(options_list):
                user_input = options_list[choice_num - 1]
                print(f"âœ… æ‚¨é€‰æ‹©äº†: {user_input}", file=sys.stderr)
            else:
                user_input = input("ğŸ’¬ è¯·è¾“å…¥æ‚¨çš„åé¦ˆ: ").strip()
                print(f"âœ… æ‚¨è¾“å…¥äº†: {user_input}", file=sys.stderr)
        except (ValueError, KeyboardInterrupt, EOFError):
            user_input = "ç”¨æˆ·å–æ¶ˆæ“ä½œ"
            print("âŒ æ“ä½œå·²å–æ¶ˆ", file=sys.stderr)
    else:
        try:
            user_input = input("\nğŸ’¬ è¯·è¾“å…¥æ‚¨çš„åé¦ˆ: ").strip()
            if user_input:
                print(f"âœ… æ‚¨è¾“å…¥äº†: {user_input}", file=sys.stderr)
        except (KeyboardInterrupt, EOFError):
            user_input = "ç”¨æˆ·å–æ¶ˆæ“ä½œ"
            print("âŒ æ“ä½œå·²å–æ¶ˆ", file=sys.stderr)

    print("="*60 + "\n", file=sys.stderr)

    # åˆ›å»ºç»“æœ
    result = {
        "content": [
            {
                "type": "text",
                "text": user_input or "æ— åé¦ˆ"
            }
        ],
        "metadata": {
            "mode": "fallback",
            "environment": "uvx_fallback",
            "version": "2.5.6"
        }
    }

    return result


def launch_feedback_ui(
    summary: str, predefined_options_list: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    Launches the feedback UI as a separate process using its command-line entry point.
    Collects user input and returns it as a structured dictionary.

    ä¿®æ”¹ç‰ˆæœ¬ï¼šæ·»åŠ  uvx ç¯å¢ƒæ£€æµ‹å’Œå…¼å®¹æ€§å¤„ç†
    Modified version: Added uvx environment detection and compatibility handling
    """
    # æ£€æµ‹ uvx ç¯å¢ƒ
    is_uvx = detect_uvx_environment()

    if is_uvx:
        print("æ£€æµ‹åˆ° uvx ç¯å¢ƒï¼Œä½¿ç”¨å…¼å®¹æ¨¡å¼", file=sys.stderr)
        try:
            # å°è¯•æ¨¡å—ç›´æ¥è°ƒç”¨
            return launch_feedback_ui_via_module(summary, predefined_options_list)
        except Exception as module_error:
            print(f"æ¨¡å—è°ƒç”¨å¤±è´¥: {module_error}", file=sys.stderr)
            print("é™çº§åˆ°ç®€åŒ–äº¤äº’æ¨¡å¼", file=sys.stderr)
            return launch_feedback_ui_fallback(summary, predefined_options_list)

    # åŸå§‹çš„å‘½ä»¤è¡Œè°ƒç”¨æ¨¡å¼ï¼ˆé uvx ç¯å¢ƒï¼‰
    tmp_file_path = None
    try:
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶
        with tempfile.NamedTemporaryFile(
            suffix=".json", delete=False, mode="w", encoding="utf-8"
        ) as tmp:
            tmp_file_path = tmp.name

        options_str = (
            "|||".join(predefined_options_list) if predefined_options_list else ""
        )

        # Build the argument list for the 'feedback-ui' command
        args_list = [
            "feedback-ui",
            "--prompt",
            summary,
            "--output-file",
            tmp_file_path,
            "--predefined-options",
            options_str,
        ]

        # Run the feedback-ui command
        process_result = subprocess.run(
            args_list,
            check=False,
            shell=False,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            stdin=subprocess.DEVNULL,
            close_fds=(
                os.name != "nt"
            ),  # close_fds is not supported on Windows when shell=False
            text=True,
            encoding="utf-8",
            errors="replace",
        )

        if process_result.returncode != 0:
            print(
                f"é”™è¯¯: å¯åŠ¨åé¦ˆUIå¤±è´¥ï¼Œè¿”å›ç : {process_result.returncode}",
                file=sys.stderr,
            )
            if process_result.stdout:
                print(f"UI STDOUT:\n{process_result.stdout}", file=sys.stderr)
            if process_result.stderr:
                print(f"UI STDERR:\n{process_result.stderr}", file=sys.stderr)

            # å¦‚æœå‘½ä»¤è¡Œè°ƒç”¨å¤±è´¥ï¼Œå°è¯•é™çº§æ¨¡å¼
            print("å‘½ä»¤è¡Œè°ƒç”¨å¤±è´¥ï¼Œå°è¯•é™çº§æ¨¡å¼", file=sys.stderr)
            return launch_feedback_ui_fallback(summary, predefined_options_list)

        with open(tmp_file_path, "r", encoding="utf-8") as f:
            ui_result_data = json.load(f)

        return ui_result_data

    except FileNotFoundError:
        print("é”™è¯¯: 'feedback-ui' å‘½ä»¤æœªæ‰¾åˆ°", file=sys.stderr)
        print("å°è¯•é™çº§æ¨¡å¼", file=sys.stderr)
        return launch_feedback_ui_fallback(summary, predefined_options_list)
    except Exception as e:
        print(f"é”™è¯¯: launch_feedback_ui å¼‚å¸¸: {e}", file=sys.stderr)
        print("å°è¯•é™çº§æ¨¡å¼", file=sys.stderr)
        return launch_feedback_ui_fallback(summary, predefined_options_list)
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if tmp_file_path and os.path.exists(tmp_file_path):
            try:
                os.unlink(tmp_file_path)
            except OSError as e_unlink:
                print(
                    f"è­¦å‘Š: åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ '{tmp_file_path}': {e_unlink}",
                    file=sys.stderr,
                )


@mcp.tool()
def interactive_feedback(
    message: Optional[str] = Field(
        default=None,
        description="[SIMPLE mode] Concise question for user input (AI must display full response in chat first)",
    ),
    full_response: Optional[str] = Field(
        default=None,
        description="[FULL mode] AI's complete response content (AI must display this in chat first)",
    ),
    predefined_options: Optional[List[str]] = Field(
        default=None, description="Predefined options for user selection"
    ),
) -> Tuple[Union[str, Image], ...]:  # è¿”å›å­—ç¬¦ä¸²å’Œ/æˆ– fastmcp.Image å¯¹è±¡çš„å…ƒç»„
    """
    Requests user input via GUI after AI displays complete response in chat.

    USAGE FLOW:
    1. AI displays complete response in chat dialog
    2. AI calls this tool to collect user input
    3. Tool returns user feedback only

    This tool collects user input, not for displaying AI responses.
    AI responses must appear in chat dialog before calling this tool.

    PARAMETER REQUIREMENTS:
    - AI MUST provide BOTH 'message' and 'full_response' parameters
    - Both parameters cannot be empty or whitespace-only
    - MCP service will automatically select which content to display based on user's display_mode setting

    USAGE PATTERN:

    # Step 1: AI displays complete response in chat
    # Step 2: AI calls tool with BOTH parameters
    interactive_feedback(
        message="ä½ å¸Œæœ›æˆ‘å®ç°è¿™äº›æ›´æ”¹å—ï¼Ÿ",  # Required: concise question
        full_response="æˆ‘åˆ†æäº†ä½ çš„ä»£ç ï¼Œå‘ç°äº†3ä¸ªé—®é¢˜...",  # Required: complete response
        predefined_options=["ä¿®å¤æ–¹æ¡ˆA", "ä¿®å¤æ–¹æ¡ˆB", "è®©æˆ‘æƒ³æƒ³"]
    )

    Note: MCP service automatically selects appropriate content based on user's display mode configuration.
    """

    # ä¸¥æ ¼çš„åŒå‚æ•°éªŒè¯ï¼šAIå¿…é¡»åŒæ—¶æä¾›ä¸¤ä¸ªæœ‰æ•ˆå‚æ•°
    if not _is_valid_param(message) or not _is_valid_param(full_response):
        return (ERROR_MESSAGES["missing_both_params"],)

    # è·å–é…ç½®ï¼ˆä¸€æ¬¡æ€§è¯»å–ï¼Œé¿å…é‡å¤ï¼‰
    config = get_config()
    display_mode = get_display_mode(config)

    # æ ¹æ®ç”¨æˆ·é…ç½®çš„æ˜¾ç¤ºæ¨¡å¼é€‰æ‹©è¦å±•ç¤ºçš„å†…å®¹
    prompt_to_display = full_response if display_mode == "full" else message

    # è§£ææœ€ç»ˆé€‰é¡¹
    final_options = resolve_final_options(
        ai_options=predefined_options, text=prompt_to_display, config=config
    )

    # è½¬æ¢ä¸ºUIéœ€è¦çš„æ ¼å¼ï¼ˆfinal_optionså·²ç»æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œæ— éœ€è½¬æ¢ï¼‰
    options_list_for_ui = final_options if final_options else None

    # å¯åŠ¨UIå¹¶è·å–ç”¨æˆ·è¾“å…¥
    ui_output_dict = launch_feedback_ui(prompt_to_display, options_list_for_ui)

    # å¤„ç†UIè¾“å‡ºå†…å®¹
    processed_mcp_content = _process_ui_output(ui_output_dict)

    if not processed_mcp_content:
        return (ERROR_MESSAGES["no_user_feedback"],)

    return tuple(processed_mcp_content)


@mcp.tool()
def optimize_user_input(
    original_text: str = Field(description="ç”¨æˆ·çš„åŸå§‹è¾“å…¥æ–‡æœ¬"),
    mode: str = Field(description="ä¼˜åŒ–æ¨¡å¼: 'optimize' æˆ– 'reinforce'"),
    reinforcement_prompt: Optional[str] = Field(
        default=None, description="åœ¨ 'reinforce' æ¨¡å¼ä¸‹ç”¨æˆ·çš„è‡ªå®šä¹‰æŒ‡ä»¤"
    ),
) -> str:
    """
    ä½¿ç”¨é…ç½®çš„ LLM API æ¥ä¼˜åŒ–æˆ–å¼ºåŒ–ç”¨æˆ·è¾“å…¥çš„æ–‡æœ¬ã€‚

    æ­¤åŠŸèƒ½å¯ä»¥å¸®åŠ©ç”¨æˆ·å°†å£è¯­åŒ–çš„ã€å¯èƒ½å­˜åœ¨æ­§ä¹‰çš„è¾“å…¥ï¼Œè½¬åŒ–ä¸ºæ›´ç»“æ„åŒ–ã€
    æ›´æ¸…æ™°ã€æ›´ä¾¿äº AI æ¨¡å‹ç†è§£çš„æ–‡æœ¬ã€‚

    Args:
        original_text: ç”¨æˆ·çš„åŸå§‹è¾“å…¥æ–‡æœ¬
        mode: ä¼˜åŒ–æ¨¡å¼
            - 'optimize': ä¸€é”®ä¼˜åŒ–ï¼Œä½¿ç”¨é¢„è®¾çš„é€šç”¨ä¼˜åŒ–æŒ‡ä»¤
            - 'reinforce': æç¤ºè¯å¼ºåŒ–ï¼Œä½¿ç”¨ç”¨æˆ·è‡ªå®šä¹‰çš„å¼ºåŒ–æŒ‡ä»¤
        reinforcement_prompt: åœ¨ 'reinforce' æ¨¡å¼ä¸‹ç”¨æˆ·çš„è‡ªå®šä¹‰æŒ‡ä»¤

    Returns:
        str: ä¼˜åŒ–åçš„æ–‡æœ¬æˆ–é”™è¯¯ä¿¡æ¯
    """
    try:
        # å¯¼å…¥LLMæ¨¡å—
        from .llm.factory import get_llm_provider
        from .llm.performance_manager import get_optimization_manager

        # è·å–é…ç½®
        config = get_config().get("expression_optimizer", {})

        # è·å–LLM provider
        provider, status_message = get_llm_provider(config)

        if not provider:
            return f"[ä¼˜åŒ–åŠŸèƒ½ä¸å¯ç”¨] {status_message}"

        # è·å–ç³»ç»Ÿæç¤ºè¯
        system_prompts = get_system_prompts()

        # éªŒè¯æ¨¡å¼å’Œå‚æ•°
        if mode == "optimize":
            system_prompt = system_prompts["optimize"]
        elif mode == "reinforce":
            if not reinforcement_prompt:
                return "[é”™è¯¯] 'reinforce' æ¨¡å¼éœ€è¦æä¾›å¼ºåŒ–æŒ‡ä»¤"
            system_prompt = system_prompts["reinforce"]
        else:
            return f"[é”™è¯¯] æ— æ•ˆçš„ä¼˜åŒ–æ¨¡å¼: {mode}ã€‚æ”¯æŒçš„æ¨¡å¼: 'optimize', 'reinforce'"

        # ç®€åŒ–é€»è¾‘ï¼šé»˜è®¤ä½¿ç”¨æ€§èƒ½ç®¡ç†å™¨ï¼ˆåŒ…å«ç¼“å­˜åŠŸèƒ½ï¼‰
        manager = get_optimization_manager(config)

        result = manager.optimize_with_cache(
            provider=provider,
            text=original_text,
            mode=mode,
            system_prompt=system_prompt,
            reinforcement=reinforcement_prompt or "",
        )

        # æ£€æŸ¥æ˜¯å¦æ˜¯é”™è¯¯ä¿¡æ¯
        if result.startswith("[ERROR"):
            return f"[ä¼˜åŒ–å¤±è´¥] {result}"

        return result

    except ImportError as e:
        return f"[é…ç½®é”™è¯¯] LLMæ¨¡å—å¯¼å…¥å¤±è´¥: {e}"
    except Exception as e:
        return f"[ç³»ç»Ÿé”™è¯¯] ä¼˜åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}"


def main():
    """Main function to run the MCP server."""
    mcp.run(transport="stdio")


if __name__ == "__main__":
    main()
