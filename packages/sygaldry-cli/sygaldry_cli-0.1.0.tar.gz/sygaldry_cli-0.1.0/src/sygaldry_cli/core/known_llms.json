{
  "openai": {
    "models": [
      "gpt-4o",
      "gpt-4o-mini",
      "gpt-4o-mini-high",
      "o3",
      "o3-mini",
      "o4-mini",
      "gpt-image-1",
      "gpt-4-turbo",
      "gpt-3.5-turbo"
    ],
    "documentation_url": "https://platform.openai.com/docs/models/overview"
  },
  "anthropic": {
    "models": [
      "claude-3-7-sonnet-20250219",
      "claude-3-7-sonnet-latest",
      "claude-3-5-sonnet-20241022",
      "claude-3-5-sonnet-latest",
      "claude-3-5-haiku-20241022",
      "claude-3-5-haiku-latest",
      "claude-3-opus-20240229",
      "claude-3-opus-latest",
      "claude-3-sonnet-20240229",
      "claude-3-haiku-20240307"
    ],
    "documentation_url": "https://docs.anthropic.com/claude/docs/models-overview"
  },
  "google": {
    "models": [
      "gemini-2.5-pro-preview-05-06",
      "gemini-2.5-flash-preview-05-20",
      "gemini-2.0-flash-001",
      "gemini-2.0-flash-lite-001",
      "gemini-1.5-pro-002",
      "gemini-1.5-flash-002",
      "gemini-1.5-pro-latest",
      "gemini-1.5-flash-latest"
    ],
    "documentation_url": "https://ai.google.dev/models/gemini"
  },
  "groq": {
    "models": [
      "gemma2-9b-it",
      "llama-3.3-70b-versatile",
      "llama-3.1-8b-instant",
      "llama3-70b-8192",
      "llama3-8b-8192",
      "meta-llama/llama-4-maverick-17b-128e-instruct",
      "meta-llama/llama-4-scout-17b-16e-instruct",
      "meta-llama/Llama-Guard-4-12B",
      "deepseek-r1-distill-llama-70b",
      "mistral-saba-24b",
      "compound-beta",
      "compound-beta-mini",
      "qwen-qwq-32b"
    ],
    "documentation_url": "https://console.groq.com/docs/models"
  },
  "xai": {
    "models": [
      "grok-1",
      "grok-1.5",
      "grok-1.5v"
    ],
    "documentation_url": "https://x.ai/science"
  },
  "mistral": {
    "models": [
      "codestral-2501",
      "codestral-latest",
      "mistral-large-2411",
      "mistral-large-latest",
      "pixtral-large-2411",
      "pixtral-large-latest",
      "mistral-medium-2505",
      "mistral-medium-latest",
      "mistral-saba-2502",
      "mistral-saba-latest",
      "ministral-3b-2410",
      "ministral-3b-latest",
      "ministral-8b-2410",
      "ministral-8b-latest",
      "mistral-embed",
      "mistral-moderation-2411",
      "mistral-moderation-latest",
      "mistral-ocr-2503",
      "mistral-ocr-latest",
      "devstral-small-2505",
      "devstral-small-latest",
      "mistral-small-2503",
      "mistral-small-latest",
      "pixtral-12b-2409",
      "open-mistral-nemo",
      "open-codestral-mamba",
      "open-mistral-7b",
      "open-mixtral-8x7b",
      "open-mixtral-8x22b"
    ],
    "documentation_url": "https://docs.mistral.ai/getting-started/models/models_overview/"
  },
  "cohere": {
    "models": [
      "command-a-03-2025",
      "command-a",
      "command-r7b-12-2024",
      "command-r-plus",
      "command-r-plus-04-2024",
      "command-r-08-2024",
      "command-r",
      "command-r-03-2024",
      "command",
      "command-light",
      "aya-expanse-32b",
      "aya-expanse-8b",
      "aya-23-8b",
      "aya-23-35b"
    ],
    "documentation_url": "https://docs.cohere.com/docs/models"
  },
  "ollama": {
    "models": [
      "llama4:scout",
      "llama4:maverick",
      "llama3.2:vision",
      "llama3.1",
      "gemma3",
      "gemma2-9b",
      "gemma2-27b",
      "qwen2.5vl",
      "qwen3",
      "mistral-small-3.1",
      "bakllava:7b",
      "vicuna:latest",
      "deepscaler:1.5b",
      "phi4",
      "aya-vision-32b",
      "aya-vision-8b"
    ],
    "documentation_url": "https://ollama.com/library"
  },
  "vllm": {
    "models": [
      "meta-llama/Meta-Llama-4-Scout-17B-16E-Instruct",
      "meta-llama/Meta-Llama-4-Maverick-17B-128E-Instruct",
      "meta-llama/Meta-Llama-3.2-90B-Vision-Instruct",
      "meta-llama/Meta-Llama-3.1-70B",
      "google/gemma-3-4b-it",
      "google/gemma-3-27b-it",
      "google/gemma-2-9b",
      "google/gemma-2-27b",
      "Qwen/Qwen2.5-VL-72B-Instruct",
      "Qwen/Qwen3-8B",
      "mistralai/Mistral-Small-3.1-24B-Instruct-2503",
      "mistralai/Mistral-7B-Instruct-v0.1",
      "mistralai/Mixtral-8x22B-v0.1",
      "CohereForAI/aya-vision-32b",
      "CohereForAI/aya-vision-8b",
      "databricks/dbrx-instruct",
      "deepseek-ai/DeepSeek-V3-Base",
      "microsoft/Phi-4",
      "microsoft/Phi-3-vision-128k-instruct"
    ],
    "documentation_url": "https://docs.vllm.ai/en/latest/models/supported_models.html"
  }
}
