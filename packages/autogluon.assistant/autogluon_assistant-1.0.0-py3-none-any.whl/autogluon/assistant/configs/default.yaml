# Tutorial Prompt Generator Configuration

per_execution_timeout: 86400

# Data Perception
max_file_group_size_to_show: 5
num_example_files_to_show: 1

max_chars_per_file: 1024
num_tutorial_retrievals: 20
max_num_tutorials: 5
max_user_input_length: 2048
max_error_message_length: 2048
max_tutorial_length: 8192
create_venv: false
condense_tutorials: True
use_tutorial_summary: True

# Default LLM Configuration
# For each agent (coder, etc.) you can use a different one
llm: &default_llm
  # Note: bedrock is only supported in limited AWS regions
  #       and requires AWS credentials
  provider: bedrock
  model: "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
  #provider: openai
  #model: gpt-4o-2024-08-06
  #provider: anthropic
  # model: claude-3-7-sonnet-20250219
  max_tokens: 16384
  proxy_url: null
  temperature: 1.
  verbose: True
  multi_turn: False
  template: null
  add_coding_format_instruction: false

coder:
  <<: *default_llm  # Merge llm_config
  temperature: 0.
  multi_turn: True
  top_p: 1

executer:
  <<: *default_llm  # Merge llm_config
  max_stdout_length: 8192
  max_stderr_length: 2048

reader:
  <<: *default_llm  # Merge llm_config
  details: False

error_analyzer:
  <<: *default_llm  # Merge llm_config

retriever:
  <<: *default_llm  # Merge llm_config

reranker:
  <<: *default_llm  # Merge llm_config

description_file_retriever:
  <<: *default_llm  # Merge llm_config

task_descriptor:
  <<: *default_llm  # Merge llm_config
  max_description_files_length_to_show: 1024
  max_description_files_length_for_summarization: 16384

tool_selector:
  <<: *default_llm  # Merge llm_config
