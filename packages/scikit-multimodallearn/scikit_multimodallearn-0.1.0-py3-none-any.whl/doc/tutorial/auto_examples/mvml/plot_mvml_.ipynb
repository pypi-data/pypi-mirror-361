{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# MVML\n\nDemonstration on how MVML (in file mvml.py) is intended to be used with very simple simulated dataset\n\nDemonstration uses scikit-learn for retrieving datasets and for calculating rbf kernel function, see\nhttp://scikit-learn.org/stable/\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import datasets\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics.pairwise import rbf_kernel\nfrom multimodal.kernels.mvml import MVML\nfrom multimodal.datasets.data_sample import DataSample\nfrom multimodal.tests.datasets.get_dataset_path import get_dataset_path\n\n\nnp.random.seed(4)\n\n# =========== create a simple dataset ============\n\nn_tot = 200\nhalf = int(n_tot/2)\nn_tr = 120\n\n# create a bit more data than needed so that we can take \"half\" amount of samples for each class\nX0, y0 = datasets.make_moons(n_samples=n_tot+2, noise=0.3, shuffle=False)\nX1, y1 = datasets.make_circles(n_samples=n_tot+2, noise=0.1, shuffle=False)\n\n# make multi-view correspondence (select equal number of samples for both classes and order the data same way\n# in both views)\n\nyinds0 = np.append(np.where(y0 == 0)[0][0:half], np.where(y0 == 1)[0][0:half])\nyinds1 = np.append(np.where(y1 == 0)[0][0:half], np.where(y1 == 1)[0][0:half])\n\nX0 = X0[yinds0, :]\nX1 = X1[yinds1, :]\nY = np.append(np.zeros(half)-1, np.ones(half))  # labels -1 and 1\n\n# show data\n# =========== create a simple dataset ============\n\nn_tot = 200\nhalf = int(n_tot/2)\nn_tr = 120\n\n# create a bit more data than needed so that we can take \"half\" amount of samples for each class\nX0, y0 = datasets.make_moons(n_samples=n_tot+2, noise=0.3, shuffle=False)\nX1, y1 = datasets.make_circles(n_samples=n_tot+2, noise=0.1, shuffle=False)\n\n# make multi-view correspondence (select equal number of samples for both classes and order the data same way\n# in both views)\n\nyinds0 = np.append(np.where(y0 == 0)[0][0:half], np.where(y0 == 1)[0][0:half])\nyinds1 = np.append(np.where(y1 == 0)[0][0:half], np.where(y1 == 1)[0][0:half])\n\nX0 = X0[yinds0, :]\nX1 = X1[yinds1, :]\nY = np.append(np.zeros(half)-1, np.ones(half))  # labels -1 and 1\n\n# show data\nplt.figure(figsize=(10., 8.))\nplt.subplot(121)\nplt.scatter(X0[:, 0], X0[:, 1], c=Y)\nplt.title(\"all data, view 1\")\nplt.subplot(122)\nplt.scatter(X1[:, 0], X1[:, 1], c=Y)\nplt.title(\"all data, view 2\")\nplt.show()\n\n# shuffle\norder = np.random.permutation(n_tot)\nX0 = X0[order, :]\nX1 = X1[order, :]\nY = Y[order]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "make kernel dictionaries\n################################\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "kernel_dict = {}\ntest_kernel_dict = {}\nkernel_dict[0] = rbf_kernel(X0[0:n_tr, :])\nkernel_dict[1] = rbf_kernel(X1[0:n_tr, :])\ntest_kernel_dict[0] = rbf_kernel(X0[n_tr:n_tot, :], X0[0:n_tr, :])\ntest_kernel_dict[1] = rbf_kernel(X1[n_tr:n_tot, :], X1[0:n_tr, :])\nx_dict = {}\nx_dict[0] = X0[0:n_tr, :]\nx_dict[1] = X1[0:n_tr, :]\ntest_x_dict = {}\ntest_x_dict[0] = X0[n_tr:n_tot, :]\ntest_x_dict[1] = X1[n_tr:n_tot, :]\n# d= DataSample(kernel_dict)\n# a = d.data\n#\n# =========== use MVML in classifying the data ============\n#  kernel precomputed\n# demo on how the code is intended to be used; parameters are not cross-validated, just picked some\n# # with approximation\n# # default: learn A, don't learn w   (learn_A=1, learn_w=0)\nmvml = MVML(lmbda=0.1, eta=1, nystrom_param=0.2, kernel='precomputed')\nmvml.fit(kernel_dict, Y[0:n_tr])\n\n\n#\n\npred1 = mvml.predict(test_kernel_dict)\n#\n# without approximation\nmvml2 = MVML(lmbda=0.1, eta=1, nystrom_param=1, kernel='precomputed')   # without approximation\nmvml2.fit(kernel_dict, Y[0:n_tr])\npred2 = mvml2.predict(test_kernel_dict)\n#\n# use MVML_Cov, don't learn w\nmvml3 = MVML(lmbda=0.1, eta=1,learn_A=3, nystrom_param=1, kernel='precomputed')\nmvml3.fit(kernel_dict, Y[0:n_tr])\npred3 = mvml3.predict(test_kernel_dict)\n#\n# use MVML_I, don't learn w\nmvml4 = MVML(lmbda=0.1, eta=1,learn_A=4, nystrom_param=1, kernel='precomputed')\nmvml4.fit(kernel_dict, Y[0:n_tr])\npred4 = mvml4.predict(test_kernel_dict)\n#\n# use kernel rbf equivalent to case 1\nmvml5 = MVML(lmbda=0.1, eta=1, nystrom_param=0.2, kernel='rbf')\nmvml5.fit(x_dict, Y[0:n_tr])\npred5 = mvml5.predict(test_x_dict)\n#\n#\n# # =========== show results ============\n#\n# # accuracies\nacc1 = accuracy_score(Y[n_tr:n_tot], pred1)\nacc2 = accuracy_score(Y[n_tr:n_tot], pred2)\nacc3 = accuracy_score(Y[n_tr:n_tot], pred3)\nacc4 = accuracy_score(Y[n_tr:n_tot], pred4)\nacc5 = accuracy_score(Y[n_tr:n_tot], pred5)\n#\n# # display obtained accuracies\n#\nprint(\"MVML:       \", acc1)\nprint(\"MVMLsparse: \", acc2)\nprint(\"MVML_Cov:   \", acc3)\nprint(\"MVML_I:     \", acc4)\nprint(\"MVML_rbf:   \", acc5)\n#\n#\n# # plot data and some classification results\n#\nplt.figure(2, figsize=(10., 8.))\nplt.subplot(341)\nplt.scatter(X0[n_tr:n_tot, 0], X0[n_tr:n_tot, 1], c=Y[n_tr:n_tot])\nplt.title(\"orig. view 1\")\nplt.subplot(342)\nplt.scatter(X1[n_tr:n_tot, 0], X1[n_tr:n_tot, 1], c=Y[n_tr:n_tot])\nplt.title(\"orig. view 2\")\n#\npred1[np.where(pred1[:] != Y[n_tr:n_tot])] = 0\npred1 = pred1.reshape((pred1.shape[0]))\nplt.subplot(343)\nplt.scatter(X0[n_tr:n_tot, 0], X0[n_tr:n_tot, 1], c=pred1)\nplt.title(\"MVML view 1\")\nplt.subplot(344)\nplt.scatter(X1[n_tr:n_tot, 0], X1[n_tr:n_tot, 1], c=pred1)\nplt.title(\"MVML view 2\")\n#\npred2[np.where(pred2[:] != Y[n_tr:n_tot])] = 0\npred2 = pred2.reshape((pred2.shape[0]))\nplt.subplot(345)\nplt.scatter(X0[n_tr:n_tot, 0], X0[n_tr:n_tot, 1], c=pred2)\nplt.title(\"MVMLsparse view 1\")\nplt.subplot(346)\nplt.scatter(X1[n_tr:n_tot, 0], X1[n_tr:n_tot, 1], c=pred2)\nplt.title(\"MVMLsparse view 2\")\n#\npred3[np.where(pred3[:] != Y[n_tr:n_tot])] = 0\npred3 = pred3.reshape((pred3.shape[0]))\n#\nplt.subplot(347)\nplt.scatter(X0[n_tr:n_tot, 0], X0[n_tr:n_tot, 1], c=pred3)\nplt.title(\"MVML_Cov view 1\")\nplt.subplot(348)\nplt.scatter(X1[n_tr:n_tot, 0], X1[n_tr:n_tot, 1], c=pred3)\nplt.title(\"MVML_Cov view 2\")\n#\npred4[np.where(pred4[:] != Y[n_tr:n_tot])] = 0\npred4 = pred4.reshape((pred4.shape[0]))\nplt.subplot(349)\nplt.scatter(X0[n_tr:n_tot, 0], X0[n_tr:n_tot, 1], c=pred4)\nplt.title(\"MVML_I view 1\")\nplt.subplot(3,4,10)\nplt.scatter(X1[n_tr:n_tot, 0], X1[n_tr:n_tot, 1], c=pred4)\nplt.title(\"MVML_I view 2\")\n#\npred5[np.where(pred5[:] != Y[n_tr:n_tot])] = 0\npred5 = pred5.reshape((pred5.shape[0]))\nplt.subplot(3,4,11)\nplt.scatter(X0[n_tr:n_tot, 0], X0[n_tr:n_tot, 1], c=pred5)\nplt.title(\"MVML_rbf_kernel view 1\")\nplt.subplot(3,4,12)\nplt.scatter(X1[n_tr:n_tot, 0], X1[n_tr:n_tot, 1], c=pred5)\nplt.title(\"MVML_rbf_kernel view 2\")\n#\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}