# Example configuration file for Multiagent Debugger

# Paths to log files
log_paths:
  - /var/log/myapp/app.log
  - /var/log/nginx/access.log

# Path to codebase
code_path: /home/user/projects/order-service

# LLM configuration
llm:
  # Provider (openai, anthropic, google, ollama)
  provider: openai
  
  # Model name
  model_name: gpt-4
  
  # API key (optional, can use environment variable instead)
  # api_key: your_api_key_here
  
  # Base URL for the API (for custom endpoints)
  # api_base: https://api.openai.com/v1
  
  # Temperature for LLM generation
  temperature: 0.1
  
  # Additional provider-specific parameters
  additional_params:
    # max_tokens: 4096
    # top_p: 1.0

# Enable verbose logging (optional, defaults to false)
verbose: false 