# serializer version: 1
# name: test_docs_dir[CHANGELOG.md]
  '''
  ```{include} ../../CHANGELOG.md
  ```
  
  '''
# ---
# name: test_docs_dir[CONTRIBUTING.md]
  '''
  ```{include} ../../CONTRIBUTING.md
  ```
  
  '''
# ---
# name: test_docs_dir[conf.py]
  '''
  # Configuration file for the Sphinx documentation builder.
  #
  # For the full list of built-in configuration values, see the documentation:
  # https://www.sphinx-doc.org/en/master/usage/configuration.html
  
  # -- Project information -----------------------------------------------------
  # https://www.sphinx-doc.org/en/master/usage/configuration.html#project-information
  
  import os
  import sys
  from datetime import datetime
  from importlib import metadata
  
  # If extensions (or modules to document with autodoc) are in another directory,
  # add these directories to sys.path here. If the directory is relative to the
  # documentation root, use os.path.abspath to make it absolute, like shown here.
  sys.path.insert(0, os.path.abspath('...'))
  sys.path.insert(0, os.path.abspath('..'))
  sys.path.insert(0, os.path.abspath('.'))
  
  # -- General configuration ---------------------------------------------------
  # https://www.sphinx-doc.org/en/master/usage/configuration.html#general-configuration
  
  extensions = [
      # auto generate API documents from Python docstrings
      'sphinx.ext.autodoc',
      # used when publishing to GitHub pages: turns off GitHub's jekyll default
      'sphinx.ext.githubpages',
      # allow cross-linking to other project's sphinx-based docs
      'sphinx.ext.intersphinx',
      # for use with autodoc: adds support for Google and NumPy style docstrings
      'sphinx.ext.napoleon',
      # links to Python source code from documentation
      'sphinx.ext.viewcode',
      # adds a copy button to code blocks
      'sphinx_copybutton',
      # generate open graph metadata for docs pages
      'sphinxext.opengraph',
      # use MyST parser for markdown files in Sphinx documentation
      'myst_parser',
  ]
  
  # extensions for the MyST markdown parser
  # https://myst-parser.readthedocs.io/en/latest/syntax/optional.html
  myst_enable_extensions = [
      'colon_fence',
      'fieldlist',
      'replacements',
      'tasklist',
  ]
  
  # Settings from the copybutton's config
  # https://github.com/executablebooks/sphinx-copybutton/blob/master/docs/conf.py
  # There are useful for ensuring that the copy button only copies code
  # (as prefixed by ">>>" for example) and not the prompt or the output.
  copybutton_prompt_text = r'>>> |\.\.\. |\$ |In \[\d*\]: | {2,5}\.\.\.: | {5,8}: '
  copybutton_prompt_is_regexp = True
  copybutton_line_continuation_character = '\\'
  copybutton_here_doc_delimiter = 'EOT'
  copybutton_selector = 'div:not(.no-copybutton) > div.highlight > pre'
  templates_path = ['_templates']
  exclude_patterns = []
  
  # The suffix(es) of source filenames.
  # You can specify multiple suffix as a list of string:
  source_suffix = ['.rst', '.md']
  
  # The encoding of source files.
  # source_encoding = 'utf-8-sig'
  
  # The master toctree document.
  master_doc = 'index'
  
  # project information
  now = datetime.now()
  project = 'transporter_logs'
  copyright = f'{now.year}, Miles O&#39;Brien | Last update {now.strftime("%B %d, %Y")}'
  author = 'Miles O&#39;Brien'
  
  version = metadata.version('transporter_logs')
  release = version
  
  # The language for content autogenerated by Sphinx. Refer to documentation
  # for a list of supported languages.
  language = 'en'
  
  # List of patterns, relative to source directory, that match files and
  # directories to ignore when looking for source files.
  exclude_patterns = ['_build']
  
  # The name of the Pygments (syntax highlighting) style to use.
  pygments_style = 'monokai'
  
  # If true, `todo` and `todoList` produce output, else they produce nothing.
  todo_include_todos = False
  
  # -- Options for HTML output -------------------------------------------------
  # https://www.sphinx-doc.org/en/master/usage/configuration.html#options-for-html-output
  
  html_theme = 'alabaster'
  html_static_path = ['_static']
  
  # Theme options are theme-specific and customize the look and feel of a theme
  # further. For a list of options available for each theme, see the
  # documentation.
  html_theme_options = {
      'description': f'An app for parsin&#39; &#34;transporter logs&#34;\n{release}',
      # 'github_user': '',
      # 'github_repo': '',
      # 'github_banner': True,
      # 'github_button': False,
      'font_family': "'Roboto', Georgia, sans",
      'head_font_family': "'Roboto', Georgia, serif",
      'code_font_family': "'Roboto Mono', 'Consolas', monospace",
      'pre_bg': '#433e56',
  }
  
  # Add any paths that contain custom themes here, relative to this directory.
  # html_theme_path = []
  
  # The name for this set of Sphinx documents.  If None, it defaults to
  # "<project> v<release> documentation".
  # html_title = None
  
  # A shorter title for the navigation bar.  Default is the same as html_title.
  # html_short_title = None
  
  # The name of an image file (relative to this directory) to place at the top
  # of the sidebar.
  # html_logo = None
  
  # The name of an image file (within the static path) to use as favicon of the
  # docs.  This file should be a Windows icon file (.ico) being 16x16 or 32x32
  # pixels large.
  # html_favicon = None
  
  # Add any paths that contain custom static files (such as style sheets) here,
  # relative to this directory. They are copied after the builtin static files,
  # so a file named "default.css" will overwrite the builtin "default.css".
  html_static_path = ['_static']
  
  # These paths are either relative to html_static_path
  # or fully qualified paths (eg. https://...)
  html_css_files = [
      'custom.css',
  ]
  
  # Add any extra paths that contain custom files (such as robots.txt or
  # .htaccess) here, relative to this directory. These files are copied
  # directly to the root of the documentation.
  # html_extra_path = []
  
  # If not '', a 'Last updated on:' timestamp is inserted at every page bottom,
  # using the given strftime format.
  html_last_updated_fmt = '%b %d, %Y'
  
  # If true, SmartyPants will be used to convert quotes and dashes to
  # typographically correct entities.
  # html_use_smartypants = True
  
  # Custom sidebar templates, maps document names to template names.
  # html_sidebars = {
  #     '**': [
  #         'about.html',
  #         'navigation.html',
  #         'relations.html',
  #         'searchbox.html',
  #     ]
  # }
  
  # Additional templates that should be rendered to pages, maps page names to
  # template names.
  # html_additional_pages = {}
  
  # If false, no module index is generated.
  # html_domain_indices = True
  
  # If false, no index is generated.
  # html_use_index = True
  
  # If true, the index is split into individual pages for each letter.
  # html_split_index = False
  
  # If true, links to the reST sources are added to the pages.
  # html_show_sourcelink = True
  
  # If true, "Created using Sphinx" is shown in the HTML footer. Default is True.
  html_show_sphinx = False
  
  # If true, "(C) Copyright ..." is shown in the HTML footer. Default is True.
  # html_show_copyright = True
  
  # If true, an OpenSearch description file will be output, and all pages will
  # contain a <link> tag referring to it.  The value of this option must be the
  # base URL from which the finished HTML is served.
  # html_use_opensearch = ''
  
  # This is the file name suffix for HTML files (e.g. ".xhtml").
  # html_file_suffix = None
  
  # Language to be used for generating the HTML full-text search index.
  # Sphinx supports the following languages:
  #   'da', 'de', 'en', 'es', 'fi', 'fr', 'hu', 'it', 'ja'
  #   'nl', 'no', 'pt', 'ro', 'ru', 'sv', 'tr'
  # html_search_language = 'en'
  
  # A dictionary with options for the search language support, empty by default.
  # Now only 'ja' uses this config value
  # html_search_options = {'type': 'default'}
  
  # Output file base name for HTML help builder.
  # htmlhelp_basename = ""
  
  '''
# ---
# name: test_docs_dir[index.rst]
  '''
  .. transporter_logs documentation index file,
     You can adapt this file completely to your liking, but it should at least
     contain the root `toctree` directive.
  
  .. toctree::
     :hidden:
     :maxdepth: 2
     :caption: Contents:
  
     usage
     CONTRIBUTING
     CHANGELOG
  
  .. include:: readme.md
     :parser: myst_parser.sphinx_
  '''
# ---
# name: test_docs_dir[readme.md]
  '''
  ```{include} ../../README.md
  ```
  
  '''
# ---
# name: test_docs_dir[usage.md]
  '''
  # Using transporter_logs
  
  This page contains information about using transporter_logs.
  
  '''
# ---
# name: test_gh_workflows[ci.yaml]
  '''
  name: CI
  
  on:
    push:
      branches:
        - main
    pull_request:
    workflow_dispatch:
  
  permissions:
    contents: read
  
  env:
    FORCE_COLOR: "1"
    PIP_DISABLE_PIP_VERSION_CHECK: "1"
    PIP_NO_PYTHON_VERSION_WARNING: "1"
  
  jobs:
  
    lint:
      name: Run linter
      runs-on: ubuntu-latest
  
      steps:
        - name: Checkout üõéÔ∏è
          uses: actions/checkout@v4
          with:
            persist-credentials: false
  
        - name: Install uv üåü
          uses: astral-sh/setup-uv@22695119d769bdb6f7032ad67b9bca0ef8c4a174 #v5.4.0
          with:
              version: ">=0.0.1"
  
        - name: Lint üßπ
          run: |
            uv tool install ruff
            ruff check
  
    tests:
      name: Run tests
      runs-on: ubuntu-latest
      strategy:
        matrix:
          python-version: ["3.9", "3.10", "3.11", "3.12", "3.13"]
  
  
      steps:
        - name: Checkout üõéÔ∏è
          uses: actions/checkout@v4
          with:
            persist-credentials: false
  
        - name: Install uv üåü
          uses: astral-sh/setup-uv@22695119d769bdb6f7032ad67b9bca0ef8c4a174 #v5.4.0
          with:
              python-version: ${{ matrix.python-version }}
              version: ">=0.0.1"
  
        - name: Test with python ${{ matrix.python-version }} üß™
          run: |
            uv run --frozen coverage run \
              --data-file .coverage.${{ matrix.python-version }} \
              -m pytest
  
        - name: Upload coverage data üì§
          uses: actions/upload-artifact@v4
          with:
            name: coverage-data-${{ matrix.python-version }}
            path: .coverage.*
            include-hidden-files: true
            if-no-files-found: ignore
  
    coverage:
      # https://hynek.me/articles/ditch-codecov-python/
      name: Combine coverage reports & fail if below threshold
      runs-on: ubuntu-latest
      needs: tests
      if: always()
  
      steps:
        - name: Checkout üõéÔ∏è
          uses: actions/checkout@v4
          with:
            persist-credentials: false
  
        - name: Install uv üåü
          uses: astral-sh/setup-uv@22695119d769bdb6f7032ad67b9bca0ef8c4a174 #v5.4.0
          with:
            version: '>=0.0.1'
  
        - name: Download coverage data üì•
          uses: actions/download-artifact@v4
          with:
            pattern: coverage-data-*
            merge-multiple: true
  
        - name: Generate coverage report üìä
          run: |
            uv tool install 'coverage[toml]'
  
            coverage combine
            coverage html --skip-covered --skip-empty
            coverage report --format=markdown >> $GITHUB_STEP_SUMMARY
  
            # Generate report again, this time with a fail-under threshold
            coverage report --fail-under=80
  
        - name: Upload HTML report if coverage check fails
          uses: actions/upload-artifact@v4
          with:
              name: html-cov-report
              path: htmlcov
          if: ${{ failure() }}
  
  '''
# ---
# name: test_gh_workflows[publish-pypi.yaml]
  '''
  # .github/workflows/publish-pypi.yml
  
  # This workflow uses PyPI's trusted publisher feature to publish the package
  # to PyPI and TestPyPI. The trusted publisher enables PyPI updates without
  # needing to store secrets in the repository.
  # There are three prerequisites:
  # 1. Create two GitHub environments named `pypi` and `pypi-test` in the
  # project's repository
  # (if you use a different environment names, change the environment names
  # below to match)
  # 2. Add a "required reviewers" deployment protection rule to the
  # `pypi` environment
  # 3. Set up a trusted publisher on PyPI and TestPyPI for the project
  # Note: the pypi.org and test.pypi.org urls in this workflow
  # should be set to the name of your package on PyPI.
  
  # Full documentation about this process:
  # https://packaging.python.org/en/latest/guides/publishing-package-distribution-releases-using-github-actions-ci-cd-workflows/
  
  name: Publish to PyPI and TestPyPI and create GitHub release
  
  on:
    push:
      tags:
        # only run workflow for tags in release format
        - "v[0-9]+.[0-9]+.[0-9]+"
      branches:
        - main
  
  permissions:
    contents: read
  
  jobs:
    build:
      name: Build distribution üì¶
      runs-on: ubuntu-latest
      outputs:
        # set publish_to_pypi to 'true' to publish to PyPI after
        # tagging a release (requires trusted publisher setup on PyPI)
        publish_to_pypi: 'false'
        publish_to_testpypi: 'false'
  
      steps:
        - name: Checkout üõéÔ∏è
          uses: actions/checkout@v4
          with:
            fetch-depth: 0
            persist-credentials: false
  
        - name: Set up Python üêç
          uses: actions/setup-python@v5
  
        - name: Install uv üåü
          uses: astral-sh/setup-uv@22695119d769bdb6f7032ad67b9bca0ef8c4a174 #v5.4.0
          with:
            version: ">=0.0.1"
  
        - name: Build package for distribution üõ†Ô∏è
          run: |
            uv build
  
        - name: Upload distribution packages üì§
          uses: actions/upload-artifact@v4
          with:
            name: package-distribution
            path: dist/
  
    publish-to-pypi:
      name: Publish Python distribution to PyPI
      if: startsWith(github.ref, 'refs/tags/')  # only publish to PyPI on tag pushes
      needs:
      - build
      runs-on: ubuntu-latest
      if: ${{ needs.build.outputs.publish_to_pypi == 'true' }}
      environment:
        name: pypi
        url: https://pypi.org/p/transporter_logs
      permissions:
         id-token: write  # needed for trusted publishing (i.e., OIDC)
  
      steps:
      - name: Download distribution artifacts üì•
        uses: actions/download-artifact@v4
        with:
          name: package-distribution
          path: dist/
      - name: Publish distribution to PyPI üöÄ
        uses: pypa/gh-action-pypi-publish@76f52bc884231f62b9a034ebfe128415bbaabdfc #v1.12.4
  
    github-release:
      name: >-
        Sign the Python distribution with Sigstore
        and upload them to GitHub Release
      needs:
      - publish-to-pypi
      runs-on: ubuntu-latest
  
      permissions:
        contents: write  # required for creating GitHub Releases
        id-token: write  # required for sigstore
  
      steps:
      - name: Download distribution artifacts üì•
        uses: actions/download-artifact@v4
        with:
          name: package-distribution
          path: dist/
      - name: Sign the dists with Sigstore üìù
        uses: sigstore/gh-action-sigstore-python@f514d46b907ebcd5bedc05145c03b69c1edd8b46 #v3.0.0
        with:
          inputs: >-
            ./dist/*.tar.gz
            ./dist/*.whl
      - name: Create GitHub Release üõ†Ô∏è
        env:
          GITHUB_TOKEN: ${{ github.token }}
        run: >-
          gh release create
          "$GITHUB_REF_NAME"
          --repo "$GITHUB_REPOSITORY"
      - name: Upload artifact signatures to GitHub Release üì§
        env:
          GITHUB_TOKEN: ${{ github.token }}
        # Upload to GitHub Release.
        # `dist/` contains the built packages, and the
        # sigstore-produced signatures and certificates.
        run: >-
          gh release upload
          "$GITHUB_REF_NAME" dist/**
          --repo "$GITHUB_REPOSITORY"
  
    publish-to-testpypi:
      name: Publish Python distribution to test PyPI
      needs:
      - build
      runs-on: ubuntu-latest
      if: ${{ needs.build.outputs.publish_to_testpypi == 'true' }}
      environment:
        name: pypi-test
        url: https://test.pypi.org/p/transporter_logs
      permissions:
         id-token: write  # needed for trusted publishing (i.e., OIDC)
  
      steps:
      - name: Download distribution artifacts üì•
        uses: actions/download-artifact@v4
        with:
          name: package-distribution
          path: dist/
      - name: Publish distribution to test PyPI üöÄ
        uses: pypa/gh-action-pypi-publish@76f52bc884231f62b9a034ebfe128415bbaabdfc #v1.12.4
        with:
          repository-url: https://test.pypi.org/legacy/
  
  '''
# ---
# name: test_meta_files[CHANGELOG.md]
  '''
  # Changelog
  
  All notable changes to transporter_logs are documented here.
  
  The format is based on [Keep a Changelog](https://keepachangelog.com), and the
  project uses [Semantic Versioning](https://semver.org/).
  
  '''
# ---
# name: test_meta_files[CONTRIBUTING.md]
  '''
  # Contributing to transporter_logs
  
  ## Reporting bugs
  
  If something isn't working as described, or if you find a mistake in the
  documentation, please feel free to report a bug by opening an issue.
  
  ## Contributing to the code base
  
  Contributions to the code base are welcome. If you want to add a new feature,
  please open an issue before doing any work, to ensure that the suggestion
  aligns with the project's goals and overall direction.
  
  If you'd like to tackle an existing issue, please leave a comment on it.
  
  ### Creating your local development environment
  
  For contributing to this code base, you'll need:
  
  - A [GitHub account](https://github.com/)
  - [Git](https://git-scm.com/) installed on your machine
  - **optional**: [uv](https://docs.astral.sh/uv/getting-started/installation/)
  (the Python-based directions below use `uv`, but if you
  already have a preferred Python toolset, that should work too)
  
  > [!IMPORTANT]
  > If you have an active Python virtual environment (for example, conda's
  > base environment), you'll need to deactivate it before following the
  > instructions below.
  
  #### Configure git
  
  1. On GitHub, [fork](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/working-with-forks/fork-a-repo) this repository.
  
  2. Clone the forked repository to your machine:
  
      ```sh
      git clone https://github.com/<your github username>/<this-repo-name>.git
      cd <this-repo-name>
      ```
  
  3. **optional:** Set the `upstream` remote to sync your fork with this
  repository:
  
      ```sh
      git remote add upstream https://github.com/<this-repo-owner-or-org-name>/<this-repo-name>.git
      git fetch upstream
      ```
  
  #### Install project and dependencies
  
  1. From the root of the repo, create a virtual environment and install the
  project dependencies. The
  [`uv sync` command](https://docs.astral.sh/uv/reference/cli/#uv-sync) handles
  installing Python, creating a virtual environment, and installing project
  dependencies.
  
      ```sh
      uv sync
      ```
  
     (More information about how uv
      [finds or downloads a Python interpreter](https://docs.astral.sh/uv/reference/cli/#uv-python))
  
  2. Run the test suite to check that everything works correctly:
  
      > [!TIP]
      > Prefixing python commands with `uv run` instructs uv to run the command
      > in the project's virtual environment, even if you haven't explicitly
      > activated it.
  
      ```sh
      uv run pytest
      ```
  
  3. Install the `pre-commit` hooks used for linting and other checks (this may
  take a few minutes but only needs to be done once).
  
      ```sh
      uv run pre-commit install
      ```
  
  4. Make sure the `pre-commit` checks are working correctly:
  
      ```sh
      uv run pre-commit install
      ```
  
  ### Updating your development environment
  
  If time has passed between your initial project setup and when you make changes
  to the code, make sure your fork and development environment are up-to-date.
  
  1. Sync your fork to the upstream repository:
  
      ```sh
      git checkout main
      git fetch upstream
      git rebase upstream/main
      git push origin main
      ```
  
  2. Update your project dependencies:
  
      ```sh
      uv sync
      ```
  
  ### Adding project dependencies
  
  If your change requires a new dependency, add it as follows:
  
  ```sh
  uv add <dependency>
  ```
  
  The [`uv add`](https://docs.astral.sh/uv/reference/cli/#uv-add) command will:
  
  - Add the dependency to `pyproject.toml`
  - Install the dependency into the project's virtual environment
  - Update the project's lockfile (`uv.lock`)
  
  Make sure to commit the updated versions of `pyproject.toml` and `uv.lock`.
  
  ### Updating documentation
  
  This project uses [Sphinx](https://www.sphinx-doc.org/en/master/) and
  [MyST-flavored markdown](https://myst-parser.readthedocs.io/en/latest/index.html)
  for documentation.
  
  Documentation updates should be made in `docs/source`. To preview
  changes:
  
  ```bash
  uv run --group docs sphinx-autobuild docs/source docs/_build/html
  ```
  
  The output of the above command provides a URL for viewing the documentation via a
  local server (usually [http://127.0.0.1:8000](http://127.0.0.1:8000)).
  
  ### Submitting code changes
  
  After you've completed the changes described in the issue you're working on,
  you can submit them by
  [creating a pull request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request-from-a-fork)
  (PR) to this repository.
  
  Please ensure the following are true before creating the PR:
  
  - Your change is covered by tests, if applicable
  - Project documentation is updated, if applicable
  - All tests pass (`uv run pytest`)
  - All pre-commit checks are successful
  (these checks will run automatically as you make commits)
  - The `[Unreleased]` section of [CHANGELOG.md](CHANGELOG.md) contains a
  description of your change.
  
  The PR itself should:
  
  - Have a descriptive title
  - Be [linked to its corresponding issue](https://docs.github.com/en/issues/tracking-your-work-with-issues/using-issues/linking-a-pull-request-to-an-issue)
  in the description.
  - Have a description that includes any other information or context that will
  help a code reviewer understand your changes.
  
  '''
# ---
# name: test_meta_files[LICENSE]
  '''
  MIT License
  
  Copyright (c) 2025 Miles O'Brien
  
  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to deal
  in the Software without restriction, including without limitation the rights
  to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
  copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:
  
  The above copyright notice and this permission notice shall be included in all
  copies or substantial portions of the Software.
  
  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
  OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
  SOFTWARE.
  '''
# ---
# name: test_meta_files[README.md]
  '''
  # transporter_logs
  
  An app for parsin' "transporter logs"
  
  ## Project setup
  
  See [CONTRIBUTING.md](CONTRIBUTING.md) for instructions on setting up a
  development environment for transporter_logs.
  
  '''
# ---
# name: test_pyproject_docs
  dict({
    'build-system': dict({
      'build-backend': 'setuptools.build_meta',
      'requires': list([
        'setuptools>=45',
        'wheel',
        'setuptools_scm>=8',
      ]),
    }),
    'dependency-groups': dict({
      'dev': list([
        'coverage',
        'pre-commit',
        'pytest',
        'pytest-random-order>=1.1.1',
        'ruff',
      ]),
      'docs': list([
        'myst-parser>=3.0.1',
        'sphinx>=7.4.7',
        'sphinx-autobuild>=2024.10.3',
        'sphinx-copybutton>=0.5.2',
        'sphinxext-opengraph>=0.9.1',
      ]),
    }),
    'project': dict({
      'authors': list([
        dict({
          'name': "Miles O'Brien",
        }),
      ]),
      'dependencies': list([
        'rich',
        'structlog',
      ]),
      'description': 'An app for parsin\' "transporter logs"',
      'dynamic': list([
        'version',
      ]),
      'license': 'MIT',
      'maintainers': list([
        dict({
          'name': "Miles O'Brien",
        }),
      ]),
      'name': 'transporter_logs',
      'readme': 'README.md',
      'requires-python': '>=3.9',
      'scripts': dict({
        'transporter_logs': 'transporter_logs.app:main',
      }),
      'urls': dict({
      }),
    }),
    'tool': dict({
      'pytest': dict({
        'ini_options': dict({
          'addopts': '--random-order',
          'testpaths': list([
            'test',
          ]),
        }),
      }),
      'ruff': dict({
        'format': dict({
          'quote-style': 'single',
        }),
        'line-length': 120,
        'lint': dict({
          'extend-select': list([
            'I',
            'Q',
          ]),
          'flake8-quotes': dict({
            'inline-quotes': 'single',
          }),
        }),
      }),
      'setuptools': dict({
        'packages': dict({
          'find': dict({
            'namespaces': True,
            'where': list([
              'src',
            ]),
          }),
        }),
      }),
      'setuptools_scm': dict({
        'fallback_version': '0.0.0.dev0',
        'local_scheme': 'no-local-version',
      }),
    }),
  })
# ---
# name: test_pyproject_no_docs
  dict({
    'build-system': dict({
      'build-backend': 'setuptools.build_meta',
      'requires': list([
        'setuptools>=45',
        'wheel',
        'setuptools_scm>=8',
      ]),
    }),
    'dependency-groups': dict({
      'dev': list([
        'coverage',
        'pre-commit',
        'pytest',
        'pytest-random-order>=1.1.1',
        'ruff',
      ]),
    }),
    'project': dict({
      'authors': list([
        dict({
          'name': "Miles O'Brien",
        }),
      ]),
      'dependencies': list([
        'rich',
        'structlog',
      ]),
      'description': 'An app for parsin\' "transporter logs"',
      'dynamic': list([
        'version',
      ]),
      'license': 'MIT',
      'maintainers': list([
        dict({
          'name': "Miles O'Brien",
        }),
      ]),
      'name': 'transporter_logs',
      'readme': 'README.md',
      'requires-python': '>=3.9',
      'scripts': dict({
        'transporter_logs': 'transporter_logs.app:main',
      }),
      'urls': dict({
      }),
    }),
    'tool': dict({
      'pytest': dict({
        'ini_options': dict({
          'addopts': '--random-order',
          'testpaths': list([
            'test',
          ]),
        }),
      }),
      'ruff': dict({
        'format': dict({
          'quote-style': 'single',
        }),
        'line-length': 120,
        'lint': dict({
          'extend-select': list([
            'I',
            'Q',
          ]),
          'flake8-quotes': dict({
            'inline-quotes': 'single',
          }),
        }),
      }),
      'setuptools': dict({
        'packages': dict({
          'find': dict({
            'namespaces': True,
            'where': list([
              'src',
            ]),
          }),
        }),
      }),
      'setuptools_scm': dict({
        'fallback_version': '0.0.0.dev0',
        'local_scheme': 'no-local-version',
      }),
    }),
  })
# ---
# name: test_src_dir[__init__.py]
  '''
  """transporter_logs initialization."""
  
  '''
# ---
# name: test_src_dir[app.py]
  '''
  import structlog
  from rich.console import Console
  from rich.panel import Panel
  
  from transporter_logs.logging import setup_logging
  
  setup_logging()
  logger = structlog.get_logger()
  
  
  def main():
      """transporter_logs starting point."""
      logger.info('starting transporter_logs...')
  
      console = Console()
      console.print(
          Panel(
              ':tada: Hello from the transporter_logs Python package!',
              border_style='green',
              expand=False,
              padding=(1, 4),
              subtitle='[italic]created by pyprefab[/italic]',
              subtitle_align='right',
              title='transporter_logs',
              title_align='left',
          )
      )
  
  
  if __name__ == '__main__':
      main()
  
  
  '''
# ---
# name: test_src_dir[logging.py]
  '''
  """transporter_logs logging configuration."""
  
  import sys
  
  import structlog
  
  
  def setup_logging():
      shared_processors = [
          structlog.processors.TimeStamper(fmt='%Y-%m-%d %H:%M:%S'),
          structlog.processors.add_log_level,
      ]
  
      if sys.stderr.isatty():
          # If we're in a terminal, pretty print the logs.
          processors = shared_processors + [
              structlog.dev.ConsoleRenderer(),
          ]  # pragma: no cover
      else:
          # Otherwise, output logs in JSON format
          processors = shared_processors + [
              structlog.processors.dict_tracebacks,
              structlog.processors.JSONRenderer(),
          ]
  
      structlog.configure(
          processors=processors,
          cache_logger_on_first_use=True,
      )
  
  '''
# ---
