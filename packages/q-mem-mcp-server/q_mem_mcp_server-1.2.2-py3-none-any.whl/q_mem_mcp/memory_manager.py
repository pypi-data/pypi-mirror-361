"""
Memory Manager using ChromaDB + HuggingFace for Amazon Q CLI
ChromaDB-only implementation - no fallback storage
"""

import json
import re
import os
import logging
import threading
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple

import chromadb
from sentence_transformers import SentenceTransformer


class MemoryManager:
    """ChromaDB-only Memory Manager optimized for Amazon Q CLI"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None, verbose: bool = False):
        """Initialize memory manager with ChromaDB implementation"""
        self.current_workspace: Optional[str] = None
        self.verbose = verbose
        
        # ë¡œê·¸ ì„¤ì •
        self._setup_logging()
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (ë‹¨ìˆœí™”)
        self.db_path = os.path.expanduser("~/.Q_mem/chroma_db")
        os.makedirs(self.db_path, exist_ok=True)
        
        # ë‹¨ì¼ ChromaDB í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš© (ìŠ¤ë ˆë“œ ì•ˆì „ì„± ì œê±°)
        self.chroma_client = chromadb.PersistentClient(path=self.db_path)
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (ì°¨ì›: 384)
        self.embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        self.embedding_dimension = 384
        
        # ì»¬ë ‰ì…˜ ì´ˆê¸°í™” (ë‹¨ìˆœí™”)
        self.conversations_collection = self._get_or_create_conversations_collection()
        self.workspaces_collection = self._get_or_create_workspaces_collection()
        
        self._log("ChromaDB initialized successfully (simplified)")

    def _get_or_create_conversations_collection(self):
        """ëŒ€í™” ì»¬ë ‰ì…˜ ìƒì„±/ì¡°íšŒ (ë‹¨ìˆœí™”)"""
        return self.chroma_client.get_or_create_collection(
            name="mcp_conversations",
            metadata={
                "description": "Amazon Q CLI conversations",
                "embedding_model": "all-MiniLM-L6-v2",
                "embedding_dimension": self.embedding_dimension,
                "hnsw:space": "cosine",
                "hnsw:M": 16,
                "hnsw:construction_ef": 200,
                "hnsw:search_ef": 50,
            }
        )
    
    def _get_or_create_workspaces_collection(self):
        """ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì»¬ë ‰ì…˜ ìƒì„±/ì¡°íšŒ (ë‹¨ìˆœí™”)"""
        return self.chroma_client.get_or_create_collection(
            name="mcp_workspaces",
            metadata={
                "description": "Amazon Q CLI workspaces",
                "hnsw:space": "cosine",
                "hnsw:M": 16,
                "hnsw:construction_ef": 200,
                "hnsw:search_ef": 50,
            }
        )

    def _setup_logging(self):
        """ë¡œê·¸ íŒŒì¼ ì„¤ì •"""
        log_dir = os.path.expanduser("~/.Q_mem")
        os.makedirs(log_dir, exist_ok=True)
        
        log_file = os.path.join(log_dir, "operations.log")
        
        # ë¡œê±° ì„¤ì •
        self.logger = logging.getLogger('q_mem_mcp')
        self.logger.setLevel(logging.INFO)
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
        for handler in self.logger.handlers[:]:
            self.logger.removeHandler(handler)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬ ì¶”ê°€
        file_handler = logging.FileHandler(log_file)
        file_handler.setLevel(logging.INFO)
        
        # í¬ë§·í„° ì„¤ì •
        formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s')
        file_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
    
    def _log(self, message: str, level: str = "INFO"):
        """ë¡œê·¸ ê¸°ë¡ (íŒŒì¼ + verbose ëª¨ë“œì‹œ ì½˜ì†”)"""
        if level == "INFO":
            self.logger.info(message)
        elif level == "ERROR":
            self.logger.error(message)
        elif level == "WARNING":
            self.logger.warning(message)
        
        if self.verbose:
            print(f"[{level}] {message}")
    
    def _get_operation_stats(self) -> Dict[str, Any]:
        """í˜„ì¬ ì‘ì—…ì˜ í†µê³„ ì •ë³´ ë°˜í™˜"""
        return {
            "current_workspace": self.current_workspace,
            "timestamp": datetime.now().isoformat(),
            "storage_type": "chromadb"
        }

    
    def find_or_create_workspace(self, description: str) -> Tuple[str, bool]:
        """Find existing workspace by description or create new one"""
        # Use description as workspace_id (sanitized)
        import re
        workspace_id = re.sub(r'[^\w\-_]', '_', description)[:50]  # ì•ˆì „í•œ IDë¡œ ë³€í™˜
        
        print(f"ğŸ” Looking for workspace: {workspace_id}")
        
        # Check existing workspaces
        existing_workspaces = self.list_all_workspaces()
        print(f"ğŸ“‹ Found {len(existing_workspaces)} existing workspaces")
        
        for workspace in existing_workspaces:
            if workspace.get('workspace_id') == workspace_id:
                print(f"âœ… Found existing workspace: {workspace_id}")
                return workspace_id, False
        
        # Create new workspace
        print(f"ğŸ†• Creating new workspace: {workspace_id}")
        workspace_data = {
            "workspace_id": workspace_id,
            "description": description,
            "created_at": datetime.now().isoformat()
        }
        
        try:
            # Save workspace to ChromaDB (ë‹¨ìˆœí™”)
            workspace_embedding = self.embedder.encode(f"Workspace: {description}")
            workspace_doc_id = f"workspace_{workspace_id}_{datetime.now().timestamp()}"
            
            self.workspaces_collection.add(
                ids=[workspace_doc_id],
                embeddings=[workspace_embedding.tolist()],
                documents=[f"Workspace: {description}"],
                metadatas=[{
                    "type": "workspace_metadata",
                    "workspace_id": workspace_data["workspace_id"],
                    "description": workspace_data["description"],
                    "created_at": workspace_data["created_at"]
                }]
            )
            print(f"âœ… Workspace '{workspace_id}' saved to ChromaDB with ID: {workspace_doc_id}")
            
            # Verify save
            verification = self.workspaces_collection.get(
                where={"workspace_id": workspace_id}
            )
            print(f"ğŸ” Verification: Found {len(verification['ids']) if verification['ids'] else 0} records for workspace")
            
        except Exception as e:
            print(f"âŒ Failed to save workspace to ChromaDB: {e}")
            raise e
        
        self.current_workspace = workspace_id
        
        return workspace_id, True  # New workspace created
    
    def start_workspace(self, description: str) -> Dict[str, Any]:
        """Start a new workspace with truthfulness context"""
        workspace_id, is_new = self.find_or_create_workspace(description)
        self.current_workspace = workspace_id
        
        # ì»¨í…ìŠ¤íŠ¸ ë³€ê²½ ê¸°ë¡
        context_data = {
            "type": "workspace_start",
            "workspace": workspace_id,
            "timestamp": datetime.now().isoformat(),
            "is_new_workspace": is_new
        }
        
        context_text = f"Workspace started: {workspace_id}"
        context_embedding = self.embedder.encode(context_text)
        self.conversations_collection.add(
            ids=[f"workspace_start_{workspace_id}_{datetime.now().timestamp()}"],
            embeddings=[context_embedding.tolist()],
            documents=[context_text],
            metadatas=[context_data]
        )
        
        # ì§„ì‹¤ì„± ê°•ì¡° ì»¨í…ìŠ¤íŠ¸ë¥¼ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì‹œì‘ ì‹œ ì£¼ì…
        try:
            truthfulness_context = self._get_truthfulness_context()
            self.add_conversation(
                user_message="[SYSTEM] Workspace started - Loading truthfulness guidelines",
                ai_response=truthfulness_context
            )
            print("âœ… Truthfulness context loaded for this workspace")
        except Exception as e:
            print(f"Warning: Could not load truthfulness context: {e}")
        
        return {
            "workspace_id": workspace_id,
            "is_new_workspace": is_new,
            "description": description,
            "truthfulness_context_loaded": True
        }
    
    def reload_truthfulness_context(self) -> bool:
        """Reload truthfulness context to current workspace"""
        if not self.current_workspace:
            return False
            
        try:
            truthfulness_context = self._get_truthfulness_context()
            self.add_conversation(
                user_message="[SYSTEM] Workspace resumed - Reloading truthfulness guidelines",
                ai_response=truthfulness_context
            )
            print("âœ… Truthfulness context reloaded")
            return True
        except Exception as e:
            print(f"Warning: Could not reload truthfulness context: {e}")
            return False
    
    def _get_truthfulness_context(self) -> str:
        """ì§„ì‹¤ì„± ê°•ì¡° ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        return """ğŸ¯ **CORE PRINCIPLES FOR THIS WORKSPACE:**

**ABSOLUTE TRUTHFULNESS REQUIRED:**
â€¢ Only provide information you are certain about
â€¢ If you don't know something, clearly state "I don't know" or "I'm not certain"
â€¢ Never guess, estimate, or make assumptions when asked for specific facts
â€¢ Distinguish clearly between what you know vs. what you think might be true

**WHEN UNCERTAIN:**
â€¢ Say "I don't have enough information to answer that accurately"
â€¢ Suggest where the user might find reliable information
â€¢ Offer to help with related topics you do know about

**AVOID:**
â€¢ "I think...", "It might be...", "Probably..." for factual questions
â€¢ Making up details to fill gaps in knowledge
â€¢ Presenting speculation as fact

**REMEMBER:** It's better to admit ignorance than to provide potentially incorrect information. Your credibility depends on accuracy, not having all the answers."""
    
    def get_current_workspace_id(self) -> Optional[str]:
        """Get current workspace identifier"""
        return self.current_workspace
    
    def add_conversation(self, user_message: str, ai_response: str) -> bool:
        """Add conversation to ChromaDB"""
        workspace_id = self.get_current_workspace_id()
        if not workspace_id:
            raise ValueError("Workspace not set. Please start a workspace first.")
        
        try:
            enhanced_metadata = self._analyze_conversation_content(user_message, ai_response)
            
            conversation_text = f"User: {user_message}\nAI: {ai_response}"
            conversation_id = f"conv_{workspace_id}_{datetime.now().timestamp()}"
            
            # ë©”íƒ€ë°ì´í„° ê¸¸ì´ ì œí•œ (ChromaDB ì œí•œ ê³ ë ¤)
            user_msg_truncated = user_message[:1000] if len(user_message) > 1000 else user_message
            ai_msg_truncated = ai_response[:1000] if len(ai_response) > 1000 else ai_response
            
            # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
            files_mentioned = enhanced_metadata.get("files_mentioned", [])
            detected_tasks = enhanced_metadata.get("detected_tasks", [])
            
            metadata = {
                "type": "conversation",
                "workspace": workspace_id,
                "timestamp": datetime.now().isoformat(),
                "user_message": user_msg_truncated,
                "ai_response": ai_msg_truncated,
                "user_message_length": len(user_message),
                "ai_response_length": len(ai_response),
                "total_length": len(user_message) + len(ai_response),
                "importance_score": enhanced_metadata.get("importance_score", 0),
                "code_blocks_count": enhanced_metadata.get("code_blocks_count", 0),
                "files_mentioned_count": len(files_mentioned),
                "detected_tasks_count": len(detected_tasks),
                "analysis_method": enhanced_metadata.get("analysis_method", "basic")
            }
            
            # íŒŒì¼ê³¼ ì‘ì—… ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ì €ì¥
            if files_mentioned:
                metadata["files_mentioned_str"] = "|".join(files_mentioned[:5])
            if detected_tasks:
                metadata["detected_tasks_str"] = "|".join(detected_tasks[:5])
            
            # ChromaDBì— ì €ì¥ (ë‹¨ìˆœí™”)
            conversation_embedding = self.embedder.encode(conversation_text)
            self.conversations_collection.add(
                ids=[conversation_id],
                embeddings=[conversation_embedding.tolist()],
                documents=[conversation_text],
                metadatas=[metadata]
            )
            
            # ë¡œê¹…
            self._log(f"Conversation stored: {len(user_message)}+{len(ai_response)} chars, importance={metadata['importance_score']}")
            
            return True
            
        except Exception as e:
            self._log(f"Failed to store conversation: {str(e)}", "ERROR")
            return False
    
    def _analyze_conversation_content(self, user_message: str, ai_response: str) -> Dict[str, Any]:
        """ì„ë² ë”© ê¸°ë°˜ ì˜ë¯¸ë¡ ì  ëŒ€í™” ë¶„ì„"""
        try:
            # ì‘ì—… ìœ í˜•ë³„ ì„ë² ë”© ì •ì˜
            task_embeddings = {
                'file_operation': self.embedder.encode("read file open document save write"),
                'code_analysis': self.embedder.encode("analyze review examine code function class"),
                'modification': self.embedder.encode("modify change update improve fix edit"),
                'creation': self.embedder.encode("create generate make build implement develop"),
                'testing': self.embedder.encode("test run execute check verify debug"),
                'explanation': self.embedder.encode("explain describe how what why tutorial"),
                'problem_solving': self.embedder.encode("error problem issue bug solve fix")
            }
            
            # ëŒ€í™” ë‚´ìš© ì„ë² ë”©
            conversation_text = f"{user_message} {ai_response}"
            conversation_embedding = self.embedder.encode(conversation_text)
            
            # ìœ ì‚¬ë„ ê³„ì‚° ë° ì‘ì—… ìœ í˜• ê°ì§€
            detected_tasks = []
            task_scores = {}
            
            for task_type, task_embedding in task_embeddings.items():
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë‚´ì  ì‚¬ìš©)
                similarity = float(conversation_embedding.dot(task_embedding) / 
                                 (conversation_embedding.dot(conversation_embedding)**0.5 * 
                                  task_embedding.dot(task_embedding)**0.5))
                
                if similarity > 0.3:  # ì„ê³„ê°’
                    detected_tasks.append(task_type)
                    task_scores[task_type] = round(similarity, 3)
            
            # íŒŒì¼ ì–¸ê¸‰ ê°ì§€ (ì •ê·œì‹ ë³´ì¡°)
            file_patterns = [r'\.[a-zA-Z]{2,4}(?:\s|$)', r'/[\w/]+', r'[\w]+\.[\w]+']
            files_mentioned = []
            for pattern in file_patterns:
                matches = re.findall(pattern, conversation_text)
                files_mentioned.extend(matches)
            
            # ì½”ë“œ ë¸”ë¡ ê°ì§€
            code_blocks = len(re.findall(r'```', ai_response))
            
            # ì¤‘ìš”ë„ ì ìˆ˜ ê³„ì‚°
            importance_score = len(detected_tasks) * 2 + len(files_mentioned) + code_blocks
            
            analysis = {
                "detected_tasks": detected_tasks,
                "task_confidence": task_scores,
                "files_mentioned": list(set(files_mentioned)) if files_mentioned else [],
                "code_blocks_count": code_blocks,
                "importance_score": importance_score,
                "user_message_length": len(user_message),
                "ai_response_length": len(ai_response),
                "total_length": len(user_message) + len(ai_response),
                "analysis_method": "embedding_based"
            }
            
            return analysis
            
        except Exception as e:
            self._log(f"Warning: Embedding analysis failed: {str(e)}", "WARNING")
            # Fallback to basic analysis
            return {
                "user_message_length": len(user_message),
                "ai_response_length": len(ai_response),
                "total_length": len(user_message) + len(ai_response),
                "analysis_method": "fallback"
            }
    
    def search_memory_by_workspace_id(self, workspace_id: str, query: str = "", limit: int = 3) -> Dict[str, Any]:
        """Search conversation memory by workspace ID using ChromaDB"""
        self._log(f"Searching memory for workspace '{workspace_id}': '{query}' (limit: {limit})")
        
        if query.strip():
            # ì˜ë¯¸ì  ê²€ìƒ‰ (ì¿¼ë¦¬ê°€ ìˆëŠ” ê²½ìš°) - ë‹¨ìˆœí™”
            query_embedding = self.embedder.encode(query)
            try:
                results = self.conversations_collection.query(
                    query_embeddings=[query_embedding.tolist()],
                    n_results=limit,
                    where={"$and": [{"workspace": workspace_id}, {"type": "conversation"}]}
                )
                
            except Exception as e:
                self._log(f"ChromaDB query error: {str(e)}", "ERROR")
                return {
                    "results": [],
                    "stats": {
                        "query": query,
                        "total_found": 0,
                        "workspace": workspace_id,
                        "limit": limit,
                        "search_type": "error",
                        "error": str(e)
                    }
                }
            
            search_results = []
            if results['documents'] and results['documents'][0]:
                for i, doc in enumerate(results['documents'][0]):
                    metadata = results['metadatas'][0][i] if results['metadatas'] and results['metadatas'][0] else {}
                    
                    if (metadata.get('type') == 'conversation' and 
                        metadata.get('workspace') == workspace_id):
                        
                        search_results.append({
                            "memory": doc,
                            "metadata": metadata,
                            "score": results['distances'][0][i] if results['distances'] and results['distances'][0] else 0,
                            "user_message": metadata.get('user_message', ''),
                            "ai_response": metadata.get('ai_response', ''),
                            "timestamp": metadata.get('timestamp', '')
                        })
            
            # ê²°ê³¼ ì œí•œ
            search_results = search_results[:limit]
            
        else:
            # ì „ì²´ ëŒ€í™” ê°€ì ¸ì˜¤ê¸° (ì¿¼ë¦¬ê°€ ì—†ëŠ” ê²½ìš°) - ë‹¨ìˆœí™”
            try:
                results = self.conversations_collection.get(
                    where={"$and": [{"workspace": workspace_id}, {"type": "conversation"}]}
                )
                
            except Exception as e:
                self._log(f"ChromaDB get error: {str(e)}", "ERROR")
                return {
                    "results": [],
                    "stats": {
                        "query": query,
                        "total_found": 0,
                        "workspace": workspace_id,
                        "limit": limit,
                        "search_type": "error",
                        "error": str(e)
                    }
                }
            
            search_results = []
            if results['documents'] and results['metadatas']:
                for i, doc in enumerate(results['documents']):
                    metadata = results['metadatas'][i] if i < len(results['metadatas']) else {}
                    
                    if (metadata.get('type') == 'conversation' and 
                        metadata.get('workspace') == workspace_id):
                        
                        search_results.append({
                            "memory": doc,
                            "metadata": metadata,
                            "score": 0,  # ì „ì²´ ì¡°íšŒì‹œ ì ìˆ˜ ì—†ìŒ
                            "user_message": metadata.get('user_message', ''),
                            "ai_response": metadata.get('ai_response', ''),
                            "timestamp": metadata.get('timestamp', '')
                        })
            
            # ì‹œê°„ìˆœ ì •ë ¬ (queryê°€ ì—†ì„ ë•ŒëŠ” limit ì ìš©í•˜ì§€ ì•ŠìŒ)
            def safe_timestamp_sort(item):
                timestamp = item.get('timestamp', '')
                if not timestamp:
                    return '1970-01-01T00:00:00'
                return timestamp
            
            search_results.sort(key=safe_timestamp_sort, reverse=True)
        
        self._log(f"Search completed: {len(search_results)} results found")
        
        return {
            "results": search_results,
            "stats": {
                "query": query,
                "total_found": len(search_results),
                "workspace": workspace_id,
                "limit": limit,
                "search_type": "semantic" if query.strip() else "all"
            }
        }
    
    def list_all_workspaces(self) -> List[Dict[str, Any]]:
        """List all available workspaces with detailed information"""
        workspaces = []
        
        try:
            self._log("Querying ChromaDB for all workspaces")
            
            # ChromaDBì—ì„œ ëª¨ë“  ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ë‹¨ìˆœí™”)
            results = self.workspaces_collection.get()
            
            if results['metadatas']:
                for metadata in results['metadatas']:
                    if metadata and metadata.get('type') == 'workspace_metadata':
                        workspace_id = metadata.get('workspace_id', '')
                        if workspace_id:
                            conversation_count = self._get_conversation_count_for_workspace(workspace_id)
                            
                            workspace_info = {
                                "workspace_id": workspace_id,
                                "description": metadata.get('description', ''),
                                "created_at": metadata.get('created_at', ''),
                                "conversation_count": conversation_count
                            }
                            workspaces.append(workspace_info)
                
                self._log(f"Found {len(workspaces)} valid workspaces")
            else:
                self._log("No workspace metadata found in ChromaDB", "WARNING")
            
        except Exception as e:
            self._log(f"Error querying workspaces from ChromaDB: {str(e)}", "ERROR")
        
        return workspaces
    
    def _get_conversation_count_for_workspace(self, workspace_id: str) -> int:
        """Get conversation count for a workspace from ChromaDB"""
        try:
            results = self.conversations_collection.get(
                where={"$and": [{"workspace": workspace_id}, {"type": "conversation"}]}
            )
            
            count = len(results['ids']) if results['ids'] else 0
            return count
            
        except Exception as e:
            self._log(f"Error counting conversations for workspace {workspace_id}: {str(e)}", "ERROR")
            return 0
    
    def resume_workspace(self, workspace_id: str) -> Dict[str, Any]:
        """Resume an existing workspace with full conversation history loaded"""
        self._log(f"Resuming workspace with full context: {workspace_id}")
        
        # ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì¡´ì¬ í™•ì¸
        workspaces = self.list_all_workspaces()
        target_workspace = None
        
        for workspace in workspaces:
            if workspace.get('workspace_id') == workspace_id:
                target_workspace = workspace
                break
        
        if not target_workspace:
            error_msg = f"Workspace '{workspace_id}' not found"
            self._log(error_msg, "ERROR")
            raise ValueError(error_msg)
        
        # ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì¬ê°œ
        self.current_workspace = workspace_id
        
        # ì „ì²´ ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¡œë“œ
        history_result = self.get_workspace_conversations(workspace_id)
        full_history = history_result.get('conversations', [])
        
        # LLM contextìš© ëŒ€í™” ë¬¸ìì—´ ìƒì„±
        context_messages = []
        for conv in full_history:
            user_msg = conv.get('user_message', '')
            ai_msg = conv.get('ai_response', '')
            if user_msg and ai_msg:
                context_messages.append(f"User: {user_msg}")
                context_messages.append(f"Assistant: {ai_msg}")
        
        context_length = sum(len(msg) for msg in context_messages)
        
        result = {
            "workspace_id": workspace_id,
            "description": target_workspace.get('description', ''),
            "created_at": target_workspace.get('created_at', ''),
            "conversation_count": len(full_history),
            "full_history": full_history,
            "context_messages": context_messages,
            "context_length": context_length,
            "estimated_tokens": context_length // 4,
            "is_resumed": True
        }
        
        self._log(f"Workspace resumed with full context: {workspace_id} ({len(full_history)} conversations, {context_length} chars)")
        return result
    
    def get_workspace_conversations(self, workspace_id: str) -> Dict[str, Any]:
        """Get all conversations from a workspace (simplified)"""
        self._log(f"Loading conversations for workspace: {workspace_id}")
        
        # ChromaDBì—ì„œ í•´ë‹¹ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì˜ ëª¨ë“  ëŒ€í™” ê°€ì ¸ì˜¤ê¸° (ë‹¨ìˆœí™”)
        results = self.conversations_collection.get(
            where={"$and": [{"workspace": workspace_id}, {"type": "conversation"}]}
        )
        
        conversations = []
        if results['documents'] and results['metadatas']:
            for i, doc in enumerate(results['documents']):
                metadata = results['metadatas'][i] if i < len(results['metadatas']) else {}
                
                if (metadata.get('type') == 'conversation' and 
                    metadata.get('workspace') == workspace_id):
                    conversations.append({
                        "content": doc,
                        "timestamp": metadata.get('timestamp', ''),
                        "user_message": metadata.get('user_message', ''),
                        "ai_response": metadata.get('ai_response', ''),
                        "importance_score": metadata.get('importance_score', 0),
                        "document": doc
                    })
        
        # ì‹œê°„ìˆœ ì •ë ¬
        def safe_timestamp_sort(conv):
            timestamp = conv.get('timestamp', '')
            if not timestamp:
                return '1970-01-01T00:00:00'
            return timestamp
        
        conversations.sort(key=safe_timestamp_sort)
        
        result = {
            "conversations": conversations,
            "stats": {
                "total_conversations": len(conversations),
                "workspace_id": workspace_id,
                "context_length": sum(len(c.get('user_message', '') + c.get('ai_response', '')) for c in conversations)
            }
        }
        
        self._log(f"Loaded {len(conversations)} conversations from workspace: {workspace_id}")
        return result
    
    def _safe_extract_string(self, metadata: Dict, key: str, default: str = "") -> str:
        """ë©”íƒ€ë°ì´í„°ì—ì„œ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ ì¶”ì¶œ"""
        try:
            value = metadata.get(key, default)
            if value is None:
                return default
            if isinstance(value, str):
                return value
            # ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ë³€í™˜ ì‹œë„
            return str(value)
        except Exception:
            return default
    
    def _safe_calculate_context_length(self, conversations: List[Dict]) -> int:
        """ì•ˆì „í•˜ê²Œ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ê³„ì‚°"""
        try:
            total_length = 0
            for conv in conversations:
                user_msg = conv.get('user_message', '')
                ai_msg = conv.get('ai_response', '')
                
                if isinstance(user_msg, str):
                    total_length += len(user_msg)
                if isinstance(ai_msg, str):
                    total_length += len(ai_msg)
            
            return total_length
        except Exception as e:
            self._log(f"Error calculating context length: {str(e)}", "WARNING")
            return 0
    
    def _generate_workspace_summary(self, conversations: List[Dict]) -> Dict[str, Any]:
        """ëŒ€í™” ëª©ë¡ì—ì„œ ìš”ì•½ ì •ë³´ ìƒì„± (ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”)"""
        file_mentions = []
        code_mentions = []
        task_mentions = []
        processing_errors = []
        
        for i, conv in enumerate(conversations):
            try:
                # ì•ˆì „í•œ ë©”ì‹œì§€ ì¶”ì¶œ
                user_msg = self._safe_extract_string(conv, 'user_message', '')
                ai_msg = self._safe_extract_string(conv, 'ai_response', '')
                
                if not user_msg and not ai_msg:
                    continue
                
                # íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ (ì•ˆì „í•œ ì •ê·œì‹ ì²˜ë¦¬)
                try:
                    import re
                    file_patterns = [
                        r'/[^\s]+\.(py|js|json|md|txt|yml|yaml|sql)',
                        r'[^\s]+\.(py|js|json|md|txt|yml|yaml|sql)'
                    ]
                    for pattern in file_patterns:
                        try:
                            matches = re.findall(pattern, user_msg + ' ' + ai_msg)
                            file_mentions.extend(matches)
                        except re.error as e:
                            processing_errors.append(f"Regex error in conversation {i}: {str(e)}")
                except Exception as e:
                    processing_errors.append(f"File pattern matching error in conversation {i}: {str(e)}")
                
                # ì½”ë“œ ë¸”ë¡ ê°ì§€ (ì•ˆì „í•œ ë¬¸ìì—´ ê²€ì‚¬)
                try:
                    if ('```' in user_msg) or ('```' in ai_msg):
                        code_mentions.append(f"Code: {user_msg[:50]}...")
                except Exception as e:
                    processing_errors.append(f"Code detection error in conversation {i}: {str(e)}")
                
                # ì‘ì—…/ìš”ì²­ ê°ì§€ (ì•ˆì „í•œ í‚¤ì›Œë“œ ê²€ì‚¬)
                try:
                    task_keywords = ['ì½ì–´', 'ë¶„ì„', 'ê°œì„ ', 'ìˆ˜ì •', 'ìƒì„±', 'ë§Œë“¤ì–´', 'êµ¬í˜„', 'í…ŒìŠ¤íŠ¸', 'ì¡°íšŒ', 'í™•ì¸']
                    if any(keyword in user_msg for keyword in task_keywords):
                        task_mentions.append(user_msg[:100])
                except Exception as e:
                    processing_errors.append(f"Task detection error in conversation {i}: {str(e)}")
                    
            except Exception as e:
                processing_errors.append(f"General processing error in conversation {i}: {str(e)}")
                continue
        
        # ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ êµ¬ì„± (ì•ˆì „í•œ ì²˜ë¦¬)
        summary_parts = []
        
        try:
            if file_mentions:
                # ì•ˆì „í•œ íŒŒì¼ ëª©ë¡ ì²˜ë¦¬
                unique_files = []
                for f in file_mentions:
                    try:
                        file_name = f[0] if isinstance(f, tuple) else f
                        if isinstance(file_name, str) and file_name not in unique_files:
                            unique_files.append(file_name)
                    except Exception:
                        continue
                
                if unique_files:
                    summary_parts.append(f"ğŸ“ Files: {', '.join(unique_files[:5])}")
            
            if task_mentions:
                # ì•ˆì „í•œ ì‘ì—… ëª©ë¡ ì²˜ë¦¬
                safe_tasks = []
                for task in task_mentions[-3:]:
                    if isinstance(task, str):
                        safe_tasks.append(task)
                
                if safe_tasks:
                    summary_parts.append(f"ğŸ¯ Tasks: {'; '.join(safe_tasks)}")
            
            if code_mentions:
                summary_parts.append(f"ğŸ’» Code discussions: {len(code_mentions)}")
            
            # ìµœê·¼ ëŒ€í™” ìš”ì•½ (ì•ˆì „í•œ ì²˜ë¦¬)
            recent_convs = conversations[-3:] if len(conversations) >= 3 else conversations
            if recent_convs:
                summary_parts.append("ğŸ’¬ Recent:")
                for conv in recent_convs:
                    try:
                        user_msg = self._safe_extract_string(conv, 'user_message', '')
                        if user_msg and len(user_msg) > 0:
                            safe_msg = user_msg[:80] if len(user_msg) > 80 else user_msg
                            summary_parts.append(f"   U: {safe_msg}...")
                    except Exception:
                        continue
            
        except Exception as e:
            processing_errors.append(f"Summary construction error: {str(e)}")
            summary_parts = ["Summary generation partially failed"]
        
        # ìµœì¢… ìš”ì•½ ìƒì„±
        summary = "\n".join(summary_parts) if summary_parts else "Workspace context available"
        
        # í†µê³„ ìƒì„± (ì•ˆì „í•œ ì²˜ë¦¬)
        try:
            unique_files_count = len(set([
                f[0] if isinstance(f, tuple) else f 
                for f in file_mentions 
                if isinstance(f, (str, tuple))
            ]))
        except Exception:
            unique_files_count = 0
        
        result = {
            "summary": summary,
            "summary_stats": {
                "conversations_analyzed": len(conversations),
                "files_found": unique_files_count,
                "tasks_found": len(task_mentions),
                "code_blocks": len(code_mentions),
                "processing_errors": len(processing_errors)
            }
        }
        
        # ì²˜ë¦¬ ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ í¬í•¨
        if processing_errors:
            self._log(f"Summary generation errors: {len(processing_errors)} errors", "WARNING")
            result["processing_errors"] = processing_errors[:5]  # ìµœëŒ€ 5ê°œë§Œ í¬í•¨
        
        return result
    
    def delete_workspace(self, workspace_id: str) -> Dict[str, Any]:
        """Delete workspace and all related data"""
        print(f"ğŸ—‘ï¸ Deleting workspace: {workspace_id}")
        
        deleted_items = {
            "workspace_metadata": False,
            "conversations": 0,
            "context_data": 0
        }
        
        # 1. ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ë©”íƒ€ë°ì´í„° ì‚­ì œ (ë‹¨ìˆœí™”)
        workspace_results = self.workspaces_collection.get(
            where={"workspace_id": workspace_id}
        )
        
        if workspace_results['ids']:
            self.workspaces_collection.delete(ids=workspace_results['ids'])
            deleted_items["workspace_metadata"] = True
            print(f"âœ… Workspace metadata deleted")
        
        # 2. í•´ë‹¹ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì˜ ëª¨ë“  ëŒ€í™” ì‚­ì œ (ë‹¨ìˆœí™”)
        conv_results = self.conversations_collection.get(
            where={"workspace": workspace_id}
        )
        
        if conv_results['ids']:
            self.conversations_collection.delete(ids=conv_results['ids'])
            deleted_items["conversations"] = len(conv_results['ids'])
            print(f"âœ… {len(conv_results['ids'])} conversations deleted")
        
        # í˜„ì¬ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ê°€ ì‚­ì œëœ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ì´ë©´ ì´ˆê¸°í™”
        if self.current_workspace == workspace_id:
            self.current_workspace = None
        
        print(f"ğŸ—‘ï¸ Workspace '{workspace_id}' completely deleted")
        return deleted_items
    
    def cleanup_old_workspaces(self, days: int = 30) -> Dict[str, Any]:
        """Clean up old workspaces"""
        from datetime import datetime, timedelta
        
        cutoff_date = datetime.now() - timedelta(days=days)
        cleanup_stats = {
            "workspaces_deleted": 0,
            "conversations_deleted": 0,
            "cutoff_date": cutoff_date.isoformat()
        }
        
        workspaces = self.list_all_workspaces()
        
        for workspace in workspaces:
            try:
                created_at = workspace.get('created_at', '')
                if created_at:
                    workspace_date = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
                    
                    if workspace_date < cutoff_date:
                        workspace_id = workspace.get('workspace_id')
                        deleted_items = self.delete_workspace(workspace_id)
                        
                        cleanup_stats["workspaces_deleted"] += 1
                        cleanup_stats["conversations_deleted"] += deleted_items.get("conversations", 0)
                        
                        print(f"ğŸ§¹ Cleaned up old workspace: {workspace_id}")
                        
            except Exception as e:
                print(f"Warning: Could not process workspace for cleanup: {e}")
        
        print(f"ğŸ§¹ Cleanup complete: {cleanup_stats['workspaces_deleted']} workspaces, {cleanup_stats['conversations_deleted']} conversations")
        return cleanup_stats
    
    def get_storage_stats(self) -> Dict[str, Any]:
        """Return storage statistics information (optimized for reliability)"""
        stats = {
            "total_workspaces": 0,
            "total_conversations": 0,
            "storage_type": "chromadb",
            "current_workspace": self.current_workspace,
            "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
            "embedding_dimension": self.embedding_dimension
        }
        
        try:
            # ê°„ë‹¨í•œ ì¹´ìš´íŠ¸ë§Œ ìˆ˜í–‰ (ë³µì¡í•œ ì—°ì‚° í”¼í•¨) - ë‹¨ìˆœí™”
            workspaces_result = self.workspaces_collection.get()
            stats["total_workspaces"] = len(workspaces_result.get('ids', []))
            
            # ëŒ€í™” ìˆ˜ëŠ” ì§ì ‘ ì¹´ìš´íŠ¸ (list_all_workspaces í˜¸ì¶œ í”¼í•¨) - ë‹¨ìˆœí™”
            conversations_result = self.conversations_collection.get()
            stats["total_conversations"] = len(conversations_result.get('ids', []))
            
        except Exception as e:
            self._log(f"Error getting basic stats: {e}", "WARNING")
            # ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ìœ ì§€
        
        # ì €ì¥ì†Œ í¬ê¸° ì •ë³´ (ê°€ëŠ¥í•œ ê²½ìš°)
        try:
            import os
            storage_dir = os.path.expanduser("~/.Q_mem")
            if os.path.exists(storage_dir):
                total_size = 0
                for root, dirs, files in os.walk(storage_dir):
                    for file in files:
                        try:
                            total_size += os.path.getsize(os.path.join(root, file))
                        except (OSError, IOError):
                            continue  # íŒŒì¼ ì ‘ê·¼ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
                stats["storage_size_mb"] = round(total_size / (1024 * 1024), 2)
        except Exception as e:
            self._log(f"Error calculating storage size: {e}", "WARNING")
            stats["storage_size_mb"] = "unknown"
        
        return stats
    
    def get_context_info(self) -> Dict[str, Any]:
        """Get current context information"""
        return {
            "workspace_id": self.get_current_workspace_id(),
            "is_active": self.get_current_workspace_id() is not None,
            "storage_type": "chromadb"
        }
