"""
Q CLI LLM-based Conversation Summarizer for Q Workspace MCP Server
Q CLIì˜ LLMì„ í™œìš©í•˜ì—¬ ëŒ€í™” ë‚´ìš©ì„ ì§€ëŠ¥ì ìœ¼ë¡œ ìš”ì•½
"""

from typing import List, Dict, Any


class QCLILLMSummarizer:
    """Q CLI LLM ê¸°ë°˜ ëŒ€í™” ìš”ì•½ í´ë˜ìŠ¤"""
    
    def __init__(self):
        pass
    
    def _format_conversation_for_summary(self, conv: Dict[str, Any]) -> str:
        """ëŒ€í™”ë¥¼ ìš”ì•½ìš©ìœ¼ë¡œ í¬ë§·íŒ…"""
        user_msg = conv.get('user_message', '')
        ai_msg = conv.get('ai_response', '')
        timestamp = conv.get('timestamp', '')[:16].replace('T', ' ')
        
        return f"[{timestamp}] User: {user_msg}\nAssistant: {ai_msg}"
    
    def _create_summary_request_for_qcli(self, conversations: List[Dict], summary_level: str) -> str:
        """Q CLI LLMì—ê²Œ ì „ë‹¬í•  ìš”ì•½ ìš”ì²­ ìƒì„±"""
        conv_texts = []
        for i, conv in enumerate(conversations, 1):
            conv_text = self._format_conversation_for_summary(conv)
            conv_texts.append(f"=== ëŒ€í™” {i} ===\n{conv_text}")
        
        all_conversations = "\n\n".join(conv_texts)
        
        if summary_level == "brief":
            instruction = """ë‹¤ìŒ ëŒ€í™”ë“¤ì„ ê°ê° ìµœì†Œ 2ì¤„, ìµœëŒ€ 3ì¤„ë¡œ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”. ì£¼ìš” ì£¼ì œì™€ ê²°ë¡ ì„ í¬í•¨í•˜ì„¸ìš”.
í˜•ì‹: "1. ì£¼ì œ: ê²°ë¡ "
ì˜ˆì‹œ: "1. Python ë¦¬ìŠ¤íŠ¸ ì§ˆë¬¸: ê°€ë³€ê°ì²´ íŠ¹ì„±ê³¼ ì£¼ìš” ë©”ì„œë“œ ì„¤ëª…í•¨"
"""
        elif summary_level == "medium":
            instruction = """ë‹¤ìŒ ëŒ€í™”ë“¤ì„ ê°ê° ìµœì†Œ3ì¤„, ìµœëŒ€ 5ì¤„ë¡œ ìƒì„¸íˆ ìš”ì•½í•´ì£¼ì„¸ìš”. ì£¼ìš” ë‚´ìš©, ì˜ˆì‹œ, ê²°ë¡ ì„ í¬í•¨í•˜ì„¸ìš”.
í˜•ì‹: "1. ì£¼ì œ: ìƒì„¸ë‚´ìš©"
ì˜ˆì‹œ: "1. í´ë˜ìŠ¤ ìƒì† ì„¤ëª…: ë¶€ëª¨í´ë˜ìŠ¤ ì†ì„± ìƒì† ë°©ë²•, super() ì‚¬ìš©ë²•, ë‹¤ì¤‘ìƒì† ì£¼ì˜ì‚¬í•­ ë“±ì„ ì½”ë“œ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…í•¨"
"""
        else:
            return ""
        
        summary_request = f"""ğŸ¤– **Q CLI LLM ìš”ì•½ ìš”ì²­**

{instruction}

ëŒ€í™” ë‚´ìš©:
{all_conversations}

ìš”ì•½ ê²°ê³¼ (ë²ˆí˜¸ìˆœìœ¼ë¡œ):"""
        
        return summary_request
    
    def format_conversations_with_qcli_summary(self, conversations: List[Dict[str, Any]]) -> str:
        """Q CLI LLM ìš”ì•½ì„ ìš”ì²­í•˜ëŠ” í˜•íƒœë¡œ ëŒ€í™” ëª©ë¡ í¬ë§·íŒ…"""
        if not conversations:
            return "â„¹ï¸ **No previous conversations found.**"
        
        total_count = len(conversations)
        
        if total_count < 100:
            # 100ê°œ ë¯¸ë§Œ: ì§§ì€ ëŒ€í™”ëŠ” ê·¸ëŒ€ë¡œ, ê¸´ ëŒ€í™”ëŠ” Q CLI LLMì—ê²Œ ìš”ì•½ ìš”ì²­
            formatted_text = f"ğŸ§  **All Conversations ({total_count} total):**\n\n"
            
            long_conversations = []
            short_conversations = []
            
            # ëŒ€í™” ë¶„ë¥˜
            for i, conv in enumerate(conversations):
                ai_msg = conv.get('ai_response', '')
                if len(ai_msg) > 300:  # 300ì ì´ìƒì¸ ê²½ìš° ìš”ì•½ ëŒ€ìƒ
                    long_conversations.append((i, conv))
                else:
                    short_conversations.append((i, conv))
            
            # ê¸´ ëŒ€í™”ê°€ ìˆìœ¼ë©´ Q CLI LLMì—ê²Œ ìš”ì•½ ìš”ì²­
            if long_conversations:
                summary_request = self._create_summary_request_for_qcli(
                    [conv for _, conv in long_conversations], 
                    "brief"
                )
                
                formatted_text += f"ğŸ“ **ìš”ì•½ì´ í•„ìš”í•œ {len(long_conversations)}ê°œ ëŒ€í™”ê°€ ìˆìŠµë‹ˆë‹¤.**\n\n"
                formatted_text += summary_request + "\n\n"
                formatted_text += "---\n\n"
            
            # ëª¨ë“  ëŒ€í™” í‘œì‹œ (ì§§ì€ ê²ƒì€ ê·¸ëŒ€ë¡œ, ê¸´ ê²ƒì€ í‘œì‹œë§Œ)
            for i, conv in enumerate(conversations, 1):
                user_msg = conv.get('user_message', '')
                ai_msg = conv.get('ai_response', '')
                timestamp = conv.get('timestamp', '')[:16].replace('T', ' ')
                
                formatted_text += f"**{i}. ({timestamp})**\n"
                formatted_text += f"**User**: {user_msg}\n"
                
                if len(ai_msg) > 300:
                    formatted_text += f"**Assistant**: [ìœ„ì—ì„œ ìš”ì•½ ìš”ì²­ëœ ê¸´ ì‘ë‹µ]\n\n"
                else:
                    formatted_text += f"**Assistant**: {ai_msg}\n\n"
            
            return formatted_text
        
        else:
            # 100ê°œ ì´ìƒ: í¼ì„¼íŠ¸ ê¸°ë°˜ìœ¼ë¡œ Q CLI LLMì—ê²Œ ìš”ì•½ ìš”ì²­
            recent_5_percent = max(5, int(total_count * 0.05))
            middle_15_percent = max(10, int(total_count * 0.15))
            old_remainder = total_count - recent_5_percent - middle_15_percent
            
            formatted_text = f"ğŸ§  **Complete Conversation History ({total_count} total conversations):**\n\n"
            
            # Q CLI LLMì—ê²Œ ìš”ì•½ ìš”ì²­ë“¤ ìƒì„±
            summary_requests = []
            
            # ì˜¤ë˜ëœ ëŒ€í™”ë“¤ (80% - Brief Summary)
            if old_remainder > 0:
                old_conversations = conversations[:old_remainder]
                old_summary_request = self._create_summary_request_for_qcli(old_conversations, "brief")
                summary_requests.append(("earlier", old_remainder, old_summary_request))
            
            # ì¤‘ê°„ ëŒ€í™”ë“¤ (15% - Medium Summary)
            if middle_15_percent > 0:
                middle_start = old_remainder
                middle_end = old_remainder + middle_15_percent
                middle_conversations = conversations[middle_start:middle_end]
                medium_summary_request = self._create_summary_request_for_qcli(middle_conversations, "medium")
                summary_requests.append(("recent", middle_15_percent, medium_summary_request))
            
            # Q CLI LLMì—ê²Œ ìš”ì•½ ìš”ì²­
            for request_type, count, request in summary_requests:
                if request_type == "earlier":
                    formatted_text += f"ğŸ“š **Earlier Context ({count} conversations) - ìš”ì•½ ìš”ì²­:**\n\n"
                else:
                    formatted_text += f"ğŸ’¬ **Recent Context ({count} conversations) - ìƒì„¸ ìš”ì•½ ìš”ì²­:**\n\n"
                
                formatted_text += request + "\n\n"
                formatted_text += "---\n\n"
            
            # ìµœê·¼ ëŒ€í™”ë“¤ (5% - Full Detail)
            recent_start = total_count - recent_5_percent
            recent_conversations = conversations[recent_start:]
            
            formatted_text += f"ğŸ”¥ **Latest Conversations ({recent_5_percent} conversations - full detail):**\n"
            
            for i, conv in enumerate(recent_conversations, recent_start + 1):
                user_msg = conv.get('user_message', '')
                ai_msg = conv.get('ai_response', '')
                timestamp = conv.get('timestamp', '')[:16].replace('T', ' ')
                
                formatted_text += f"**{i}. ({timestamp})**\n"
                formatted_text += f"**User**: {user_msg}\n"
                formatted_text += f"**Assistant**: {ai_msg}\n\n"
            
            formatted_text += "\nğŸ¤– **ìœ„ì˜ ìš”ì•½ ìš”ì²­ë“¤ì„ ì²˜ë¦¬í•´ì£¼ì‹œë©´, ëª¨ë“  ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì„ ì™„ë²½íˆ ì´í•´í•˜ê³  ëŒ€í™”ë¥¼ ì´ì–´ê°ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**\n"
            formatted_text += "ğŸ’¡ **ìš”ì•½ì´ ì™„ë£Œë˜ë©´ ì´ì „ ì£¼ì œë“¤ì„ ììœ ë¡­ê²Œ ì°¸ì¡°í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.**"
            
            return formatted_text


# ì „ì—­ Q CLI LLM ìš”ì•½ê¸° ì¸ìŠ¤í„´ìŠ¤
_qcli_llm_summarizer = None


def get_qcli_llm_summarizer() -> QCLILLMSummarizer:
    """Q CLI LLM ìš”ì•½ê¸° ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _qcli_llm_summarizer
    if _qcli_llm_summarizer is None:
        _qcli_llm_summarizer = QCLILLMSummarizer()
    return _qcli_llm_summarizer
