"""
TTL (Time To Live) ìºì‹œ êµ¬í˜„

í•œêµ­íˆ¬ìì¦ê¶Œ API ì‘ë‹µì„ ìºì‹±í•˜ì—¬ API í˜¸ì¶œ íšŸìˆ˜ë¥¼ ì¤„ì´ê³  ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
"""

import time
import threading
import sys
import zlib
import pickle
import logging
from typing import Dict, Any, Optional, Callable, Tuple
from functools import wraps
from collections import defaultdict
from datetime import datetime, timedelta
from functools import lru_cache

logger = logging.getLogger(__name__)


class CacheEntry:
    """ìºì‹œ í•­ëª© ë°ì´í„° êµ¬ì¡°"""
    
    def __init__(self, value: Any, ttl: int):
        """
        Args:
            value: ìºì‹œí•  ê°’
            ttl: Time To Live (ì´ˆ)
        """
        self.value = value
        self.expires_at = time.time() + ttl
        self.created_at = time.time()
        self.access_count = 0
        self.last_accessed = time.time()
        self.size = sys.getsizeof(value)
    
    def is_expired(self) -> bool:
        """ë§Œë£Œ ì—¬ë¶€ í™•ì¸"""
        return time.time() > self.expires_at
    
    def access(self) -> Any:
        """ê°’ ì ‘ê·¼ ì‹œ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.access_count += 1
        self.last_accessed = time.time()
        return self.value
    
    def get_age(self) -> float:
        """í•­ëª© ë‚˜ì´ (ì´ˆ)"""
        return time.time() - self.created_at


class TTLCache:
    """Thread-safe TTL ìºì‹œ"""
    
    def __init__(self, default_ttl: int = 300, max_size: int = 10000):
        """
        Args:
            default_ttl: ê¸°ë³¸ TTL (ì´ˆ, ê¸°ë³¸ê°’: 300ì´ˆ=5ë¶„)
            max_size: ìµœëŒ€ ìºì‹œ í•­ëª© ìˆ˜
        """
        self._cache: Dict[str, CacheEntry] = {}
        self._default_ttl = default_ttl
        self._max_size = max_size
        self._lock = threading.RLock()
        
        # í†µê³„
        self._hit_count = 0
        self._miss_count = 0
        self._eviction_count = 0
        self._access_count = defaultdict(int)
        
        # ë©”ëª¨ë¦¬ ê´€ë¦¬
        self._total_memory = 0
        self._cleanup_interval = 60  # 1ë¶„ë§ˆë‹¤ ì •ë¦¬
        self._last_cleanup = time.time()
        self._expired_count = 0
        
        # ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ìŠ¤ë ˆë“œ
        self._stop_cleanup = False
        self._cleanup_thread = None
        self.start_cleanup_thread()
        
        # ì••ì¶• ì„¤ì •
        self._compression_threshold = 1024  # 1KB ì´ìƒ ì••ì¶•
        
        logger.info(f"TTLCache ì´ˆê¸°í™”: default_ttl={default_ttl}s, max_size={max_size}")
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ê°’ ì¡°íšŒ"""
        with self._lock:
            # ì£¼ê¸°ì  ì •ë¦¬
            if time.time() - self._last_cleanup > self._cleanup_interval:
                self._cleanup_expired()
            
            # ì›ë³¸ í‚¤ì™€ ì••ì¶•ëœ í‚¤ ëª¨ë‘ í™•ì¸
            entry = None
            actual_key = key
            
            if key in self._cache:
                entry = self._cache[key]
            elif f"{key}:compressed" in self._cache:
                actual_key = f"{key}:compressed"
                entry = self._cache[actual_key]
            
            if entry is None:
                self._miss_count += 1
                logger.debug(f"Cache MISS for {key}")
                return None
            
            # ë§Œë£Œ í™•ì¸
            if entry.is_expired():
                self._miss_count += 1
                logger.debug(f"Cache MISS for {key} (expired)")
                del self._cache[actual_key]
                self._total_memory -= entry.size
                return None
            
            # íˆíŠ¸
            self._hit_count += 1
            self._access_count[key] += 1
            logger.debug(f"Cache HIT for {key}")
            
            # ì••ì¶•ëœ ë°ì´í„° ë³µì›
            value = entry.access()
            if isinstance(value, bytes) and actual_key.endswith(":compressed"):
                value = pickle.loads(zlib.decompress(value))
            
            return value
    
    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:
        """ìºì‹œì— ê°’ ì €ì¥"""
        with self._lock:
            # TTL ì„¤ì •
            if ttl is None:
                ttl = self._default_ttl
            
            # í¬ê¸° ì œí•œ í™•ì¸
            if len(self._cache) >= self._max_size:
                self._evict_lru()
            
            # ê¸°ì¡´ í•­ëª© ì œê±°
            if key in self._cache:
                old_entry = self._cache[key]
                self._total_memory -= old_entry.size
            
            # ì••ì¶• ì²˜ë¦¬
            compressed = False
            original_size = sys.getsizeof(value)
            if original_size > self._compression_threshold:
                compressed_value = zlib.compress(pickle.dumps(value))
                compressed_size = sys.getsizeof(compressed_value)
                if compressed_size < original_size * 0.8:  # 20% ì´ìƒ ì••ì¶• íš¨ê³¼
                    value = compressed_value
                    key = f"{key}:compressed"
                    compressed = True
                    logger.debug(f"Compressed {original_size} -> {compressed_size} bytes ({compressed_size/original_size:.1%})")
            
            # ìƒˆ í•­ëª© ì¶”ê°€
            entry = CacheEntry(value, ttl)
            self._cache[key] = entry
            self._total_memory += entry.size
            
            logger.debug(f"Cache SET for {key}, TTL={ttl}s, compressed={compressed}")
    
    def delete(self, key: str) -> bool:
        """ìºì‹œì—ì„œ í•­ëª© ì‚­ì œ"""
        with self._lock:
            # ì••ì¶•ëœ í‚¤ë„ í™•ì¸
            keys_to_check = [key, f"{key}:compressed"]
            
            for k in keys_to_check:
                if k in self._cache:
                    entry = self._cache[k]
                    self._total_memory -= entry.size
                    del self._cache[k]
                    logger.debug(f"Cache DELETE for {k}")
                    return True
            
            return False
    
    def clear(self, pattern: Optional[str] = None) -> int:
        """ìºì‹œ ë¹„ìš°ê¸°
        
        Args:
            pattern: ì‚­ì œí•  í‚¤ íŒ¨í„´ (Noneì´ë©´ ì „ì²´ ì‚­ì œ)
            
        Returns:
            ì‚­ì œëœ í•­ëª© ìˆ˜
        """
        with self._lock:
            if pattern is None:
                # ì „ì²´ ì‚­ì œ
                count = len(self._cache)
                self._cache.clear()
                self._total_memory = 0
                logger.info(f"Cache CLEAR: {count} items removed")
                return count
            
            # íŒ¨í„´ ë§¤ì¹­ ì‚­ì œ
            import fnmatch
            keys_to_delete = []
            
            for key in self._cache:
                if fnmatch.fnmatch(key, pattern):
                    keys_to_delete.append(key)
            
            for key in keys_to_delete:
                entry = self._cache[key]
                self._total_memory -= entry.size
                del self._cache[key]
            
            logger.info(f"Cache CLEAR pattern '{pattern}': {len(keys_to_delete)} items removed")
            return len(keys_to_delete)
    
    def _cleanup_expired(self) -> None:
        """ë§Œë£Œëœ í•­ëª© ì •ë¦¬"""
        with self._lock:
            expired_keys = []
            for key, entry in list(self._cache.items()):
                if entry.is_expired():
                    expired_keys.append(key)
            
            for key in expired_keys:
                self._remove_entry(key)
                self._expired_count += 1
            
            self._last_cleanup = time.time()
            if expired_keys:
                logger.debug(f"{len(expired_keys)}ê°œì˜ ë§Œë£Œëœ í•­ëª© ì œê±°")
    
    def _evict_lru(self) -> None:
        """LRU (Least Recently Used) ì •ì±…ìœ¼ë¡œ í•­ëª© ì œê±°"""
        if not self._cache:
            return
        
        # ê°€ì¥ ì˜¤ë˜ ì‚¬ìš©í•˜ì§€ ì•Šì€ í•­ëª© ì°¾ê¸°
        oldest_key = min(self._cache.keys(), 
                        key=lambda k: self._cache[k].last_accessed)
        self._remove_entry(oldest_key)
        self._eviction_count += 1
        logger.debug(f"LRU ì œê±°: {oldest_key}")
    
    def _evict_lfu(self) -> None:
        """LFU (Least Frequently Used) ì •ì±…ìœ¼ë¡œ í•­ëª© ì œê±°"""
        if not self._cache:
            return
        
        # ê°€ì¥ ì ê²Œ ì‚¬ìš©ëœ í•­ëª© ì°¾ê¸°
        least_used_key = min(self._cache.keys(), 
                            key=lambda k: self._cache[k].access_count)
        self._remove_entry(least_used_key)
        self._eviction_count += 1
        logger.debug(f"LFU ì œê±°: {least_used_key}")
    
    def get_stats(self) -> dict:
        """ìºì‹œ í†µê³„ ì¡°íšŒ"""
        with self._lock:
            total_requests = self._hit_count + self._miss_count
            hit_rate = self._hit_count / total_requests if total_requests > 0 else 0
            
            # í‰ê·  í•­ëª© ë‚˜ì´ ê³„ì‚°
            ages = [entry.get_age() for entry in self._cache.values()]
            avg_age = sum(ages) / len(ages) if ages else 0
            
            return {
                'hit_count': self._hit_count,
                'miss_count': self._miss_count,
                'hit_rate': hit_rate,
                'miss_rate': 1 - hit_rate,
                'total_entries': len(self._cache),
                'eviction_count': self._eviction_count,
                'avg_entry_age': avg_age,
                'memory_usage_mb': self._total_memory / (1024 * 1024),
                'api_calls_saved': self._hit_count,
            }
    
    def print_stats(self) -> None:
        """í†µê³„ ì¶œë ¥"""
        stats = self.get_stats()
        print(f"\nğŸ“Š ìºì‹œ í†µê³„:")
        print(f"- ìºì‹œ ì ì¤‘ë¥ : {stats['hit_rate']:.1%}")
        print(f"- ì´ í•­ëª© ìˆ˜: {stats['total_entries']:,}")
        print(f"- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {stats['memory_usage_mb']:.2f} MB")
        print(f"- API í˜¸ì¶œ ì ˆê°: {stats['api_calls_saved']:,}íšŒ")
        print(f"- í‰ê·  í•­ëª© ë‚˜ì´: {stats['avg_entry_age']:.1f}ì´ˆ")
        print(f"- ì œê±°ëœ í•­ëª©: {stats['eviction_count']:,}ê°œ")
    
    @property
    def hit_rate(self) -> float:
        """ìºì‹œ ì ì¤‘ë¥ """
        total = self._hit_count + self._miss_count
        return self._hit_count / total if total > 0 else 0
    
    @property
    def memory_usage(self) -> float:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
        return self._total_memory / (1024 * 1024)
    
    @property
    def expired_count(self) -> int:
        """ë§Œë£Œëœ í•­ëª© ìˆ˜"""
        with self._lock:
            return sum(1 for entry in self._cache.values() if entry.is_expired())

    def start_cleanup_thread(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘"""
        if not self._cleanup_thread or not self._cleanup_thread.is_alive():
            self._cleanup_thread = threading.Thread(target=self._cleanup_worker, daemon=True)
            self._cleanup_thread.start()
            logger.debug("ìºì‹œ ì •ë¦¬ ìŠ¤ë ˆë“œ ì‹œì‘")
    
    def stop_cleanup_thread(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ìŠ¤ë ˆë“œ ì •ì§€"""
        self._stop_cleanup = True
        if self._cleanup_thread and self._cleanup_thread.is_alive():
            self._cleanup_thread.join(timeout=5)
            logger.debug("ìºì‹œ ì •ë¦¬ ìŠ¤ë ˆë“œ ì •ì§€")
    
    def _cleanup_worker(self):
        """ë°±ê·¸ë¼ìš´ë“œ ì •ë¦¬ ì›Œì»¤"""
        while not self._stop_cleanup:
            time.sleep(self._cleanup_interval)
            if not self._stop_cleanup:
                self._cleanup_expired()
                logger.debug(f"ìºì‹œ ì •ë¦¬ ì™„ë£Œ - ë§Œë£Œëœ í•­ëª©: {self._expired_count}ê°œ")

    def _remove_entry(self, key: str):
        """ìºì‹œ í•­ëª© ì œê±° (ë‚´ë¶€ ì‚¬ìš©)"""
        if key in self._cache:
            entry = self._cache[key]
            self._total_memory -= entry.size
            del self._cache[key]


# APIë³„ ê¸°ë³¸ TTL ì„¤ì • (ì‹¤ì œ ë©”ì„œë“œ ê¸°ì¤€)
CACHE_TTL_CONFIG = {
    'fetch_domestic_price': 300,            # 5ë¶„
    'fetch_etf_domestic_price': 300,        # 5ë¶„
    'fetch_price_list': 300,                # 5ë¶„
    'fetch_price_detail_oversea_list': 300, # 5ë¶„
    'fetch_stock_info_list': 18000,         # 5ì‹œê°„
    'fetch_search_stock_info_list': 18000,  # 5ì‹œê°„
    'fetch_kospi_symbols': 259200,          # 3ì¼
    'fetch_kosdaq_symbols': 259200,         # 3ì¼
    'fetch_symbols': 259200,                # 3ì¼
}


def generate_cache_key(method_name: str, *args, **kwargs) -> str:
    """
    ë©”ì„œë“œëª…ê³¼ íŒŒë¼ë¯¸í„°ë¥¼ ì¡°í•©í•˜ì—¬ ìœ ë‹ˆí¬í•œ ìºì‹œ í‚¤ ìƒì„±
    
    ì˜ˆì‹œ:
    - fetch_domestic_price:J:005930
    - fetch_etf_domestic_price:J:294400
    - fetch_stock_info:005930:KR
    - fetch_kospi_symbols
    """
    key_parts = [method_name]
    key_parts.extend(str(arg) for arg in args)
    key_parts.extend(f"{k}={v}" for k, v in sorted(kwargs.items()))
    return ":".join(key_parts)


def cacheable(ttl: Optional[int] = None, 
              cache_condition: Optional[Callable] = None,
              key_generator: Optional[Callable] = None,
              use_dynamic_ttl: bool = True):
    """
    ë©”ì„œë“œì— ìºì‹± ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ëŠ” ë°ì½”ë ˆì´í„°
    
    Args:
        ttl: ì´ ë©”ì„œë“œì˜ TTL (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
        cache_condition: ìºì‹œ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜
        key_generator: ì»¤ìŠ¤í…€ ìºì‹œ í‚¤ ìƒì„± í•¨ìˆ˜
        use_dynamic_ttl: ë™ì  TTL ì‚¬ìš© ì—¬ë¶€
    
    ì‚¬ìš© ì˜ˆ:
    @cacheable(ttl=300)  # 5ë¶„
    def fetch_domestic_price(self, market_code: str, symbol: str) -> dict:
        ...
    
    @cacheable(ttl=259200, cache_condition=lambda result: result.get('rt_cd') == '0')  # 3ì¼
    def fetch_kospi_symbols(self) -> pd.DataFrame:
        ...
    """
    def decorator(func):
        @wraps(func)
        def wrapper(self, *args, **kwargs):
            # use_cache íŒŒë¼ë¯¸í„° í™•ì¸
            use_cache = kwargs.pop('use_cache', True)
            
            # ìºì‹œê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆê±°ë‚˜ use_cache=Falseì¸ ê²½ìš°
            if not hasattr(self, '_cache') or not self._cache or not use_cache:
                return func(self, *args, **kwargs)
            
            # ìºì‹œê°€ í™œì„±í™”ë˜ì§€ ì•Šì€ ê²½ìš°
            if hasattr(self, '_cache_enabled') and not self._cache_enabled:
                return func(self, *args, **kwargs)
            
            # ìºì‹œ í‚¤ ìƒì„±
            if key_generator:
                cache_key = key_generator(func.__name__, *args, **kwargs)
            else:
                cache_key = generate_cache_key(func.__name__, *args, **kwargs)
            
            # ìºì‹œì—ì„œ ì¡°íšŒ
            cached_value = self._cache.get(cache_key)
            if cached_value is not None:
                return cached_value
            
            # API í˜¸ì¶œ
            result = func(self, *args, **kwargs)
            
            # ìºì‹œ ì¡°ê±´ í™•ì¸
            should_cache = True
            if cache_condition:
                should_cache = cache_condition(result)
            
            # ìºì‹œ ì €ì¥
            if should_cache:
                # TTL ê²°ì •
                method_ttl = ttl
                if method_ttl is None:
                    method_ttl = CACHE_TTL_CONFIG.get(func.__name__, 
                                                      self._cache._default_ttl)
                
                # ë™ì  TTL ì ìš©
                if use_dynamic_ttl:
                    # market íŒŒë¼ë¯¸í„° ì¶”ì¶œ
                    market = 'KR'  # ê¸°ë³¸ê°’
                    if len(args) > 1 and isinstance(args[1], str):
                        # marketì´ ë‘ ë²ˆì§¸ ì¸ìë¡œ ì „ë‹¬ë˜ëŠ” ê²½ìš°
                        market = args[1]
                    elif 'market' in kwargs:
                        market = kwargs['market']
                    
                    # ë™ì  TTL ê³„ì‚°
                    from .market_hours import get_dynamic_ttl
                    method_ttl = get_dynamic_ttl(func.__name__, market)
                
                self._cache.set(cache_key, result, method_ttl)
            
            return result
        
        return wrapper
    return decorator 