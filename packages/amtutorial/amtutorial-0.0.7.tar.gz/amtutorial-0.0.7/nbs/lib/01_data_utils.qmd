# Pokemon Sprites
> A collection of useful functions and classes for downloading and processing the pokemon sprite data used in this tutorial.

```{python}
#| default_exp data_utils
```

## Cache Directory

We will use a cache directory to store the downloaded, processed data. This defaults to `~/.cache/amtutorial`, but can be overridden by setting the `AMTUTORIAL_CACHE_DIR` environment variable.

```{python}
#| export
import os
from typing import Optional
import functools as ft
from pathlib import Path
import amtutorial.path_fixes as pf
import requests
import imageio
```

```{python}
#| hide
# For rendering stuff only
import matplotlib.pyplot as plt
```

```{python}
#| export
APP_NAME = "amtutorial"

@ft.lru_cache()
def get_cache_dir(
    subfolder: Optional[str] = None, # Subdir of cache dir
) -> Path:
    """Get a cross-platform cache directory that works locally and in Google Colab."""
    if cache_dir := os.environ.get(f'{APP_NAME}_CACHE_DIR'):
        base_path = Path(cache_dir)
    else:
        cache_base = Path(os.environ.get('XDG_CACHE_HOME', '~/.cache')).expanduser() # Linux, macOS, Colab
        base_path = cache_base / APP_NAME
    
    if subfolder: base_path = base_path / subfolder
    base_path.mkdir(parents=True, exist_ok=True)
    return base_path
```


## Preparing Pokemon

For cutesies and funsies, let's build our own black and white pokemon dataset from the [Pokemon Database](https://pokemondb.net/sprites). Let's use a little help from AI to download and process our Pokemon sprites to be binary.

```{python}
#| export
#| hide
from fastcore.script import *
import requests
from bs4 import BeautifulSoup
import os
from urllib.parse import urlparse
import time
```

### Downloading Pokemon Sprites

```{python}
#| export
def download_pokemon_sprites(
    delay:float=0.1,                               # Delay between downloads (seconds) to be nice to server
    verbose:bool=True                              # Print progress messages
):
    "Download Pokemon sprite images from pokemondb.net"
    class_name='icon-pkmn'
    url='https://pokemondb.net/sprites'
    if delay < 0: raise ValueError(f"Error: delay must be non-negative, got {delay}")
    output_dir = get_cache_dir("_data/pokemon/raw")
    if verbose: print(f"Fetching sprite page from: {url}")
    
    try:
        response = requests.get(url)
        response.raise_for_status()
    except requests.RequestException as e:
        print(f"Error fetching page: {e}")
        return
    
    soup = BeautifulSoup(response.content, 'html.parser')
    img_tags = soup.find_all('img', class_=class_name)
    
    if verbose:
        print(f"Found {len(img_tags)} Pokemon sprites to download")
        print(f"Using {delay}s delay between downloads")
    
    if len(img_tags) == 0:
        print(f"Warning: No images found with class '{class_name}'. Check the URL and class name.")
        return
    
    downloaded_count = 0
    skipped_count = 0
    
    # Download each image
    for i, img in enumerate(img_tags, 1):
        src = img.get('src')
        if not src:
            if verbose: print(f"Skipping image {i}: no src attribute")
            skipped_count += 1
            continue
        
        # Handle relative URLs
        if src.startswith('//'): src = 'https:' + src
        elif src.startswith('/'): src = '/'.join(url.split('/')[:3]) + src
        
        # Get filename from URL
        filename = os.path.basename(urlparse(src).path)
        if not filename: filename = f"sprite_{i}.png"  # fallback filename
        filepath = os.path.join(output_dir, filename)
        
        # Skip if file already exists
        if os.path.exists(filepath):
            if verbose: print(f"Skipping {i}/{len(img_tags)}: {filename} (already exists)")
            skipped_count += 1
            continue
        
        try:
            img_response = requests.get(src)
            img_response.raise_for_status()
            with open(filepath, 'wb') as f: f.write(img_response.content)
            downloaded_count += 1
            if verbose: print(f"Downloaded {i}/{len(img_tags)}: {filename}")
            if delay > 0: time.sleep(delay) # Be nice to the server
                
        except Exception as e:
            print(f"Error downloading {src}: {e}")
            skipped_count += 1
    
    if verbose:
        print(f"Download complete! Downloaded: {downloaded_count}, Skipped: {skipped_count}, Total found: {len(img_tags)}")

```

```{python}
#| hide
#| eval: false
download_pokemon_sprites()
```

### Processing Pokemon Sprites

```{python}
#| export
#| hide
from PIL import Image
import numpy as np
import cv2
```

```{python}
#| export
def process_pokemon_sprites(
    ds_name:str, # Dataset name
    canvas_size:int=48, # Final image size
    sprite_percentage:float=0.95, # Pct of canvas the sprite should occupy (0.0-1.0)
    binarize_method:str='adaptive', # Binarization method: 'adaptive' or 'dithered'
    dither_strength:float=1.0,  # Dithering intensity (0.0=none, 1.0=full Floyd-Steinberg)
    invert_colors:bool=False, # Invert binary colors (only works with binarize=True)
    verbose:bool=True,  # Print progress messages
    force:bool=False # Force re-processing
):
    """Process Pokemon sprites: upscale non-transparent pixels, convert to white bg, resize to specified dimensions
    
    This script processes Pokemon sprite images by:
    1. Cropping excess transparency around sprites
    2. Scaling sprites to occupy a specified percentage of the canvas
    3. Converting transparent backgrounds to white
    4. Optionally converting to black and white using adaptive thresholding or dithering
    5. Optionally inverting the binary result (black background, white sprites)
    6. Centering sprites on a square canvas
    """
    input_dir = get_cache_dir("_data/pokemon/raw")
    output_dir = get_cache_dir(f"_data/pokemon/{ds_name}")
    
    # Validate inputs
    if not os.path.exists(input_dir): raise ValueError(f"Input directory '{input_dir}' does not exist")
    if not 0 < sprite_percentage <= 1.0: raise ValueError(f"sprite_percentage must be between 0 and 1.0, got {sprite_percentage}")
    if canvas_size <= 0: raise ValueError(f"canvas_size must be positive, got {canvas_size}")
    if not 0.0 <= dither_strength <= 1.0: raise ValueError(f"dither_strength must be between 0.0 and 1.0, got {dither_strength}")
    
    valid_methods = ['adaptive', 'dithered']
    if binarize_method not in valid_methods: raise ValueError(f"binarize_method must be one of {valid_methods}, got {binarize_method}")
    
    # Get all image files
    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif'))]
    
    if verbose:
        print(f"Processing {len(image_files)} Pokemon sprites...")
        print(f"Canvas size: {canvas_size}x{canvas_size}")
        print(f"Sprite will occupy {sprite_percentage*100:.1f}% of canvas ({int(canvas_size * sprite_percentage)} pixels max)")
        print(f"Binarization using '{binarize_method}' method")
        if binarize_method == 'dithered': print(f"Dither strength: {dither_strength} (0.0=none, 1.0=full)")
        if invert_colors: print("Colors will be inverted: black background, white sprites")
    
    processed_count = 0
    for i, filename in enumerate(image_files, 1):
        try:
            # Load image with transparency
            img_path = os.path.join(input_dir, filename)
            img = Image.open(img_path).convert('RGBA')
            
            # Find bounding box of non-transparent pixels
            bbox = get_sprite_bbox(img)
            if bbox is None:
                if verbose: print(f"Skipping {filename}: no non-transparent pixels found")
                continue
            
            # Crop to sprite content
            cropped = img.crop(bbox)
            
            # Calculate target size based on percentage of canvas
            target_size = int(canvas_size * sprite_percentage)
            
            # Scale the cropped sprite to target size while maintaining aspect ratio
            scaled = scale_to_fit(cropped, target_size)
            
            # Create canvas with white background
            final_img = Image.new('RGB', (canvas_size, canvas_size), 'white')
            
            # Calculate position to center the sprite
            x_offset = (canvas_size - scaled.width) // 2
            y_offset = (canvas_size - scaled.height) // 2
            
            # Paste the scaled sprite (with alpha compositing)
            final_img.paste(scaled, (x_offset, y_offset), scaled)
            
            # Apply binarization
            final_img = binarize_image(final_img, method=binarize_method, invert=invert_colors, dither_strength=dither_strength)
        
            # Save processed image
            output_path = os.path.join(output_dir, filename)
            final_img.save(output_path, 'PNG')
            
            processed_count += 1
            if verbose: print(f"Processed {i}/{len(image_files)}: {filename}")
            
        except Exception as e: print(f"Error processing {filename}: {e}")
    
    if verbose:
        print(f"Processing complete! Successfully processed {processed_count}/{len(image_files)} sprites.")

def binarize_image(img, method='adaptive', invert=False, dither_strength=1.0):
    """Apply binarization to convert image to black and white"""
    img_array = np.array(img)
    
    gray = 0.299 * img_array[:,:,0] + 0.587 * img_array[:,:,1] + 0.114 * img_array[:,:,2]
    gray = gray.astype(np.float32)
    
    if method == 'dithered':
        # Floyd-Steinberg dithering - creates grayscale illusion through pixel patterns
        binary = floyd_steinberg_dither(gray, strength=dither_strength)
    elif method == 'adaptive':
        # Adaptive thresholding - works better for varying lighting conditions
        gray_uint8 = gray.astype(np.uint8)
        binary = cv2.adaptiveThreshold(
            gray_uint8, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY, 11, 2
        )
    
    if np.mean(binary[0:5, 0:5]) < 128: binary = cv2.bitwise_not(binary)
    if invert: binary = cv2.bitwise_not(binary)
    binary_rgb = np.stack([binary, binary, binary], axis=2)
    return Image.fromarray(binary_rgb.astype(np.uint8))

def floyd_steinberg_dither(gray, strength=1.0):
    """Apply Floyd-Steinberg dithering with adjustable strength"""
    # Normalize to 0-1 range for processing
    img = gray / 255.0
    h, w = img.shape

    # Create a copy for error diffusion
    dithered = img.copy()
    
    # Floyd-Steinberg error diffusion with adjustable strength
    for y in range(h):
        for x in range(w):
            old_pixel = dithered[y, x]
            
            # Quantize to 0 or 1 (black or white)
            new_pixel = 1.0 if old_pixel > 0.5 else 0.0
            dithered[y, x] = new_pixel
            
            # Calculate quantization error and scale by strength
            error = (old_pixel - new_pixel) * strength
            
            # Distribute error to neighboring pixels
            if x + 1 < w: dithered[y, x + 1] += error * 7/16
            if y + 1 < h:
                if x - 1 >= 0: dithered[y + 1, x - 1] += error * 3/16
                dithered[y + 1, x] += error * 5/16
                if x + 1 < w: dithered[y + 1, x + 1] += error * 1/16
    
    # Convert back to 0-255 range
    return (dithered * 255).astype(np.uint8)

def get_sprite_bbox(img):
    """Get bounding box of non-transparent pixels"""
    data = np.array(img)
    alpha = data[:, :, 3]
    non_transparent = alpha > 0
    
    if not non_transparent.any(): return None
    rows = np.any(non_transparent, axis=1)
    cols = np.any(non_transparent, axis=0)
    
    y_min, y_max = np.where(rows)[0][[0, -1]]
    x_min, x_max = np.where(cols)[0][[0, -1]]
    
    return (x_min, y_min, x_max + 1, y_max + 1)

def scale_to_fit(img, target_size):
    """Scale image to fit within target_size while maintaining aspect ratio"""
    scale_factor = min(target_size / img.width, target_size / img.height)
    new_width = int(img.width * scale_factor)
    new_height = int(img.height * scale_factor)
    return img.resize((new_width, new_height), Image.Resampling.LANCZOS)

```

We can experiment with different binarization methods.


```{python}
# Experimenting with different binarization methods
process_pokemon_sprites("processed_adaptive", binarize_method='adaptive') # Best
```

We only care about efficient representations of this data for this tutorial. `.npy` file and `.txt` file of names it is!

```{python}
#| export
def datafy_pokemon_sprites(ds_name:str):
    """Convert Pokemon sprites to numpy arrays and save filenames"""
    input_dir = get_cache_dir(f"_data/pokemon/{ds_name}")
    pixels_path = input_dir / 'pokesprites_pixels.npy'
    names_path = input_dir / 'pokesprites_names.txt'

    files = sorted([f for f in os.listdir(input_dir) if f.lower().endswith('.png')])
    images = np.array([np.array(Image.open(os.path.join(input_dir, f)).convert('L')) for f in files])
    
    np.save(pixels_path, images)
    with open(names_path, 'w') as f: f.write('\n'.join(files))
    return pixels_path, names_path
```

```{python}
#| output: false
download_pokemon_sprites()
process_pokemon_sprites("processed_adaptive", binarize_method='adaptive') # Best
poke_pixels_path, poke_names_path = datafy_pokemon_sprites("processed_adaptive")
```

Let's load the data and take a look at it.

```{python}
#| export
@ft.lru_cache()
def load_bipolar_pokemon_sprites(ds_name:str='processed_adaptive', binarize_method:str='adaptive'):
    """Load Pokemon sprites from numpy arrays"""
    download_pokemon_sprites()
    process_pokemon_sprites(ds_name, binarize_method=binarize_method)
    poke_pixels_path, poke_names_path = datafy_pokemon_sprites(ds_name)
    poke_pixels = np.load(poke_pixels_path)
    poke_pixels = (poke_pixels > 0).astype(np.float32) * 2 - 1
    poke_names = [n.strip().replace('.png', '') for n in open(poke_names_path).readlines()]
    return poke_pixels, poke_names
```

```{python}
#| export
#|hide
cli_download_pokemon_sprites = call_parse(download_pokemon_sprites)
cli_process_pokemon_sprites = call_parse(process_pokemon_sprites)
cli_datafy_pokemon_sprites = call_parse(datafy_pokemon_sprites)
```

This is what the pokemon data looks like after all the processing.

```{python}
#| echo: false
poke_pixels, poke_names = load_bipolar_pokemon_sprites()
assert poke_pixels.min() == -1 and poke_pixels.max() == 1
assert len(poke_names) == poke_pixels.shape[0]

np.random.seed(42)
n_rows = n_cols = 6
idxs = np.random.choice(np.arange(len(poke_names)), n_rows * n_cols, replace=False)
fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_rows*1.2, n_cols*1.2))

for i, ax in enumerate(axs.flat):
    ax.imshow(poke_pixels[idxs[i]], cmap='gray')
    ax.set_title(poke_names[idxs[i]])
    ax.axis('off')

plt.tight_layout()
plt.show()
```


## Downloading data from github repo

All data used in this tutorial are small, so we upload and download them from the [github](https://github.com/bhoov/amtutorial/tree/main/data) itself.

```{python}
# poke_pixels, poke_names = get_pokemon_data()
poke_pixels, poke_names = load_bipolar_pokemon_sprites()
np.save(pf.DATA / "pokesprites_pixels.npy", poke_pixels)
with open(pf.DATA / "pokesprites_names.txt", 'w') as f: f.write('\n'.join(poke_names))
```

We can download the github repo to our cache directory.

```{python}
#| export
def download_github_folder(
    repo: str = "bhoov/amtutorial",
    branch: str = "main", 
    folder_path: str = "data",
    cache_subdir: str = ""
) -> Path:
    """Download GitHub folder in one API call using Trees API."""
    cache_dir = get_cache_dir(cache_subdir)
    
    print(f"Downloading {folder_path}/ folder from {repo}...")
    
    # Get entire repo tree recursively in ONE call
    tree_url = f"https://api.github.com/repos/{repo}/git/trees/{branch}?recursive=1"
    response = requests.get(tree_url)
    response.raise_for_status()
    
    tree_data = response.json()
    
    # Filter files that are in our target folder
    for item in tree_data['tree']:
        if item['type'] == 'blob' and item['path'].startswith(f"{folder_path}/"):
            # Download file
            rel_path = Path(item['path']).relative_to(folder_path)
            local_file = cache_dir / rel_path
            local_file.parent.mkdir(parents=True, exist_ok=True)
            
            print(f"  Downloading {item['path']}...")
            
            # Use raw GitHub URL for download
            raw_url = f"https://raw.githubusercontent.com/{repo}/{branch}/{item['path']}"
            file_response = requests.get(raw_url)
            file_response.raise_for_status()
            
            with open(local_file, 'wb') as f:
                f.write(file_response.content)
    
    print(f"Downloaded to: {cache_dir}")
    return cache_dir

def download_remote_data():
    download_github_folder(
        repo="bhoov/amtutorial",
        branch="main",
        folder_path="data",
        cache_subdir=""
    )

@ft.lru_cache()
def get_pokemon_data():
    pixel_fname, names_fname = "pokesprites_pixels.npy", "pokesprites_names.txt"
    if not (get_cache_dir() / pixel_fname).exists() or not (get_cache_dir() / names_fname).exists():
        download_remote_data()
    poke_pixels = np.load(get_cache_dir() / pixel_fname)
    poke_names = [n.strip().replace('.png', '') for n in open(get_cache_dir() / names_fname).readlines()]
    return poke_pixels, poke_names

@ft.lru_cache()
def get_et_imgs():
    et_dir = get_cache_dir() / "et-figs"
    try:
        imgs = np.stack([imageio.imread(f) for f in sorted(et_dir.glob("*.png"))])
        assert len(imgs) == 11
    except:
        download_remote_data()
        imgs = np.stack([imageio.imread(f) for f in sorted(et_dir.glob("*.png"))])
        assert len(imgs) == 11
    return imgs

@ft.lru_cache()
def get_et_checkpoint():
    ckpt_fname = "et_ckpt.npz"
    if not (get_cache_dir() / ckpt_fname).exists(): download_remote_data()  
    return np.load(get_cache_dir() / ckpt_fname)
```