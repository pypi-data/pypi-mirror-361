import os
import ast
import json
import re
import time
import shutil
from typing import Dict, List, Tuple, Optional, Any
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
from rich.console import Console
from rich.progress import Progress, TaskID, TimeElapsedColumn, TimeRemainingColumn, SpinnerColumn, TextColumn, BarColumn, MofNCompleteColumn
from rich.live import Live
from rich.table import Table
from rich.panel import Panel

try:
    import yaml
except ImportError:
    yaml = None

from readmex.utils.model_client import ModelClient
from readmex.utils.file_handler import (
    find_files,
    get_project_structure,
    load_gitignore_patterns,
)
from readmex.config import load_config
from readmex.code_rag import CodeRAG


class ProgressTracker:
    """è¿›åº¦è·Ÿè¸ªå™¨ï¼Œç”¨äºæ˜¾ç¤ºè¯¦ç»†çš„ç”Ÿæˆè¿›åº¦ä¿¡æ¯"""
    
    def __init__(self, console: Console):
        self.console = console
        self.start_time = None
        self.current_stage = ""
        self.stages = [
            ("é¡¹ç›®åˆ†æ", "æ­£åœ¨åˆ†æé¡¹ç›®ç»“æ„å’Œä»£ç ..."),
            ("é¦–é¡µç”Ÿæˆ", "æ­£åœ¨ç”Ÿæˆé¡¹ç›®é¦–é¡µæ–‡æ¡£..."),
            ("å®‰è£…æŒ‡å—", "æ­£åœ¨ç”Ÿæˆå®‰è£…è¯´æ˜æ–‡æ¡£..."),
            ("ä½¿ç”¨è¯´æ˜", "æ­£åœ¨ç”Ÿæˆä½¿ç”¨æŒ‡å—æ–‡æ¡£..."),
            ("APIæ–‡æ¡£", "æ­£åœ¨ç”ŸæˆAPIå‚è€ƒæ–‡æ¡£..."),
            ("ç¤ºä¾‹æ–‡æ¡£", "æ­£åœ¨ç”Ÿæˆä»£ç ç¤ºä¾‹æ–‡æ¡£..."),
            ("æ¶æ„æ–‡æ¡£", "æ­£åœ¨ç”Ÿæˆé¡¹ç›®æ¶æ„æ–‡æ¡£..."),
            ("è´¡çŒ®æŒ‡å—", "æ­£åœ¨ç”Ÿæˆè´¡çŒ®è€…æŒ‡å—..."),
            ("æ›´æ–°æ—¥å¿—", "æ­£åœ¨ç”Ÿæˆå˜æ›´æ—¥å¿—æ¨¡æ¿..."),
            ("é…ç½®æ–‡ä»¶", "æ­£åœ¨ç”ŸæˆMkDocsé…ç½®æ–‡ä»¶...")
        ]
        self.current_stage_index = 0
        self.total_stages = len(self.stages)
        
    def start(self):
        """å¼€å§‹è¿›åº¦è·Ÿè¸ª"""
        self.start_time = time.time()
        
    def update_stage(self, stage_index: int):
        """æ›´æ–°å½“å‰é˜¶æ®µ"""
        if stage_index < len(self.stages):
            self.current_stage_index = stage_index
            self.current_stage = self.stages[stage_index][1]
            
    def get_elapsed_time(self) -> str:
        """è·å–å·²ç”¨æ—¶é—´"""
        if self.start_time is None:
            return "00:00"
        elapsed = time.time() - self.start_time
        minutes = int(elapsed // 60)
        seconds = int(elapsed % 60)
        return f"{minutes:02d}:{seconds:02d}"
        
    def get_estimated_time(self) -> str:
        """è·å–é¢„è®¡æ€»æ—¶é—´"""
        if self.start_time is None or self.current_stage_index == 0:
            return "é¢„ä¼°ä¸­..."
        
        elapsed = time.time() - self.start_time
        progress_ratio = self.current_stage_index / self.total_stages
        
        if progress_ratio > 0:
            estimated_total = elapsed / progress_ratio
            remaining = estimated_total - elapsed
            
            if remaining < 0:
                return "å³å°†å®Œæˆ"
                
            minutes = int(remaining // 60)
            seconds = int(remaining % 60)
            return f"{minutes:02d}:{seconds:02d}"
        
        return "é¢„ä¼°ä¸­..."
        
    def create_progress_display(self) -> Table:
        """åˆ›å»ºè¿›åº¦æ˜¾ç¤ºè¡¨æ ¼"""
        table = Table.grid(padding=1)
        table.add_column(style="cyan", no_wrap=True)
        table.add_column(style="white")
        
        # è¿›åº¦ä¿¡æ¯
        progress_percent = (self.current_stage_index / self.total_stages) * 100
        progress_bar = "â–ˆ" * int(progress_percent // 5) + "â–‘" * (20 - int(progress_percent // 5))
        
        table.add_row("ğŸ“Š æ€»ä½“è¿›åº¦:", f"[{progress_bar}] {progress_percent:.1f}% ({self.current_stage_index}/{self.total_stages})")
        table.add_row("â±ï¸  å·²ç”¨æ—¶é—´:", self.get_elapsed_time())
        table.add_row("â³ é¢„è®¡å‰©ä½™:", self.get_estimated_time())
        table.add_row("ğŸ”„ å½“å‰é˜¶æ®µ:", self.current_stage)
        
        return table


class WebsiteGenerator:
    """MkDocsç½‘ç«™ç”Ÿæˆå™¨ - ç‹¬ç«‹äºREADMEç”Ÿæˆé€»è¾‘"""
    
    def __init__(self, project_dir: str, output_dir: str = None, model_client=None, verbose: bool = False, debug: bool = False, enable_rag: bool = True):
        self.project_dir = Path(project_dir)
        self.output_dir = Path(output_dir) if output_dir else self.project_dir / "website"
        self.console = Console()
        self.model_client = model_client or self._create_model_client()
        self.config = load_config()
        self.verbose = verbose
        self.debug = debug
        self.enable_rag = enable_rag
        
        # ç½‘ç«™ç»“æ„é…ç½®
        self.docs_dir = self.output_dir / "docs"
        self.api_dir = self.docs_dir / "api"
        self.assets_dir = self.output_dir / "assets"
        
        # APIæ–‡æ¡£ç”Ÿæˆç­–ç•¥
        self.api_filter = APIDocumentationFilter()
        self.api_generator = APIDocumentationGenerator(self.model_client, debug)
        
        # åˆ›å»ºè¿›åº¦è·Ÿè¸ªå™¨
        self.progress_tracker = ProgressTracker(self.console)
        
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        self.code_rag = None
        if self.enable_rag:
            try:
                from readmex.config import get_embedding_config
                
                cache_dir = self.output_dir / ".rag_cache"
                # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
                cache_dir.mkdir(parents=True, exist_ok=True)
                
                # è·å–embeddingé…ç½®
                embedding_config = get_embedding_config()
                
                self.code_rag = CodeRAG(
                    project_dir=str(self.project_dir),
                    cache_dir=str(cache_dir),
                    use_local_embedding=embedding_config.get('local_embedding', True)
                )
                self.console.print("[green]âœ… RAGç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ[/green]")
            except Exception as e:
                self.console.print(f"[yellow]âš ï¸  RAGç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}[/yellow]")
                self.console.print("[yellow]å°†ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼ç”Ÿæˆæ–‡æ¡£[/yellow]")
                self.enable_rag = False
        
    def _create_model_client(self):
        """åˆ›å»ºæ¨¡å‹å®¢æˆ·ç«¯ï¼Œå¤„ç†å¯èƒ½çš„é”™è¯¯"""
        try:
            return ModelClient()
        except Exception as e:
            self.console.print(f"[yellow]Warning: Could not create ModelClient: {e}[/yellow]")
            return None
        
    def generate_website(self) -> None:
        """ç”Ÿæˆå®Œæ•´çš„MkDocsç½‘ç«™"""
        self.console.print("[bold green]ğŸŒ å¼€å§‹ç”Ÿæˆé¡¹ç›®ç½‘ç«™...[/bold green]")
        
        # å¯åŠ¨è¿›åº¦è·Ÿè¸ª
        self.progress_tracker.start()
        
        # åˆ›å»ºç›®å½•ç»“æ„
        self._create_directory_structure()
        
        # é˜¶æ®µ0: åˆ†æé¡¹ç›®ï¼ˆä¸æ˜¾ç¤ºè¿›åº¦æ¡ï¼‰
        self.progress_tracker.update_stage(0)
        project_analysis = self._analyze_project()
        
        # é˜¶æ®µ1: ç”Ÿæˆé¦–é¡µï¼ˆREADMEç”Ÿæˆé˜¶æ®µï¼Œä¸æ˜¾ç¤ºç½‘ç«™è¿›åº¦æ¡ï¼‰
        self.progress_tracker.update_stage(1)
        self._generate_home_page(project_analysis)
        
        # READMEç”Ÿæˆå®Œæˆåï¼Œå¼€å§‹æ˜¾ç¤ºç½‘ç«™ç”Ÿæˆè¿›åº¦æ¡
        self.console.print("\n[bold green]ğŸŒ å¼€å§‹å¹¶è¡Œç”Ÿæˆç½‘ç«™å…¶ä»–é¡µé¢...[/bold green]")
        
        # ä½¿ç”¨Liveæ˜¾ç¤ºå®æ—¶è¿›åº¦ï¼ˆä»é˜¶æ®µ2å¼€å§‹ï¼‰
        with Live(self.progress_tracker.create_progress_display(), refresh_per_second=1, console=self.console) as live:
            # å¹¶è¡Œç”Ÿæˆæ‰€æœ‰é¡µé¢
            self._generate_pages_in_parallel(project_analysis, live)
            
            # é˜¶æ®µ9: ç”Ÿæˆé…ç½®æ–‡ä»¶
            self.progress_tracker.update_stage(9)
            live.update(self.progress_tracker.create_progress_display())
            config = self._create_mkdocs_config(project_analysis)
            self._write_mkdocs_config(config)
            
            # å®Œæˆ
            self.progress_tracker.current_stage_index = self.progress_tracker.total_stages
            self.progress_tracker.current_stage = "âœ… ç½‘ç«™ç”Ÿæˆå®Œæˆï¼"
            live.update(self.progress_tracker.create_progress_display())
            time.sleep(1)  # è®©ç”¨æˆ·çœ‹åˆ°å®ŒæˆçŠ¶æ€
        
        self.console.print(f"\n[bold green]âœ… ç½‘ç«™ç”Ÿæˆå®Œæˆ: {self.output_dir}[/bold green]")
        
    def _generate_pages_in_parallel(self, project_analysis: Dict, live) -> None:
        """å¹¶è¡Œç”Ÿæˆæ‰€æœ‰é¡µé¢ä»¥æå‡æ€§èƒ½"""
        # å®šä¹‰éœ€è¦å¹¶è¡Œç”Ÿæˆçš„é¡µé¢ä»»åŠ¡
        page_tasks = [
            ('installation', 2, self._generate_installation_page),
            ('usage', 3, self._generate_usage_page), 
            ('examples', 5, self._generate_examples_page),
            ('architecture', 6, self._generate_architecture_page),
            ('contributing', 7, self._generate_contributing_page),
            ('changelog', 8, self._generate_changelog_page)
        ]
        
        # APIæ–‡æ¡£å•ç‹¬å¤„ç†ï¼Œå› ä¸ºå®ƒæœ‰è‡ªå·±çš„å¹¶è¡Œé€»è¾‘
        self.progress_tracker.update_stage(4)
        live.update(self.progress_tracker.create_progress_display())
        self._generate_api_documentation(project_analysis)
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œç”Ÿæˆå…¶ä»–é¡µé¢
        with ThreadPoolExecutor(max_workers=20) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {}
            for page_type, stage_index, generator_func in page_tasks:
                future = executor.submit(self._generate_page_wrapper, page_type, project_analysis, generator_func)
                future_to_task[future] = (page_type, stage_index)
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆå¹¶æ›´æ–°è¿›åº¦
            completed_stages = set()
            for future in as_completed(future_to_task):
                page_type, stage_index = future_to_task[future]
                try:
                    future.result()
                    completed_stages.add(stage_index)
                    
                    # æ›´æ–°è¿›åº¦åˆ°æœ€æ–°å®Œæˆçš„é˜¶æ®µ
                    max_completed_stage = max(completed_stages) if completed_stages else 2
                    self.progress_tracker.update_stage(max_completed_stage)
                    live.update(self.progress_tracker.create_progress_display())
                    
                    if self.verbose:
                        self.console.print(f"[green]âœ… {page_type} é¡µé¢ç”Ÿæˆå®Œæˆ[/green]")
                        
                except Exception as e:
                    self.console.print(f"[red]âŒ {page_type} é¡µé¢ç”Ÿæˆå¤±è´¥: {e}[/red]")
                    if self.debug:
                        import traceback
                        self.console.print(f"[red]{traceback.format_exc()}[/red]")
    
    def _generate_page_wrapper(self, page_type: str, project_analysis: Dict, generator_func) -> None:
        """é¡µé¢ç”ŸæˆåŒ…è£…å™¨ï¼Œç”¨äºå¹¶è¡Œæ‰§è¡Œ"""
        try:
            generator_func(project_analysis)
        except Exception as e:
            # ä¿ç•™åŸå§‹å¼‚å¸¸ä¿¡æ¯ï¼Œä¾¿äºè°ƒè¯•
            import traceback
            error_details = traceback.format_exc()
            raise Exception(f"ç”Ÿæˆ{page_type}é¡µé¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}\nè¯¦ç»†é”™è¯¯ä¿¡æ¯:\n{error_details}") from e
        
    def _create_directory_structure(self) -> None:
        """åˆ›å»ºç½‘ç«™ç›®å½•ç»“æ„"""
        directories = [
            self.output_dir,
            self.docs_dir,
            self.api_dir,
            self.assets_dir,
            self.assets_dir / "images",
            self.assets_dir / "css",
            self.docs_dir / "assets",
            self.docs_dir / "assets" / "images"
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
            
        # å¤åˆ¶é¡¹ç›®èµ„æºæ–‡ä»¶åˆ°docs/assetsç›®å½•
        self._copy_project_assets()
            
    def _analyze_project(self) -> Dict[str, Any]:
        """åˆ†æé¡¹ç›®ç»“æ„å’Œå†…å®¹"""
        # åŠ è½½gitignoreæ¨¡å¼
        ignore_patterns = load_gitignore_patterns(str(self.project_dir))
        
        analysis = {
            'structure': get_project_structure(str(self.project_dir), ignore_patterns),
            'dependencies': self._get_dependencies(),
            'functions': self._extract_functions(),
            'classes': self._extract_classes(),
            'modules': self._get_modules(),
            'entry_points': self._find_entry_points(),
            'git_info': self._get_git_info()
        }
        
        # å¦‚æœå¯ç”¨äº†RAGï¼Œè¿›è¡Œæ·±åº¦ä»£ç åˆ†æ
        if self.enable_rag and self.code_rag is not None:
            try:
                self.console.print("[blue]ğŸ” å¼€å§‹RAGä»£ç åˆ†æ...[/blue]")
                
                # æå–ä»£ç å—
                code_blocks = self.code_rag.extract_code_blocks()
                
                # æ„å»ºå‘é‡åµŒå…¥
                if self.code_rag.build_embeddings():
                    # è·å–ä»£ç ç»Ÿè®¡ä¿¡æ¯
                    rag_stats = self.code_rag.get_code_statistics()
                    analysis['rag_stats'] = rag_stats
                    analysis['rag_enabled'] = True
                    
                    self.console.print(f"[green]âœ… RAGåˆ†æå®Œæˆ: {len(code_blocks)} ä¸ªä»£ç å—[/green]")
                else:
                    analysis['rag_enabled'] = False
                    self.console.print("[yellow]âš ï¸  RAGå‘é‡åŒ–å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿåˆ†æ[/yellow]")
                    
            except Exception as e:
                self.console.print(f"[red]âŒ RAGåˆ†æå¤±è´¥: {e}[/red]")
                analysis['rag_enabled'] = False
        else:
            analysis['rag_enabled'] = False
        
        return analysis
        
    def _generate_home_page(self, analysis: Dict) -> None:
        """ç”Ÿæˆé¦–é¡µ - ä½¿ç”¨READMEç”Ÿæˆé€»è¾‘"""
        content = self._generate_readme_as_homepage(analysis)

        # åå¤„ç†ï¼šæ·»åŠ logoæ”¯æŒ
        content = self._post_process_homepage_content(content)
        self._write_page('index.md', content)
        
    def _generate_installation_page(self, analysis: Dict) -> None:
        """ç”Ÿæˆå®‰è£…é¡µé¢"""
        content = self._generate_page_content('installation', analysis)
        self._write_page('installation.md', content)
        
    def _generate_usage_page(self, analysis: Dict) -> None:
        """ç”Ÿæˆä½¿ç”¨è¯´æ˜é¡µé¢"""
        content = self._generate_page_content('usage', analysis)
        self._write_page('usage.md', content)
        
    def _generate_api_documentation(self, analysis: Dict) -> None:
        """ç”ŸæˆAPIæ–‡æ¡£ - æ™ºèƒ½ç­›é€‰æœ‰ä»·å€¼çš„å‡½æ•°"""
        # ç­›é€‰æœ‰ä»·å€¼çš„API
        valuable_apis = self.api_filter.filter_valuable_apis(
            analysis['functions'], 
            analysis['classes']
        )
        
        # ç”ŸæˆAPIç´¢å¼•é¡µé¢
        api_index_content = self._generate_api_index(valuable_apis)
        self._write_page('api/index.md', api_index_content)
        
        # ä¸ºæ¯ä¸ªAPIç”Ÿæˆç‹¬ç«‹é¡µé¢
        self._generate_individual_api_pages(valuable_apis)
        
    def _generate_individual_api_pages(self, apis: List[Dict]) -> None:
        """ä¸ºæ¯ä¸ªAPIç”Ÿæˆç‹¬ç«‹çš„markdowné¡µé¢"""
        with ThreadPoolExecutor(max_workers=20) as executor:
            futures = []
            
            for api in apis:
                future = executor.submit(self._generate_single_api_page, api)
                futures.append(future)
                
            for future in as_completed(futures):
                try:
                    future.result()
                except Exception as e:
                    self.console.print(f"[red]APIé¡µé¢ç”Ÿæˆå¤±è´¥: {e}[/red]")
                    
    def _generate_single_api_page(self, api: Dict) -> None:
        """ç”Ÿæˆå•ä¸ªAPIçš„è¯¦ç»†æ–‡æ¡£é¡µé¢"""
        content = self.api_generator.generate_api_documentation(
            api['definition'],
            api['context'],
            api['metadata']
        )
        
        filename = f"api/{api['module']}/{api['name']}.md"
        self._write_page(filename, content)
        
    def _generate_examples_page(self, analysis: Dict) -> None:
        """ç”Ÿæˆç¤ºä¾‹é¡µé¢"""
        content = self._generate_page_content('examples', analysis)
        self._write_page('examples.md', content)
        
    def _generate_architecture_page(self, analysis: Dict) -> None:
        """ç”Ÿæˆæ¶æ„é¡µé¢ - å¹¶è¡Œç”Ÿæˆå›¾è¡¨å’Œæ–‡æ¡£å†…å®¹"""
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œç”Ÿæˆæ¶æ„å›¾å’Œæ–‡æ¡£å†…å®¹
        with ThreadPoolExecutor(max_workers=20) as executor:
            # æäº¤ä¸¤ä¸ªå¹¶è¡Œä»»åŠ¡
            drawio_future = executor.submit(self._generate_drawio_diagram, analysis)
            content_future = executor.submit(self._generate_page_content, 'architecture', analysis)
            
            # ç­‰å¾…ä¸¤ä¸ªä»»åŠ¡å®Œæˆ
            drawio_content = drawio_future.result()
            content = content_future.result()
        
        # ä¿å­˜æ¶æ„å›¾æ–‡ä»¶
        drawio_file_path = self.docs_dir / 'architecture_diagram.drawio'
        try:
            with open(drawio_file_path, 'w', encoding='utf-8') as f:
                f.write(drawio_content)
            if self.verbose:
                self.console.print(f"[green]æ¶æ„å›¾å·²ä¿å­˜åˆ°: {drawio_file_path}[/green]")
        except Exception as e:
            if self.verbose:
                self.console.print(f"[red]ä¿å­˜æ¶æ„å›¾å¤±è´¥: {e}[/red]")
        
        # åå¤„ç†ï¼šæ›¿æ¢å ä½ç¬¦ä¸º markdown å›¾ç‰‡å¼•ç”¨è¯­æ³•
        content = self._post_process_architecture_content(content, drawio_content)
        
        self._write_page('architecture.md', content)
        
    def _generate_contributing_page(self, analysis: Dict) -> None:
        """ç”Ÿæˆè´¡çŒ®æŒ‡å—é¡µé¢"""
        content = self._generate_page_content('contributing', analysis)
        self._write_page('contributing.md', content)
        
    def _generate_changelog_page(self, analysis: Dict) -> None:
        """ç”Ÿæˆæ›´æ–°æ—¥å¿—é¡µé¢"""
        content = self._generate_page_content('changelog', analysis)
        self._write_page('changelog.md', content)
        
    def _post_process_architecture_content(self, content: str, drawio_content: str) -> str:
        """
        åå¤„ç†æ¶æ„æ–‡æ¡£å†…å®¹ï¼Œå°†å ä½ç¬¦æ›¿æ¢ä¸º markdown å›¾ç‰‡å¼•ç”¨è¯­æ³•
        
        Args:
            content: åŸå§‹çš„æ¶æ„æ–‡æ¡£å†…å®¹
            drawio_content: drawio XML å†…å®¹ï¼ˆæ­¤å‚æ•°ä¿ç•™å…¼å®¹æ€§ï¼Œä½†ä¸å†ä½¿ç”¨ï¼‰
            
        Returns:
            str: å¤„ç†åçš„æ¶æ„æ–‡æ¡£å†…å®¹
        """
        # ç›´æ¥æ›¿æ¢ä¸º markdown å›¾ç‰‡å¼•ç”¨è¯­æ³•
        markdown_reference = "![é¡¹ç›®æ¶æ„å›¾](architecture_diagram.drawio)"
        
        # æ›¿æ¢å ä½ç¬¦
        processed_content = content.replace('{{ARCHITECTURE_DIAGRAM_PLACEHOLDER}}', markdown_reference)
        
        return processed_content
    
    def _post_process_homepage_content(self, content: str) -> str:
        """
        åå¤„ç†é¦–é¡µå†…å®¹ï¼Œå¤„ç†logoå›¾ç‰‡è·¯å¾„
        
        Args:
            content: åŸå§‹çš„é¦–é¡µå†…å®¹
            
        Returns:
            str: å¤„ç†åçš„é¦–é¡µå†…å®¹
        """
        # å¤åˆ¶logoåˆ°assetsç›®å½•
        logo_relative_path = self._copy_logo_to_assets()
        
        if logo_relative_path:
            # æ›¿æ¢logoè·¯å¾„ä¸ºç›¸å¯¹äºwebsiteçš„æ­£ç¡®è·¯å¾„
            # å°† images/logo.png æˆ– images/logo.svg æ›¿æ¢ä¸ºæ­£ç¡®çš„ç›¸å¯¹è·¯å¾„
            import re
            
            # åŒ¹é…å„ç§logoå¼•ç”¨æ ¼å¼ï¼ˆåŒ…æ‹¬ç›¸å¯¹è·¯å¾„ï¼‰
            logo_patterns = [
                r'<img src="(\.\./)?images/logo\.png"([^>]*)>',
                r'<img src="(\.\./)?images/logo\.svg"([^>]*)>',
                r'!\[([^\]]*)\]\((\.\./)?images/logo\.png\)',
                r'!\[([^\]]*)\]\((\.\./)?images/logo\.svg\)',
            ]
            
            for pattern in logo_patterns:
                if 'img src' in pattern:
                    # HTMLæ ¼å¼ - ç¬¬äºŒä¸ªæ•è·ç»„æ˜¯imgæ ‡ç­¾çš„å…¶ä»–å±æ€§
                    content = re.sub(pattern, f'<img src="{logo_relative_path}"\\2>', content)
                else:
                    # Markdownæ ¼å¼ - ç¬¬ä¸€ä¸ªæ•è·ç»„æ˜¯altæ–‡æœ¬
                    content = re.sub(pattern, f'![\\1]({logo_relative_path})', content)
        
        return content
    
    def _copy_logo_to_assets(self) -> str:
        """
        å¤åˆ¶é¡¹ç›®æ ¹ç›®å½•çš„logoåˆ°website/docs/assetsç›®å½•ï¼Œå¹¶è°ƒæ•´å¤§å°
        
        Returns:
            str: logoçš„ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äºdocsç›®å½•ï¼‰ï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°logoåˆ™è¿”å›None
        """
        # ç¡®ä¿docs/assets/imagesç›®å½•å­˜åœ¨
        docs_assets_images_dir = self.docs_dir / "assets" / "images"
        docs_assets_images_dir.mkdir(parents=True, exist_ok=True)
        
        # æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•çš„logoæ–‡ä»¶
        logo_files = ['logo.svg', 'logo.png']
        project_images_dir = self.project_dir / "images"
        
        for logo_file in logo_files:
            logo_source = project_images_dir / logo_file
            if logo_source.exists():
                # å¤åˆ¶logoåˆ°docs/assetsç›®å½•
                logo_dest = docs_assets_images_dir / logo_file
                try:
                    # å¦‚æœæ˜¯PNGæ–‡ä»¶ï¼Œå°è¯•è°ƒæ•´å¤§å°
                    if logo_file.endswith('.png'):
                        self._resize_and_copy_image(logo_source, logo_dest, max_height=100)
                    else:
                        shutil.copy2(logo_source, logo_dest)
                    
                    # è¿”å›ç›¸å¯¹äºdocsç›®å½•çš„è·¯å¾„
                    relative_path = f"assets/images/{logo_file}"
                    if self.verbose:
                        self.console.print(f"[green]âœ… Logoå·²å¤åˆ¶åˆ°: {logo_dest}[/green]")
                        self.console.print(f"[green]ğŸ“ ç›¸å¯¹è·¯å¾„: {relative_path}[/green]")
                    return relative_path
                except Exception as e:
                    if self.verbose:
                        self.console.print(f"[yellow]âš ï¸  å¤åˆ¶logoå¤±è´¥: {e}[/yellow]")
        
        if self.verbose:
            self.console.print(f"[yellow]âš ï¸  æœªæ‰¾åˆ°logoæ–‡ä»¶ (æŸ¥æ‰¾è·¯å¾„: {project_images_dir})[/yellow]")
        return None

    def _resize_and_copy_image(self, source_path: Path, dest_path: Path, max_height: int = 100) -> None:
        """
        è°ƒæ•´å›¾ç‰‡å¤§å°å¹¶å¤åˆ¶
        
        Args:
            source_path: æºå›¾ç‰‡è·¯å¾„
            dest_path: ç›®æ ‡å›¾ç‰‡è·¯å¾„
            max_height: æœ€å¤§é«˜åº¦ï¼ˆåƒç´ ï¼‰
        """
        try:
            from PIL import Image
            
            # æ‰“å¼€å›¾ç‰‡
            with Image.open(source_path) as img:
                # è·å–åŸå§‹å°ºå¯¸
                original_width, original_height = img.size
                
                # å¦‚æœé«˜åº¦è¶…è¿‡æœ€å¤§å€¼ï¼ŒæŒ‰æ¯”ä¾‹ç¼©æ”¾
                if original_height > max_height:
                    ratio = max_height / original_height
                    new_width = int(original_width * ratio)
                    new_height = max_height
                    
                    # è°ƒæ•´å¤§å°
                    resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                    resized_img.save(dest_path, optimize=True, quality=95)
                    
                    if self.verbose:
                        self.console.print(f"[green]ğŸ”§ å›¾ç‰‡å·²è°ƒæ•´å¤§å°: {original_width}x{original_height} -> {new_width}x{new_height}[/green]")
                else:
                    # ç›´æ¥å¤åˆ¶
                    img.save(dest_path, optimize=True, quality=95)
                    
        except ImportError:
            # å¦‚æœæ²¡æœ‰å®‰è£…PILï¼Œç›´æ¥å¤åˆ¶
            shutil.copy2(source_path, dest_path)
            if self.verbose:
                self.console.print(f"[yellow]âš ï¸  PILæœªå®‰è£…ï¼Œæ— æ³•è°ƒæ•´å›¾ç‰‡å¤§å°ï¼Œç›´æ¥å¤åˆ¶[/yellow]")
        except Exception as e:
            # å¦‚æœè°ƒæ•´å¤§å°å¤±è´¥ï¼Œç›´æ¥å¤åˆ¶
            shutil.copy2(source_path, dest_path)
            if self.verbose:
                self.console.print(f"[yellow]âš ï¸  å›¾ç‰‡è°ƒæ•´å¤±è´¥ï¼Œç›´æ¥å¤åˆ¶: {e}[/yellow]")

    def _copy_project_assets(self) -> None:
        """
        å¤åˆ¶é¡¹ç›®ä¸­çš„æ‰€æœ‰èµ„æºæ–‡ä»¶åˆ°docs/assetsç›®å½•
        åŒ…æ‹¬logoã€screenshotç­‰å›¾ç‰‡èµ„æº
        """
        # ç¡®ä¿docs/assets/imagesç›®å½•å­˜åœ¨
        docs_assets_images_dir = self.docs_dir / "assets" / "images"
        docs_assets_images_dir.mkdir(parents=True, exist_ok=True)
        
        # æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•çš„imagesæ–‡ä»¶å¤¹
        project_images_dir = self.project_dir / "images"
        
        if project_images_dir.exists():
            # å¤åˆ¶æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
            image_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.svg', '.webp']
            
            for image_file in project_images_dir.iterdir():
                if image_file.is_file() and image_file.suffix.lower() in image_extensions:
                    dest_file = docs_assets_images_dir / image_file.name
                    
                    try:
                        # å¯¹PNGå’ŒJPGæ–‡ä»¶è¿›è¡Œå¤§å°è°ƒæ•´
                        if image_file.suffix.lower() in ['.png', '.jpg', '.jpeg']:
                            # æ ¹æ®æ–‡ä»¶ååˆ¤æ–­æ˜¯å¦éœ€è¦ç‰¹æ®Šå¤„ç†
                            if 'logo' in image_file.name.lower():
                                self._resize_and_copy_image(image_file, dest_file, max_height=100)
                            elif 'screenshot' in image_file.name.lower():
                                self._resize_and_copy_image(image_file, dest_file, max_height=400)
                            else:
                                self._resize_and_copy_image(image_file, dest_file, max_height=300)
                        else:
                            # SVGç­‰çŸ¢é‡å›¾ç›´æ¥å¤åˆ¶
                            shutil.copy2(image_file, dest_file)
                        
                        if self.verbose:
                            self.console.print(f"[green]ğŸ“ å·²å¤åˆ¶èµ„æº: {image_file.name}[/green]")
                            
                    except Exception as e:
                        if self.verbose:
                            self.console.print(f"[yellow]âš ï¸  å¤åˆ¶èµ„æºå¤±è´¥ {image_file.name}: {e}[/yellow]")
        
        # æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•çš„å…¶ä»–å¸¸è§å›¾ç‰‡æ–‡ä»¶
        common_image_files = ['logo.png', 'logo.svg', 'screenshot.png', 'banner.png', 'icon.png']
        
        for image_name in common_image_files:
            image_file = self.project_dir / image_name
            if image_file.exists():
                dest_file = docs_assets_images_dir / image_name
                
                try:
                    if image_name.endswith('.png') or image_name.endswith('.jpg'):
                        if 'logo' in image_name:
                            self._resize_and_copy_image(image_file, dest_file, max_height=100)
                        elif 'screenshot' in image_name:
                            self._resize_and_copy_image(image_file, dest_file, max_height=400)
                        else:
                            self._resize_and_copy_image(image_file, dest_file, max_height=300)
                    else:
                        shutil.copy2(image_file, dest_file)
                    
                    if self.verbose:
                        self.console.print(f"[green]ğŸ“ å·²å¤åˆ¶æ ¹ç›®å½•èµ„æº: {image_name}[/green]")
                        
                except Exception as e:
                    if self.verbose:
                        self.console.print(f"[yellow]âš ï¸  å¤åˆ¶æ ¹ç›®å½•èµ„æºå¤±è´¥ {image_name}: {e}[/yellow]")

    def _write_mkdocs_config(self, config: Dict) -> None:
        """å†™å…¥MkDocsé…ç½®æ–‡ä»¶"""
        config_path = self.output_dir / "mkdocs.yml"
        
        if yaml is None:
            # å¦‚æœæ²¡æœ‰å®‰è£…PyYAMLï¼Œä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²æ ¼å¼
            yaml_content = self._dict_to_yaml_string(config)
            with open(config_path, 'w', encoding='utf-8') as f:
                f.write(yaml_content)
            return
            
        with open(config_path, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
        
    def _generate_page_content(self, page_type: str, analysis: Dict) -> str:
        """ä½¿ç”¨LLMç”Ÿæˆé¡µé¢å†…å®¹"""
        if self.debug:
            # Debugæ¨¡å¼ä¸‹è·³è¿‡å¤§æ¨¡å‹è°ƒç”¨ï¼Œè¿”å›ç®€å•çš„å ä½ç¬¦å†…å®¹
            self.console.print(f"[yellow]ç”Ÿæˆ {page_type} é¡µé¢ (debugæ¨¡å¼ - è·³è¿‡å¤§æ¨¡å‹è°ƒç”¨)...[/yellow]")
            return self._generate_debug_page_content(page_type, analysis)
        
        # æ£€æŸ¥model_clientæ˜¯å¦å¯ç”¨
        if self.model_client is None:
            self.console.print(f"[yellow]âš ï¸  æ¨¡å‹å®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œä½¿ç”¨debugæ¨¡å¼ç”Ÿæˆ {page_type} é¡µé¢[/yellow]")
            return self._generate_debug_page_content(page_type, analysis)
        
        # ç”ŸæˆåŸºç¡€prompt
        base_prompt = self._create_page_prompt(page_type, analysis)
        
        # å¦‚æœå¯ç”¨RAGï¼Œä½¿ç”¨RAGå¢å¼ºprompt
        if self.enable_rag and self.code_rag is not None and analysis.get('rag_enabled', False):
            # æ ¹æ®é¡µé¢ç±»å‹ç”ŸæˆæŸ¥è¯¢
            query = self._generate_rag_query(page_type, analysis)
            
            # ä½¿ç”¨RAGå¢å¼ºprompt
            enhanced_prompt = self.code_rag.generate_enhanced_prompt(
                base_prompt=base_prompt,
                query=query,
                max_context_blocks=8
            )
            
            if self.verbose:
                self.console.print(f"[green]ğŸ” ä½¿ç”¨RAGå¢å¼º {page_type} é¡µé¢prompt[/green]")
            
            prompt = enhanced_prompt
        else:
            prompt = base_prompt
        
        # åœ¨verboseæ¨¡å¼ä¸‹æ‰“å°prompt
        if self.verbose:
            self.console.print(f"\n[bold cyan]ğŸ“ ç”Ÿæˆ {page_type} é¡µé¢çš„Prompt:[/bold cyan]")
            self.console.print(Panel(prompt, title=f"{page_type.upper()} Prompt", border_style="cyan"))
            self.console.print("\n")
        
        content = self.model_client.generate_text(prompt)
        return self._format_markdown_content(content)
    
    def _generate_rag_query(self, page_type: str, analysis: Dict) -> str:
        """æ ¹æ®é¡µé¢ç±»å‹ç”ŸæˆRAGæŸ¥è¯¢"""
        project_name = analysis.get('git_info', {}).get('repo_name', Path(self.project_dir).name)
        
        queries = {
            'home': f"é¡¹ç›® {project_name} ä¸»è¦åŠŸèƒ½ æ ¸å¿ƒç‰¹æ€§ å…¥å£ç‚¹ ä¸»è¦ç±»å’Œå‡½æ•°",
            'installation': f"é¡¹ç›® {project_name} å®‰è£… ä¾èµ– é…ç½® setup åˆå§‹åŒ–",
            'usage': f"é¡¹ç›® {project_name} ä½¿ç”¨æ–¹æ³• API æ¥å£ ä¸»è¦å‡½æ•° ç¤ºä¾‹ä»£ç ",
            'examples': f"é¡¹ç›® {project_name} ç¤ºä¾‹ æ¼”ç¤º ç”¨æ³• ä»£ç ç‰‡æ®µ å®é™…åº”ç”¨",
            'architecture': f"é¡¹ç›® {project_name} æ¶æ„ è®¾è®¡ æ¨¡å—ç»“æ„ ç±»å…³ç³» ç»„ä»¶",
            'contributing': f"é¡¹ç›® {project_name} å¼€å‘ è´¡çŒ® æµ‹è¯• ä»£ç è§„èŒƒ å·¥å…·",
            'changelog': f"é¡¹ç›® {project_name} ç‰ˆæœ¬ æ›´æ–° å˜æ›´ æ–°åŠŸèƒ½ ä¿®å¤"
        }
        
        return queries.get(page_type, f"é¡¹ç›® {project_name} {page_type}")
        
    def _generate_debug_page_content(self, page_type: str, analysis: Dict) -> str:
        """åœ¨debugæ¨¡å¼ä¸‹ç”Ÿæˆç®€å•çš„å ä½ç¬¦é¡µé¢å†…å®¹"""
        project_name = self.project_dir.name
        
        debug_contents = {
            'installation': f"""# å®‰è£…æŒ‡å—

## ç³»ç»Ÿè¦æ±‚

- Python 3.7+
- pip

## å®‰è£…æ­¥éª¤

```bash
# å…‹éš†ä»“åº“
git clone <repository-url>
cd {project_name}

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

*æ³¨æ„ï¼šæ­¤é¡µé¢åœ¨debugæ¨¡å¼ä¸‹ç”Ÿæˆï¼Œæœªä½¿ç”¨AIç”Ÿæˆå†…å®¹ã€‚*
""",
            'usage': f"""# ä½¿ç”¨è¯´æ˜

## å¿«é€Ÿå¼€å§‹

```python
# å¯¼å…¥æ¨¡å—
from {project_name} import main

# è¿è¡Œç¤ºä¾‹
main()
```

## åŸºæœ¬ç”¨æ³•

è¯¦ç»†çš„ä½¿ç”¨è¯´æ˜è¯·å‚è€ƒé¡¹ç›®æ–‡æ¡£ã€‚

*æ³¨æ„ï¼šæ­¤é¡µé¢åœ¨debugæ¨¡å¼ä¸‹ç”Ÿæˆï¼Œæœªä½¿ç”¨AIç”Ÿæˆå†…å®¹ã€‚*
""",
            'examples': f"""# ç¤ºä¾‹

## åŸºæœ¬ç¤ºä¾‹

```python
# ç¤ºä¾‹ä»£ç 
print("Hello, {project_name}!")
```

## æ›´å¤šç¤ºä¾‹

æ›´å¤šç¤ºä¾‹è¯·æŸ¥çœ‹é¡¹ç›®çš„examplesç›®å½•ã€‚

*æ³¨æ„ï¼šæ­¤é¡µé¢åœ¨debugæ¨¡å¼ä¸‹ç”Ÿæˆï¼Œæœªä½¿ç”¨AIç”Ÿæˆå†…å®¹ã€‚*
""",
            'architecture': f"""# é¡¹ç›®æ¶æ„

## æ¦‚è¿°

{project_name} é¡¹ç›®çš„æ¶æ„è®¾è®¡ã€‚

## ä¸»è¦ç»„ä»¶

- æ ¸å¿ƒæ¨¡å—
- å·¥å…·æ¨¡å—
- é…ç½®æ¨¡å—

*æ³¨æ„ï¼šæ­¤é¡µé¢åœ¨debugæ¨¡å¼ä¸‹ç”Ÿæˆï¼Œæœªä½¿ç”¨AIç”Ÿæˆå†…å®¹ã€‚*
""",
            'contributing': f"""# è´¡çŒ®æŒ‡å—

## å¦‚ä½•è´¡çŒ®

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. åˆ›å»º Pull Request

## å¼€å‘ç¯å¢ƒ

è¯·ç¡®ä¿å®‰è£…äº†æ‰€æœ‰å¼€å‘ä¾èµ–ã€‚

*æ³¨æ„ï¼šæ­¤é¡µé¢åœ¨debugæ¨¡å¼ä¸‹ç”Ÿæˆï¼Œæœªä½¿ç”¨AIç”Ÿæˆå†…å®¹ã€‚*
""",
            'changelog': f"""# æ›´æ–°æ—¥å¿—

## [æœªå‘å¸ƒ]

### æ–°å¢
- æ–°åŠŸèƒ½å¼€å‘ä¸­

### ä¿®å¤
- Bugä¿®å¤

*æ³¨æ„ï¼šæ­¤é¡µé¢åœ¨debugæ¨¡å¼ä¸‹ç”Ÿæˆï¼Œæœªä½¿ç”¨AIç”Ÿæˆå†…å®¹ã€‚*
""",
            'home': f"""# {project_name}

æ¬¢è¿ä½¿ç”¨ {project_name}ï¼

## ç®€ä»‹

è¿™æ˜¯ä¸€ä¸ªPythoné¡¹ç›®ã€‚

## ç‰¹æ€§

- åŠŸèƒ½1
- åŠŸèƒ½2
- åŠŸèƒ½3

*æ³¨æ„ï¼šæ­¤é¡µé¢åœ¨debugæ¨¡å¼ä¸‹ç”Ÿæˆï¼Œæœªä½¿ç”¨AIç”Ÿæˆå†…å®¹ã€‚*
"""
        }
        
        return debug_contents.get(page_type, f"""# {page_type.title()}

æ­¤é¡µé¢å†…å®¹å¾…å®Œå–„ã€‚

*æ³¨æ„ï¼šæ­¤é¡µé¢åœ¨debugæ¨¡å¼ä¸‹ç”Ÿæˆï¼Œæœªä½¿ç”¨AIç”Ÿæˆå†…å®¹ã€‚*
""")
        
    def _format_markdown_content(self, content: str) -> str:
        """æ ¼å¼åŒ–markdownå†…å®¹ï¼Œé¿å…å‰ç«¯æ¸²æŸ“é”™è¯¯"""
        # ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
        lines = content.split('\n')
        formatted_lines = []
        prev_empty = False
        
        for line in lines:
            line = line.rstrip()  # ç§»é™¤è¡Œå°¾ç©ºæ ¼
            is_empty = len(line.strip()) == 0
            
            # é¿å…è¿ç»­çš„ç©ºè¡Œ
            if is_empty and prev_empty:
                continue
                
            formatted_lines.append(line)
            prev_empty = is_empty
            
        # ç¡®ä¿ä»£ç å—æ­£ç¡®é—­åˆ
        content = '\n'.join(formatted_lines)
        
        # ä¿®å¤ä»£ç å—
        content = self._fix_code_blocks(content)
        
        # ç¡®ä¿æ–‡æ¡£ä»¥æ¢è¡Œç¬¦ç»“å°¾
        if not content.endswith('\n'):
            content += '\n'
            
        return content
    
    def _generate_readme_as_homepage(self, analysis: Dict) -> str:
        """ä½¿ç”¨READMEç”Ÿæˆé€»è¾‘ç”Ÿæˆé¦–é¡µå†…å®¹"""
        try:
            self.console.print("[bold cyan]ğŸ“ æ­£åœ¨ç”ŸæˆREADMEå†…å®¹ä½œä¸ºé¦–é¡µ...[/bold cyan]")
            
            # åˆ›å»ºreadmexå®ä¾‹ï¼Œå¯ç”¨silentæ¨¡å¼é¿å…äº¤äº’å¼è¾“å…¥
            from readmex.core import readmex
            readme_generator = readmex(str(self.project_dir), silent=True, debug=self.debug)
            
            # è®¾ç½®åŸºæœ¬é…ç½®
            readme_generator.output_dir = str(self.project_dir / "temp_readme_output")
            os.makedirs(readme_generator.output_dir, exist_ok=True)
            
            # åŠ è½½é…ç½®
            readme_generator._load_configuration()
            
            # è·å–é¡¹ç›®ä¿¡æ¯
            readme_generator._get_git_info()
            readme_generator._get_user_info()
            readme_generator._get_project_meta_info()
            
            # åˆ†æé¡¹ç›®
            structure = readme_generator._get_project_structure()
            dependencies = readme_generator._get_project_dependencies()
            descriptions = readme_generator._get_script_descriptions()
            
            # è‡ªåŠ¨ç”Ÿæˆé¡¹ç›®æè¿°ç­‰ä¿¡æ¯
            if not readme_generator.config["project_description"]:
                readme_generator.config["project_description"] = readme_generator._generate_project_description(structure, dependencies, descriptions)
            
            if not readme_generator.config["entry_file"]:
                readme_generator.config["entry_file"] = readme_generator._generate_entry_file(structure, dependencies, descriptions)
            
            if not readme_generator.config["key_features"]:
                readme_generator.config["key_features"] = readme_generator._generate_key_features(structure, dependencies, descriptions)
            
            if not readme_generator.config["additional_info"]:
                readme_generator.config["additional_info"] = readme_generator._generate_additional_info(structure, dependencies, descriptions)
            
            # ç”ŸæˆREADMEå†…å®¹ï¼ˆä¼ é€’logoè·¯å¾„ä»¥ä¿ç•™logoï¼‰
            # æŸ¥æ‰¾é¡¹ç›®ä¸­çš„logoæ–‡ä»¶
            logo_path = None
            project_images_dir = self.project_dir / "images"
            for logo_file in ['logo.svg', 'logo.png']:
                logo_source = project_images_dir / logo_file
                if logo_source.exists():
                    logo_path = str(logo_source)
                    break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç°æœ‰logoä¸”édebugæ¨¡å¼ï¼Œç”Ÿæˆlogo
            if not logo_path and not self.debug:
                try:
                    from readmex.utils.logo_generator import generate_logo
                    # ç¡®ä¿imagesç›®å½•å­˜åœ¨
                    project_images_dir.mkdir(parents=True, exist_ok=True)
                    # ç”Ÿæˆlogoåˆ°é¡¹ç›®imagesç›®å½•
                    logo_path = generate_logo(str(self.project_dir), descriptions, self.model_client, self.console)
                    if self.verbose and logo_path:
                        self.console.print(f"[green]âœ… Logoå·²ç”Ÿæˆåˆ°: {logo_path}[/green]")
                except Exception as e:
                    if self.verbose:
                        self.console.print(f"[yellow]âš ï¸  Logoç”Ÿæˆå¤±è´¥: {e}[/yellow]")
            
            readme_content = readme_generator._generate_readme_content(structure, dependencies, descriptions, logo_path)
            
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            if os.path.exists(readme_generator.output_dir):
                shutil.rmtree(readme_generator.output_dir)
            
            self.console.print("[green]âœ… READMEå†…å®¹ç”Ÿæˆå®Œæˆ[/green]")
            
            # åœ¨verboseæ¨¡å¼ä¸‹æ˜¾ç¤ºç”Ÿæˆçš„READMEå†…å®¹
            if self.verbose:
                self.console.print(f"\n[bold cyan]ğŸ“ ç”Ÿæˆçš„READMEå†…å®¹ä½œä¸ºé¦–é¡µ:[/bold cyan]")
                self.console.print(Panel(readme_content[:500] + "..." if len(readme_content) > 500 else readme_content, 
                                        title="README Homepage Content", border_style="cyan"))
                self.console.print("\n")
            
            return readme_content
            
        except Exception as e:
            self.console.print(f"[red]ä½¿ç”¨READMEç”Ÿæˆé€»è¾‘å¤±è´¥ï¼Œå›é€€åˆ°åŸå§‹æ–¹æ³•: {e}[/red]")
            # å›é€€åˆ°åŸå§‹çš„é¡µé¢ç”Ÿæˆæ–¹æ³•
            return self._generate_page_content('home', analysis)
        
    def _fix_code_blocks(self, content: str) -> str:
        """ä¿®å¤ä»£ç å—æ ¼å¼"""
        lines = content.split('\n')
        fixed_lines = []
        in_code_block = False
        code_block_lang = ''
        
        for line in lines:
            # æ£€æµ‹ä»£ç å—å¼€å§‹
            if line.strip().startswith('```'):
                if not in_code_block:
                    in_code_block = True
                    code_block_lang = line.strip()[3:].strip()
                    fixed_lines.append(f'```{code_block_lang}')
                else:
                    in_code_block = False
                    fixed_lines.append('```')
            else:
                fixed_lines.append(line)
                
        # å¦‚æœä»£ç å—æ²¡æœ‰æ­£ç¡®é—­åˆï¼Œæ·»åŠ é—­åˆæ ‡è®°
        if in_code_block:
            fixed_lines.append('```')
            
        return '\n'.join(fixed_lines)
    
    def _write_page(self, filename: str, content: str) -> None:
        """å†™å…¥é¡µé¢æ–‡ä»¶"""
        file_path = self.docs_dir / filename
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
            
    # è¾…åŠ©æ–¹æ³•
    def _get_dependencies(self) -> Dict:
        """è·å–é¡¹ç›®ä¾èµ–"""
        dependencies = {'python': [], 'npm': [], 'other': []}
        
        # æ£€æŸ¥Pythonä¾èµ–
        python_deps = set()  # ä½¿ç”¨seté¿å…é‡å¤
        
        # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥ä¾èµ–æ–‡ä»¶
        dep_files = [
            ('pyproject.toml', 'pyproject'),
            ('requirements.txt', 'requirements'),
            ('setup.py', 'setup'),
            ('Pipfile', 'pipfile'),
            ('setup.cfg', 'setup_cfg'),
            ('environment.yml', 'conda'),
            ('poetry.lock', 'poetry')
        ]
        
        for filename, file_type in dep_files:
            file_path = self.project_dir / filename
            if file_path.exists():
                try:
                    parsed_deps = self._parse_python_deps(file_path)
                    if parsed_deps:
                        python_deps.update(parsed_deps)
                        if self.verbose:
                            self.console.print(f"[green]Found {len(parsed_deps)} dependencies in {filename}[/green]")
                except Exception as e:
                    if self.verbose:
                        self.console.print(f"[yellow]Warning: Could not parse {filename}: {e}[/yellow]")
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¾èµ–æ–‡ä»¶ï¼Œå°è¯•ä»ä»£ç ä¸­æ¨æ–­
        if not python_deps:
            inferred_deps = self._infer_dependencies_from_code()
            python_deps.update(inferred_deps)
            if inferred_deps and self.verbose:
                self.console.print(f"[blue]Inferred {len(inferred_deps)} dependencies from code analysis[/blue]")
        
        dependencies['python'] = sorted(list(python_deps))
                
        # æ£€æŸ¥Node.jsä¾èµ–
        for js_file in ['package.json', 'package-lock.json', 'yarn.lock']:
            js_path = self.project_dir / js_file
            if js_path.exists():
                try:
                    npm_deps = self._parse_npm_deps(js_path)
                    dependencies['npm'].extend(npm_deps)
                    if npm_deps and self.verbose:
                        self.console.print(f"[green]Found {len(npm_deps)} npm dependencies in {js_file}[/green]")
                    break  # åªè§£æç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„æ–‡ä»¶
                except Exception as e:
                    if self.verbose:
                        self.console.print(f"[yellow]Warning: Could not parse {js_file}: {e}[/yellow]")
        
        # æ£€æŸ¥å…¶ä»–ç±»å‹çš„ä¾èµ–
        other_deps = self._detect_other_dependencies()
        dependencies['other'] = other_deps
        
        return dependencies
        
    def _extract_functions(self) -> List[Dict]:
        """æå–é¡¹ç›®ä¸­çš„å‡½æ•°"""
        functions = []
        python_files = list(self.project_dir.rglob('*.py'))
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                tree = ast.parse(content)
                file_functions = self._extract_functions_from_ast(tree, file_path, content)
                functions.extend(file_functions)
                
            except Exception as e:
                self.console.print(f"[yellow]Warning: Could not parse {file_path}: {e}[/yellow]")
                
        return functions
        
    def _extract_classes(self) -> List[Dict]:
        """æå–é¡¹ç›®ä¸­çš„ç±»"""
        classes = []
        python_files = list(self.project_dir.rglob('*.py'))
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                tree = ast.parse(content)
                file_classes = self._extract_classes_from_ast(tree, file_path, content)
                classes.extend(file_classes)
                
            except Exception as e:
                self.console.print(f"[yellow]Warning: Could not parse {file_path}: {e}[/yellow]")
                
        return classes
        
    def _get_modules(self) -> List[str]:
        """è·å–é¡¹ç›®æ¨¡å—åˆ—è¡¨"""
        modules = []
        python_files = list(self.project_dir.rglob('*.py'))
        
        for file_path in python_files:
            relative_path = file_path.relative_to(self.project_dir)
            module_path = str(relative_path).replace('/', '.').replace('\\', '.').replace('.py', '')
            if not module_path.startswith('.'):
                modules.append(module_path)
                
        return sorted(modules)
        
    def _find_entry_points(self) -> List[str]:
        """æŸ¥æ‰¾é¡¹ç›®å…¥å£ç‚¹"""
        entry_points = []
        
        # æ£€æŸ¥pyproject.tomlä¸­çš„è„šæœ¬
        pyproject_path = self.project_dir / 'pyproject.toml'
        if pyproject_path.exists():
            entry_points.extend(self._parse_pyproject_scripts(pyproject_path))
            
        # æ£€æŸ¥setup.pyä¸­çš„å…¥å£ç‚¹
        setup_path = self.project_dir / 'setup.py'
        if setup_path.exists():
            entry_points.extend(self._parse_setup_scripts(setup_path))
            
        # æ£€æŸ¥å¸¸è§çš„ä¸»æ–‡ä»¶
        main_files = ['main.py', 'app.py', '__main__.py', 'cli.py']
        for main_file in main_files:
            main_path = self.project_dir / main_file
            if main_path.exists():
                entry_points.append(main_file)
                
        return entry_points
        
    def _get_git_info(self) -> Dict:
        """è·å–Gitä¿¡æ¯"""
        git_info = {}
        
        try:
            import subprocess
            
            # è·å–è¿œç¨‹ä»“åº“URL
            result = subprocess.run(
                ['git', 'remote', 'get-url', 'origin'],
                cwd=self.project_dir,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                git_info['remote_url'] = result.stdout.strip()
                
                # è§£æGitHubä¿¡æ¯
                github_match = re.search(
                    r'github\.com[:/]([^/]+)/([^/\.]+)(?:\.git)?/?$',
                    git_info['remote_url']
                )
                
                if github_match:
                    git_info['github_username'] = github_match.group(1)
                    git_info['repo_name'] = github_match.group(2)
                    
        except Exception as e:
            self.console.print(f"[yellow]Warning: Could not get git info: {e}[/yellow]")
            
        return git_info
    
    def _get_git_commit_history(self, limit: int = 20) -> List[Dict]:
        """è·å–å¢å¼ºçš„Gitæäº¤å†å²ï¼ŒåŒ…å«æ–‡ä»¶å˜æ›´ç»Ÿè®¡"""
        commits = []
        
        try:
            import subprocess
            
            # è·å–æœ€è¿‘çš„æäº¤å†å²ï¼ŒåŒ…å«æ–‡ä»¶å˜æ›´ç»Ÿè®¡
            result = subprocess.run(
                ['git', 'log', f'--max-count={limit}', '--pretty=format:%H|%an|%ae|%ad|%s', '--date=short', '--stat', '--oneline'],
                cwd=self.project_dir,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                lines = result.stdout.strip().split('\n')
                i = 0
                while i < len(lines):
                    line = lines[i]
                    if '|' in line and len(line.split('|')) >= 5:
                        parts = line.split('|', 4)
                        if len(parts) == 5:
                            commit_hash = parts[0][:8]
                            
                            # è·å–è¯¥æäº¤çš„è¯¦ç»†æ–‡ä»¶å˜æ›´ä¿¡æ¯
                            stat_result = subprocess.run(
                                ['git', 'show', '--stat', '--format=', parts[0]],
                                cwd=self.project_dir,
                                capture_output=True,
                                text=True
                            )
                            
                            files_changed = []
                            insertions = 0
                            deletions = 0
                            
                            if stat_result.returncode == 0:
                                stat_lines = stat_result.stdout.strip().split('\n')
                                for stat_line in stat_lines:
                                    if '|' in stat_line and ('+' in stat_line or '-' in stat_line):
                                        file_info = stat_line.split('|')
                                        if len(file_info) >= 2:
                                            filename = file_info[0].strip()
                                            changes = file_info[1].strip()
                                            files_changed.append({
                                                'file': filename,
                                                'changes': changes
                                            })
                                    elif 'insertion' in stat_line or 'deletion' in stat_line:
                                        # è§£ææ’å…¥å’Œåˆ é™¤è¡Œæ•°
                                        import re
                                        ins_match = re.search(r'(\d+) insertion', stat_line)
                                        del_match = re.search(r'(\d+) deletion', stat_line)
                                        if ins_match:
                                            insertions = int(ins_match.group(1))
                                        if del_match:
                                            deletions = int(del_match.group(1))
                            
                            # åˆ†ææäº¤ç±»å‹ï¼ˆåŸºäº Conventional Commitsï¼‰
                            commit_type = self._analyze_commit_type(parts[4])
                            
                            commits.append({
                                'hash': commit_hash,
                                'author': parts[1],
                                'email': parts[2],
                                'date': parts[3],
                                'message': parts[4],
                                'files_changed': files_changed,
                                'insertions': insertions,
                                'deletions': deletions,
                                'type': commit_type,
                                'is_breaking': self._is_breaking_change(parts[4])
                            })
                    i += 1
                            
        except Exception as e:
            self.console.print(f"[yellow]Warning: Could not get git commit history: {e}[/yellow]")
            
        return commits
    
    def _get_git_contributors(self) -> List[Dict]:
        """è·å–Gitè´¡çŒ®è€…ä¿¡æ¯"""
        contributors = []
        
        try:
            import subprocess
            
            # è·å–è´¡çŒ®è€…ç»Ÿè®¡
            result = subprocess.run(
                ['git', 'shortlog', '-sn', '--all'],
                cwd=self.project_dir,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                for line in result.stdout.strip().split('\n'):
                    if line:
                        parts = line.strip().split('\t', 1)
                        if len(parts) == 2:
                            commit_count = int(parts[0])
                            author_name = parts[1]
                            
                            # è·å–ä½œè€…é‚®ç®±
                            email_result = subprocess.run(
                                ['git', 'log', '--author', author_name, '--pretty=format:%ae', '-1'],
                                cwd=self.project_dir,
                                capture_output=True,
                                text=True
                            )
                            
                            email = email_result.stdout.strip() if email_result.returncode == 0 else ''
                            
                            contributors.append({
                                'name': author_name,
                                'email': email,
                                'commits': commit_count,
                                'avatar_url': f'https://github.com/{author_name}.png' if email else ''
                            })
                            
        except Exception as e:
            self.console.print(f"[yellow]Warning: Could not get git contributors: {e}[/yellow]")
            
        return contributors
    
    def _analyze_commit_statistics(self, commits: List[Dict]) -> Dict[str, int]:
        """åˆ†ææäº¤ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        for commit in commits:
            commit_type = commit.get('type', 'other')
            stats[commit_type] = stats.get(commit_type, 0) + 1
        
        return stats
    
    def _analyze_commit_type(self, message: str) -> str:
        """åˆ†ææäº¤ç±»å‹ï¼ˆåŸºäº Conventional Commits è§„èŒƒï¼‰"""
        message_lower = message.lower()
        
        # Conventional Commits ç±»å‹æ˜ å°„
        type_patterns = {
            'feat': ['feat:', 'feature:', 'add:', 'new:'],
            'fix': ['fix:', 'bug:', 'hotfix:', 'patch:'],
            'docs': ['docs:', 'doc:', 'documentation:'],
            'style': ['style:', 'format:', 'lint:'],
            'refactor': ['refactor:', 'refact:', 'restructure:'],
            'test': ['test:', 'tests:', 'testing:'],
            'chore': ['chore:', 'build:', 'ci:', 'deps:'],
            'perf': ['perf:', 'performance:', 'optimize:'],
            'revert': ['revert:', 'rollback:']
        }
        
        for commit_type, patterns in type_patterns.items():
            for pattern in patterns:
                if message_lower.startswith(pattern):
                    return commit_type
        
        # åŸºäºå…³é”®è¯çš„å¯å‘å¼åˆ†æ
        if any(word in message_lower for word in ['add', 'new', 'create', 'implement']):
            return 'feat'
        elif any(word in message_lower for word in ['fix', 'bug', 'error', 'issue']):
            return 'fix'
        elif any(word in message_lower for word in ['update', 'change', 'modify']):
            return 'refactor'
        elif any(word in message_lower for word in ['remove', 'delete', 'clean']):
            return 'chore'
        
        return 'other'
    
    def _is_breaking_change(self, message: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºç ´åæ€§å˜æ›´"""
        breaking_indicators = [
            'BREAKING CHANGE',
            'breaking change',
            'breaking:',
            '!:',  # Conventional Commits çš„ç ´åæ€§å˜æ›´æ ‡è®°
            'major:',
            'incompatible'
        ]
        
        return any(indicator in message for indicator in breaking_indicators)
    
    def _get_git_tags(self) -> List[Dict]:
        """è·å–Gitæ ‡ç­¾ä¿¡æ¯"""
        tags = []
        
        try:
            import subprocess
            
            # è·å–æ ‡ç­¾åˆ—è¡¨ï¼ŒæŒ‰æ—¥æœŸæ’åº
            result = subprocess.run(
                ['git', 'tag', '-l', '--sort=-creatordate', '--format=%(refname:short)|%(creatordate:short)|%(subject)'],
                cwd=self.project_dir,
                capture_output=True,
                text=True
            )
            
            if result.returncode == 0:
                for line in result.stdout.strip().split('\n'):
                    if line:
                        parts = line.split('|', 2)
                        if len(parts) >= 2:
                            tags.append({
                                'name': parts[0],
                                'date': parts[1],
                                'message': parts[2] if len(parts) > 2 else ''
                            })
                            
        except Exception as e:
            if self.verbose:
                self.console.print(f"[yellow]Warning: Could not get git tags: {e}[/yellow]")
            
        return tags
    
    def _validate_drawio_content(self, content: str) -> bool:
        """
        éªŒè¯drawioå†…å®¹æ˜¯å¦å®Œæ•´
        
        Args:
            content: drawio XMLå†…å®¹
            
        Returns:
            bool: æ˜¯å¦å®Œæ•´æœ‰æ•ˆ
        """
        if not content or not content.strip():
            return False
            
        # æ£€æŸ¥åŸºæœ¬çš„XMLç»“æ„
        required_tags = ['<mxfile', '</mxfile>', '<diagram', '</diagram>', '<mxGraphModel', '</mxGraphModel>']
        for tag in required_tags:
            if tag not in content:
                return False
                
        # æ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­ï¼ˆé€šå¸¸æˆªæ–­çš„æ–‡ä»¶ä¼šç¼ºå°‘ç»“æŸæ ‡ç­¾ï¼‰
        if not content.strip().endswith('</mxfile>'):
            return False
            
        # æ£€æŸ¥å†…å®¹é•¿åº¦ï¼ˆå¤ªçŸ­å¯èƒ½ä¸å®Œæ•´ï¼‰
        if len(content.strip()) < 500:
            return False
            
        # å°è¯•åŸºæœ¬çš„XMLè§£æéªŒè¯
        try:
            import xml.etree.ElementTree as ET
            ET.fromstring(content)
            return True
        except ET.ParseError:
            return False
        except Exception:
            # å¦‚æœæ²¡æœ‰xmlæ¨¡å—æˆ–å…¶ä»–é”™è¯¯ï¼Œä½¿ç”¨åŸºæœ¬éªŒè¯
            return True
    
    def _generate_drawio_diagram(self, analysis: Dict) -> str:
        """
        ç”Ÿæˆæ¶æ„å›¾çš„ drawio ä»£ç ï¼ˆå¸¦é‡è¯•é€»è¾‘ï¼‰
        
        Args:
            analysis: é¡¹ç›®åˆ†æç»“æœ
            
        Returns:
            str: drawio XML ä»£ç 
        """
        git_info = analysis.get('git_info', {})
        project_name = git_info.get('repo_name', Path(self.project_dir).name)
        modules = analysis.get('modules', [])
        functions = analysis.get('functions', [])
        classes = analysis.get('classes', [])
        dependencies = analysis.get('dependencies', {})
        
        # å‡†å¤‡è„šæœ¬ç®€ä»‹ä¿¡æ¯
        script_descriptions_file = self.project_dir / "script_descriptions.json"
        script_descriptions = {}
        if script_descriptions_file.exists():
            try:
                with open(script_descriptions_file, 'r', encoding='utf-8') as f:
                    script_descriptions = json.load(f)
            except Exception as e:
                if self.verbose:
                    self.console.print(f"[yellow]Warning: æ— æ³•è¯»å–è„šæœ¬æè¿°æ–‡ä»¶: {e}[/yellow]")
        
        # æ„å»ºæ¶æ„å›¾ç”Ÿæˆçš„æç¤ºè¯
        architecture_info = f"""
é¡¹ç›®æ¶æ„ä¿¡æ¯ï¼š
- é¡¹ç›®åç§°: {project_name}
- æ¨¡å—æ•°é‡: {len(modules)}
- å‡½æ•°æ•°é‡: {len(functions)}
- ç±»æ•°é‡: {len(classes)}
- ä¸»è¦ä¾èµ–: {list(dependencies.keys())[:10]}

æ¨¡å—åˆ—è¡¨:
{chr(10).join([f"- {module}" for module in modules[:15]])}

ä¸»è¦ç±»:
{chr(10).join([f"- {cls}" for cls in classes[:10]])}

è„šæœ¬æè¿°:
{json.dumps(script_descriptions, ensure_ascii=False, indent=2)[:1000]}...
"""
        
        prompt = f"""
è¯·åŸºäºä»¥ä¸‹é¡¹ç›®ä¿¡æ¯ç”Ÿæˆä¸€ä¸ªæ¶æ„å›¾çš„ draw.io XML ä»£ç ã€‚

{architecture_info}

è¦æ±‚ï¼š
1. ç”Ÿæˆå®Œæ•´çš„ draw.io XML æ ¼å¼ä»£ç 
2. åŒ…å«é¡¹ç›®çš„ä¸»è¦æ¨¡å—å’Œç»„ä»¶
3. æ˜¾ç¤ºæ¨¡å—ä¹‹é—´çš„ä¾èµ–å…³ç³»
4. ä½¿ç”¨æ¸…æ™°çš„å¸ƒå±€å’Œé¢œè‰²åŒºåˆ†ä¸åŒç±»å‹çš„ç»„ä»¶
5. åŒ…å«æ•°æ®æµå‘å’Œäº¤äº’å…³ç³»
6. é€‚åˆåœ¨ MkDocs ä¸­ä½¿ç”¨ drawio æ’ä»¶æ˜¾ç¤º
7. ç¡®ä¿XMLæ ¼å¼å®Œæ•´ï¼ŒåŒ…å«æ‰€æœ‰å¿…è¦çš„å¼€å§‹å’Œç»“æŸæ ‡ç­¾

è¯·ç›´æ¥è¿”å›å®Œæ•´çš„ draw.io XML ä»£ç ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šæ–‡å­—ã€‚
"""
        
        # é‡è¯•é€»è¾‘
        max_retries = 3
        for attempt in range(max_retries):
            try:
                if self.verbose:
                    if attempt == 0:
                        self.console.print("[blue]æ­£åœ¨ç”Ÿæˆæ¶æ„å›¾...[/blue]")
                    else:
                        self.console.print(f"[yellow]æ¶æ„å›¾ç”Ÿæˆé‡è¯• {attempt}/{max_retries-1}...[/yellow]")
                
                drawio_code = self.model_client.get_answer(prompt)
                
                # éªŒè¯ç”Ÿæˆçš„å†…å®¹æ˜¯å¦å®Œæ•´
                if self._validate_drawio_content(drawio_code):
                    if self.verbose and attempt > 0:
                        self.console.print(f"[green]æ¶æ„å›¾ç”ŸæˆæˆåŠŸï¼ˆé‡è¯• {attempt} æ¬¡åï¼‰[/green]")
                    return drawio_code
                else:
                    if self.verbose:
                        self.console.print(f"[yellow]ç”Ÿæˆçš„æ¶æ„å›¾ä¸å®Œæ•´æˆ–è¢«æˆªæ–­ï¼Œå‡†å¤‡é‡è¯•...[/yellow]")
                    
                    # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œè®°å½•è¯¦ç»†ä¿¡æ¯
                    if attempt == max_retries - 1:
                        if self.verbose:
                            self.console.print(f"[red]æ¶æ„å›¾éªŒè¯å¤±è´¥è¯¦æƒ…ï¼š[/red]")
                            self.console.print(f"[red]- å†…å®¹é•¿åº¦: {len(drawio_code) if drawio_code else 0}[/red]")
                            self.console.print(f"[red]- å†…å®¹é¢„è§ˆ: {drawio_code[:200] if drawio_code else 'None'}...[/red]")
                    continue
                    
            except Exception as e:
                if self.verbose:
                    self.console.print(f"[red]ç”Ÿæˆæ¶æ„å›¾å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}[/red]")
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œè¿”å›é»˜è®¤æ¶æ„å›¾
                if attempt == max_retries - 1:
                    if self.verbose:
                        self.console.print(f"[yellow]æ‰€æœ‰é‡è¯•å‡å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¶æ„å›¾[/yellow]")
                    return self._get_default_drawio_diagram(project_name)
        
        # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤æ¶æ„å›¾
        if self.verbose:
            self.console.print(f"[yellow]æ¶æ„å›¾ç”ŸæˆéªŒè¯å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¶æ„å›¾[/yellow]")
        return self._get_default_drawio_diagram(project_name)
    
    def _get_default_drawio_diagram(self, project_name: str) -> str:
        """
        è·å–é»˜è®¤çš„ drawio æ¶æ„å›¾
        
        Args:
            project_name: é¡¹ç›®åç§°
            
        Returns:
            str: é»˜è®¤çš„ drawio XML ä»£ç 
        """
        return f'''<mxfile host="app.diagrams.net" modified="2024-01-01T00:00:00.000Z" agent="5.0" version="22.1.16">
  <diagram name="Architecture" id="architecture">
    <mxGraphModel dx="1422" dy="794" grid="1" gridSize="10" guides="1" tooltips="1" connect="1" arrows="1" fold="1" page="1" pageScale="1" pageWidth="827" pageHeight="1169" math="0" shadow="0">
      <root>
        <mxCell id="0" />
        <mxCell id="1" parent="0" />
        <mxCell id="2" value="{project_name}" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#dae8fc;strokeColor=#6c8ebf;fontSize=16;fontStyle=1" vertex="1" parent="1">
          <mxGeometry x="300" y="100" width="200" height="60" as="geometry" />
        </mxCell>
        <mxCell id="3" value="Core Module" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#d5e8d4;strokeColor=#82b366" vertex="1" parent="1">
          <mxGeometry x="150" y="250" width="120" height="60" as="geometry" />
        </mxCell>
        <mxCell id="4" value="API Module" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#d5e8d4;strokeColor=#82b366" vertex="1" parent="1">
          <mxGeometry x="350" y="250" width="120" height="60" as="geometry" />
        </mxCell>
        <mxCell id="5" value="Utils Module" style="rounded=1;whiteSpace=wrap;html=1;fillColor=#d5e8d4;strokeColor=#82b366" vertex="1" parent="1">
          <mxGeometry x="550" y="250" width="120" height="60" as="geometry" />
        </mxCell>
        <mxCell id="6" value="" style="endArrow=classic;html=1;rounded=0;exitX=0.25;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0" edge="1" parent="1" source="2" target="3">
          <mxGeometry width="50" height="50" relative="1" as="geometry">
            <mxPoint x="390" y="300" as="sourcePoint" />
            <mxPoint x="440" y="250" as="targetPoint" />
          </mxGeometry>
        </mxCell>
        <mxCell id="7" value="" style="endArrow=classic;html=1;rounded=0;exitX=0.5;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0" edge="1" parent="1" source="2" target="4">
          <mxGeometry width="50" height="50" relative="1" as="geometry">
            <mxPoint x="390" y="300" as="sourcePoint" />
            <mxPoint x="440" y="250" as="targetPoint" />
          </mxGeometry>
        </mxCell>
        <mxCell id="8" value="" style="endArrow=classic;html=1;rounded=0;exitX=0.75;exitY=1;exitDx=0;exitDy=0;entryX=0.5;entryY=0;entryDx=0;entryDy=0" edge="1" parent="1" source="2" target="5">
          <mxGeometry width="50" height="50" relative="1" as="geometry">
            <mxPoint x="390" y="300" as="sourcePoint" />
            <mxPoint x="440" y="250" as="targetPoint" />
          </mxGeometry>
        </mxCell>
      </root>
    </mxGraphModel>
  </diagram>
</mxfile>'''
        
    def _convert_git_url_to_https(self, git_url: str) -> str:
        """å°†git@æ ¼å¼çš„URLè½¬æ¢ä¸ºhttpsæ ¼å¼"""
        if not git_url:
            return ''
            
        # å¦‚æœå·²ç»æ˜¯httpsæ ¼å¼ï¼Œç›´æ¥è¿”å›ï¼ˆå»æ‰.gitåç¼€ï¼‰
        if git_url.startswith('https://'):
            return git_url.rstrip('.git')
            
        # è½¬æ¢git@æ ¼å¼åˆ°httpsæ ¼å¼
        if git_url.startswith('git@'):
            # git@github.com:user/repo.git -> https://github.com/user/repo
            import re
            match = re.match(r'git@([^:]+):(.+?)(?:\.git)?/?$', git_url)
            if match:
                host, path = match.groups()
                return f'https://{host}/{path}'
                
        # å¦‚æœæ˜¯å…¶ä»–æ ¼å¼ï¼Œå°è¯•ç›´æ¥è¿”å›
        return git_url.rstrip('.git')
        
    def _generate_api_index(self, apis: List[Dict]) -> str:
        """ç”ŸæˆAPIç´¢å¼•é¡µé¢"""
        content = "# API æ–‡æ¡£\n\n"
        content += "æœ¬é¡µé¢åŒ…å«é¡¹ç›®çš„ä¸»è¦APIæ–‡æ¡£ã€‚\n\n"
        
        # æŒ‰æ¨¡å—åˆ†ç»„
        modules = {}
        for api in apis:
            module = api['module']
            if module not in modules:
                modules[module] = []
            modules[module].append(api)
            
        # ç”Ÿæˆç´¢å¼•
        for module, module_apis in sorted(modules.items()):
            content += f"## {module}\n\n"
            
            for api in module_apis:
                api_type = api['type']
                api_name = api['name']
                link = f"[{api_name}]({module}/{api_name}.md)"
                
                if api_type == 'class':
                    content += f"- ğŸ›ï¸ {link} - ç±»\n"
                else:
                    content += f"- ğŸ”§ {link} - å‡½æ•°\n"
                    
            content += "\n"
            
        return content
        
    def _create_page_prompt(self, page_type: str, analysis: Dict) -> str:
        """åˆ›å»ºé¡µé¢ç”Ÿæˆçš„æç¤ºè¯ - è·¯ç”±åˆ°å…·ä½“çš„é¡µé¢promptæ–¹æ³•"""
        prompt_methods = {
            'home': self._create_home_prompt,
            'installation': self._create_installation_prompt,
            'usage': self._create_usage_prompt,
            'examples': self._create_examples_prompt,
            'architecture': self._create_architecture_prompt,
            'contributing': self._create_contributing_prompt,
            'changelog': self._create_changelog_prompt
        }
        
        method = prompt_methods.get(page_type)
        if method:
            return method(analysis)
        else:
            return "è¯·ç”Ÿæˆç›¸å…³æ–‡æ¡£ã€‚"
    
    def _create_home_prompt(self, analysis: Dict) -> str:
        """
        åˆ›å»ºé¦–é¡µæ–‡æ¡£ç”Ÿæˆçš„æç¤ºè¯
        
        æ‰€éœ€è¾“å…¥ä¿¡æ¯ï¼š
        - analysis['git_info']['repo_name']: é¡¹ç›®åç§°
        - analysis['git_info']: Gitä»“åº“ä¿¡æ¯
        - analysis['modules']: æ¨¡å—åˆ—è¡¨
        - analysis['functions']: å‡½æ•°åˆ—è¡¨
        - analysis['classes']: ç±»åˆ—è¡¨
        - analysis['dependencies']: ä¾èµ–ä¿¡æ¯
        - analysis['entry_points']: å…¥å£ç‚¹ä¿¡æ¯
        - self.project_dir: é¡¹ç›®è·¯å¾„
        """
        git_info = analysis.get('git_info', {})
        project_name = git_info.get('repo_name', Path(self.project_dir).name)
        
        # è·å–è´¡çŒ®è€…ä¿¡æ¯
        contributors = self._get_git_contributors()[:5]  # é™åˆ¶ä¸ºå‰5ä¸ªè´¡çŒ®è€…
        contributors_info = "\né¡¹ç›®è´¡çŒ®è€…ï¼š\n"
        for contributor in contributors:
            contributors_info += f"- {contributor['name']} ({contributor['commits']} commits)"
            if contributor['email']:
                contributors_info += f" - {contributor['email']}"
            contributors_info += "\n"
        
        project_info = f"""
é¡¹ç›®ä¿¡æ¯ï¼š
- é¡¹ç›®åç§°: {project_name}
- é¡¹ç›®è·¯å¾„: {self.project_dir}
- æ¨¡å—æ•°é‡: {len(analysis.get('modules', []))}
- å‡½æ•°æ•°é‡: {len(analysis.get('functions', []))}
- ç±»æ•°é‡: {len(analysis.get('classes', []))}
- Gitä¿¡æ¯: {git_info}
- ä¾èµ–ä¿¡æ¯: {analysis.get('dependencies', {})}
- å…¥å£ç‚¹: {analysis.get('entry_points', [])}

{contributors_info}
"""
        
        return f"""
è¯·ä¸ºè¿™ä¸ªé¡¹ç›®ç”Ÿæˆä¸€ä¸ªä¸“ä¸šçš„é¦–é¡µæ–‡æ¡£ï¼ŒåŒ…æ‹¬ï¼š
1. é¡¹ç›®ç®€ä»‹å’Œä¸»è¦åŠŸèƒ½
2. å¿«é€Ÿå¼€å§‹æŒ‡å—
3. ä¸»è¦ç‰¹æ€§åˆ—è¡¨
4. é¡¹ç›®ç»“æ„æ¦‚è§ˆ
5. ç›¸å…³é“¾æ¥

{project_info}

è¯·ä½¿ç”¨Markdownæ ¼å¼ï¼Œé£æ ¼è¦ä¸“ä¸šä¸”æ˜“è¯»ã€‚
"""
    
    def _create_installation_prompt(self, analysis: Dict) -> str:
        """
        åˆ›å»ºå®‰è£…æŒ‡å—æ–‡æ¡£ç”Ÿæˆçš„æç¤ºè¯
        
        æ‰€éœ€è¾“å…¥ä¿¡æ¯ï¼š
        - analysis['git_info']['repo_name']: é¡¹ç›®åç§°
        - analysis['git_info']: Gitä»“åº“ä¿¡æ¯
        - analysis['dependencies']: ä¾èµ–ä¿¡æ¯ï¼ˆé‡ç‚¹ä½¿ç”¨ï¼‰
        - analysis['modules']: æ¨¡å—åˆ—è¡¨
        - analysis['functions']: å‡½æ•°åˆ—è¡¨
        - analysis['classes']: ç±»åˆ—è¡¨
        - analysis['entry_points']: å…¥å£ç‚¹ä¿¡æ¯
        - self.project_dir: é¡¹ç›®è·¯å¾„
        """
        git_info = analysis.get('git_info', {})
        project_name = git_info.get('repo_name', Path(self.project_dir).name)
        dependencies = analysis.get('dependencies', {})
        
        project_info = f"""
é¡¹ç›®ä¿¡æ¯ï¼š
- é¡¹ç›®åç§°: {project_name}
- é¡¹ç›®è·¯å¾„: {self.project_dir}
- æ¨¡å—æ•°é‡: {len(analysis.get('modules', []))}
- å‡½æ•°æ•°é‡: {len(analysis.get('functions', []))}
- ç±»æ•°é‡: {len(analysis.get('classes', []))}
- Gitä¿¡æ¯: {git_info}
- ä¾èµ–ä¿¡æ¯: {dependencies}
- å…¥å£ç‚¹: {analysis.get('entry_points', [])}
"""
        
        return f"""
è¯·ä¸ºè¿™ä¸ªé¡¹ç›®ç”Ÿæˆè¯¦ç»†çš„å®‰è£…æŒ‡å—ï¼ŒåŒ…æ‹¬ï¼š
1. ç³»ç»Ÿè¦æ±‚
2. ä¾èµ–å®‰è£…
3. ä¸åŒå¹³å°çš„å®‰è£…æ­¥éª¤
4. éªŒè¯å®‰è£…
5. å¸¸è§å®‰è£…é—®é¢˜

{project_info}

è¯·ä½¿ç”¨Markdownæ ¼å¼ã€‚
"""
    
    def _create_usage_prompt(self, analysis: Dict) -> str:
        """
        åˆ›å»ºä½¿ç”¨è¯´æ˜æ–‡æ¡£ç”Ÿæˆçš„æç¤ºè¯
        
        æ‰€éœ€è¾“å…¥ä¿¡æ¯ï¼š
        - analysis['git_info']['repo_name']: é¡¹ç›®åç§°
        - analysis['git_info']: Gitä»“åº“ä¿¡æ¯
        - analysis['functions']: å‡½æ•°åˆ—è¡¨ï¼ˆé‡ç‚¹ä½¿ç”¨ï¼Œç”¨äºç”ŸæˆAPIç¤ºä¾‹ï¼‰
        - analysis['classes']: ç±»åˆ—è¡¨ï¼ˆé‡ç‚¹ä½¿ç”¨ï¼Œç”¨äºç”ŸæˆAPIç¤ºä¾‹ï¼‰
        - analysis['entry_points']: å…¥å£ç‚¹ä¿¡æ¯ï¼ˆé‡ç‚¹ä½¿ç”¨ï¼Œç”¨äºCLIç¤ºä¾‹ï¼‰
        - analysis['modules']: æ¨¡å—åˆ—è¡¨
        - analysis['dependencies']: ä¾èµ–ä¿¡æ¯
        - self.project_dir: é¡¹ç›®è·¯å¾„
        """
        git_info = analysis.get('git_info', {})
        project_name = git_info.get('repo_name', Path(self.project_dir).name)
        
        # æ„å»ºåŸºç¡€é¡¹ç›®ä¿¡æ¯
        project_info = f"""
é¡¹ç›®ä¿¡æ¯ï¼š
- é¡¹ç›®åç§°: {project_name}
- é¡¹ç›®è·¯å¾„: {self.project_dir}
- æ¨¡å—æ•°é‡: {len(analysis.get('modules', []))}
- å‡½æ•°æ•°é‡: {len(analysis.get('functions', []))}
- ç±»æ•°é‡: {len(analysis.get('classes', []))}
- Gitä¿¡æ¯: {git_info}
- ä¾èµ–ä¿¡æ¯: {analysis.get('dependencies', {})}
- å…¥å£ç‚¹: {analysis.get('entry_points', [])}
"""
        
        # æ·»åŠ è¯¦ç»†çš„å‡½æ•°å’Œç±»ä¿¡æ¯
        functions_info = "\nä¸»è¦å‡½æ•°è¯¦æƒ…:\n"
        for func in analysis.get('functions', [])[:5]:
            functions_info += f"- {func.get('name', '')}: {func.get('definition', '')[:100]}...\n"
        
        classes_info = "\nä¸»è¦ç±»è¯¦æƒ…:\n"
        for cls in analysis.get('classes', [])[:3]:
            classes_info += f"- {cls.get('name', '')}: {cls.get('definition', '')[:100]}...\n"
        
        detailed_info = project_info + functions_info + classes_info
        
        return f"""
è¯·ä¸ºè¿™ä¸ªé¡¹ç›®ç”Ÿæˆè¯¦ç»†çš„ä½¿ç”¨è¯´æ˜æ–‡æ¡£ã€‚è¯·ä»”ç»†åˆ†ææä¾›çš„é¡¹ç›®ä¿¡æ¯ï¼Œç‰¹åˆ«æ˜¯å…¥å£ç‚¹ã€å‡½æ•°å®šä¹‰å’Œç±»å®šä¹‰ï¼Œç”Ÿæˆå‡†ç¡®å®ç”¨çš„ä½¿ç”¨æŒ‡å—ã€‚

åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š
1. åŸºæœ¬ç”¨æ³•ï¼ˆåŸºäºå®é™…çš„å…¥å£ç‚¹å’Œä¸»è¦APIï¼‰
2. å‘½ä»¤è¡Œæ¥å£è¯´æ˜ï¼ˆå¦‚æœæœ‰CLIå…¥å£ç‚¹ï¼‰
3. ç¼–ç¨‹æ¥å£è¯´æ˜ï¼ˆå¦‚æœæœ‰Python APIï¼‰
4. é…ç½®é€‰é¡¹ï¼ˆåŸºäºå®é™…çš„é…ç½®æ–‡ä»¶æˆ–å‚æ•°ï¼‰
5. å¸¸ç”¨åœºæ™¯ç¤ºä¾‹ï¼ˆåŸºäºå®é™…åŠŸèƒ½æ¨æ–­ï¼‰
6. æœ€ä½³å®è·µ

{detailed_info}

é‡è¦æç¤ºï¼š
- è¯·åŸºäºæä¾›çš„å®é™…å‡½æ•°å’Œç±»ä¿¡æ¯ç”Ÿæˆç¤ºä¾‹ï¼Œä¸è¦ç¼–é€ ä¸å­˜åœ¨çš„API
- å¦‚æœæ˜¯å‘½ä»¤è¡Œå·¥å…·ï¼Œè¯·åŸºäºå…¥å£ç‚¹ä¿¡æ¯ç”Ÿæˆæ­£ç¡®çš„å‘½ä»¤ç¤ºä¾‹
- å¦‚æœæ˜¯Pythonåº“ï¼Œè¯·åŸºäºå®é™…çš„ç±»å’Œå‡½æ•°ç”Ÿæˆå¯¼å…¥å’Œä½¿ç”¨ç¤ºä¾‹
- é¿å…ä½¿ç”¨è™šæ„çš„åŠŸèƒ½æˆ–å‚æ•°

è¯·ä½¿ç”¨Markdownæ ¼å¼ã€‚
"""
    
    def _create_examples_prompt(self, analysis: Dict) -> str:
        """
        åˆ›å»ºç¤ºä¾‹æ–‡æ¡£ç”Ÿæˆçš„æç¤ºè¯
        
        æ‰€éœ€è¾“å…¥ä¿¡æ¯ï¼š
        - analysis['git_info']['repo_name']: é¡¹ç›®åç§°
        - analysis['git_info']: Gitä»“åº“ä¿¡æ¯
        - analysis['functions']: å‡½æ•°åˆ—è¡¨ï¼ˆé‡ç‚¹ä½¿ç”¨ï¼Œç”¨äºç”Ÿæˆä»£ç ç¤ºä¾‹ï¼‰
        - analysis['classes']: ç±»åˆ—è¡¨ï¼ˆé‡ç‚¹ä½¿ç”¨ï¼Œç”¨äºç”Ÿæˆä»£ç ç¤ºä¾‹ï¼‰
        - analysis['entry_points']: å…¥å£ç‚¹ä¿¡æ¯ï¼ˆé‡ç‚¹ä½¿ç”¨ï¼Œç”¨äºCLIç¤ºä¾‹ï¼‰
        - analysis['modules']: æ¨¡å—åˆ—è¡¨
        - analysis['dependencies']: ä¾èµ–ä¿¡æ¯
        - self.project_dir: é¡¹ç›®è·¯å¾„
        """
        git_info = analysis.get('git_info', {})
        project_name = git_info.get('repo_name', Path(self.project_dir).name)
        
        project_info = f"""
é¡¹ç›®ä¿¡æ¯ï¼š
- é¡¹ç›®åç§°: {project_name}
- é¡¹ç›®è·¯å¾„: {self.project_dir}
- æ¨¡å—æ•°é‡: {len(analysis.get('modules', []))}
- å‡½æ•°æ•°é‡: {len(analysis.get('functions', []))}
- ç±»æ•°é‡: {len(analysis.get('classes', []))}
- Gitä¿¡æ¯: {git_info}
- ä¾èµ–ä¿¡æ¯: {analysis.get('dependencies', {})}
- å…¥å£ç‚¹: {analysis.get('entry_points', [])}
"""
        
        return f"""
è¯·ä¸ºè¿™ä¸ªé¡¹ç›®ç”Ÿæˆç¤ºä¾‹æ–‡æ¡£ã€‚è¯·ä»”ç»†åˆ†æé¡¹ç›®çš„å®é™…åŠŸèƒ½å’ŒAPIï¼Œç”ŸæˆçœŸå®å¯ç”¨çš„ç¤ºä¾‹ä»£ç ã€‚

åŒ…æ‹¬ä»¥ä¸‹å†…å®¹ï¼š
1. åŸºç¡€ä½¿ç”¨ç¤ºä¾‹ï¼ˆåŸºäºä¸»è¦å…¥å£ç‚¹å’Œæ ¸å¿ƒåŠŸèƒ½ï¼‰
2. é«˜çº§åŠŸèƒ½ç¤ºä¾‹ï¼ˆåŸºäºå¤æ‚çš„ç±»å’Œæ–¹æ³•ï¼‰
3. é›†æˆç¤ºä¾‹ï¼ˆå¦‚ä½•ä¸å…¶ä»–å·¥å…·æˆ–åº“é›†æˆï¼‰
4. å®Œæ•´é¡¹ç›®ç¤ºä¾‹ï¼ˆç«¯åˆ°ç«¯çš„ä½¿ç”¨åœºæ™¯ï¼‰
5. ä»£ç ç‰‡æ®µè¯´æ˜

{project_info}

ç”ŸæˆæŒ‡å¯¼åŸåˆ™ï¼š
- ä»”ç»†åˆ†ææä¾›çš„å‡½æ•°å’Œç±»å®šä¹‰ï¼Œç¡®ä¿ç¤ºä¾‹ä»£ç ä½¿ç”¨çœŸå®å­˜åœ¨çš„API
- æ ¹æ®å‡½æ•°å‚æ•°å’Œè¿”å›å€¼ç±»å‹ç”Ÿæˆåˆç†çš„ç¤ºä¾‹
- å¦‚æœæ˜¯å‘½ä»¤è¡Œå·¥å…·ï¼Œæä¾›å®é™…å¯æ‰§è¡Œçš„å‘½ä»¤ç¤ºä¾‹
- å¦‚æœæ˜¯Pythonåº“ï¼Œæä¾›æ­£ç¡®çš„å¯¼å…¥è¯­å¥å’Œæ–¹æ³•è°ƒç”¨
- ä¸ºæ¯ä¸ªç¤ºä¾‹æ·»åŠ æ¸…æ™°çš„æ³¨é‡Šè¯´æ˜
- ç¡®ä¿ç¤ºä¾‹ä»£ç çš„è¯­æ³•æ­£ç¡®æ€§
- é¿å…ä½¿ç”¨ä¸å­˜åœ¨çš„æ–¹æ³•ã€å‚æ•°æˆ–é…ç½®é€‰é¡¹

è¯·ä½¿ç”¨Markdownæ ¼å¼ï¼ŒåŒ…å«å¯è¿è¡Œçš„ä»£ç ç¤ºä¾‹ã€‚
"""
    
    def _create_architecture_prompt(self, analysis: Dict) -> str:
        """
        åˆ›å»ºæ¶æ„æ–‡æ¡£ç”Ÿæˆçš„æç¤ºè¯
        
        æ‰€éœ€è¾“å…¥ä¿¡æ¯ï¼š
        - analysis['git_info']['repo_name']: é¡¹ç›®åç§°
        - analysis['git_info']: Gitä»“åº“ä¿¡æ¯
        - analysis['modules']: æ¨¡å—åˆ—è¡¨ï¼ˆé‡ç‚¹ä½¿ç”¨ï¼Œç”¨äºæ¶æ„åˆ†æï¼‰
        - analysis['functions']: å‡½æ•°åˆ—è¡¨
        - analysis['classes']: ç±»åˆ—è¡¨
        - analysis['dependencies']: ä¾èµ–ä¿¡æ¯
        - analysis['entry_points']: å…¥å£ç‚¹ä¿¡æ¯
        - self.project_dir: é¡¹ç›®è·¯å¾„
        """
        git_info = analysis.get('git_info', {})
        project_name = git_info.get('repo_name', Path(self.project_dir).name)
        modules = analysis.get('modules', [])
        
        # è¯»å–è„šæœ¬ç®€ä»‹ä¿¡æ¯
        script_descriptions_file = self.project_dir / "script_descriptions.json"
        script_descriptions = {}
        if script_descriptions_file.exists():
            try:
                with open(script_descriptions_file, 'r', encoding='utf-8') as f:
                    script_descriptions = json.load(f)
            except Exception as e:
                if self.verbose:
                    self.console.print(f"[yellow]Warning: æ— æ³•è¯»å–è„šæœ¬æè¿°æ–‡ä»¶: {e}[/yellow]")
        
        # æ ¼å¼åŒ–è„šæœ¬ç®€ä»‹
        scripts_info = "\nè„šæœ¬ç®€ä»‹ï¼š\n"
        for script_path, description in script_descriptions.items():
            scripts_info += f"- {script_path}: {description[:200]}...\n"
        
        project_info = f"""
é¡¹ç›®ä¿¡æ¯ï¼š
- é¡¹ç›®åç§°: {project_name}
- é¡¹ç›®è·¯å¾„: {self.project_dir}
- æ¨¡å—æ•°é‡: {len(analysis.get('modules', []))}
- å‡½æ•°æ•°é‡: {len(analysis.get('functions', []))}
- ç±»æ•°é‡: {len(analysis.get('classes', []))}
- Gitä¿¡æ¯: {git_info}
- ä¾èµ–ä¿¡æ¯: {analysis.get('dependencies', {})}
- å…¥å£ç‚¹: {analysis.get('entry_points', [])}
- æ¨¡å—åˆ—è¡¨: {modules}

{scripts_info}
"""
        
        return f"""
è¯·åŸºäºé¡¹ç›®çš„è„šæœ¬ç®€ä»‹å’Œæ¨¡å—ä¿¡æ¯ç”Ÿæˆä¸“ä¸šçš„æ¶æ„æ–‡æ¡£ï¼ŒåŒ…æ‹¬ï¼š

1. **é¡¹ç›®æ¶æ„æ¦‚è§ˆ**ï¼š
   - æ•´ä½“æ¶æ„è®¾è®¡ç†å¿µ
   - æ ¸å¿ƒç»„ä»¶å’Œæ¨¡å—ä»‹ç»
   - æ¶æ„å›¾å¼•ç”¨ï¼š{{{{ARCHITECTURE_DIAGRAM_PLACEHOLDER}}}}

2. **æ¨¡å—è¯¦ç»†è¯´æ˜**ï¼š
   - åŸºäºè„šæœ¬ç®€ä»‹åˆ†æå„æ¨¡å—çš„èŒè´£
   - æ¨¡å—ä¹‹é—´çš„ä¾èµ–å…³ç³»
   - æ ¸å¿ƒç±»å’Œå‡½æ•°çš„ä½œç”¨

3. **æ•°æ®æµå’Œäº¤äº’**ï¼š
   - æ•°æ®åœ¨ç³»ç»Ÿä¸­çš„æµè½¬è¿‡ç¨‹
   - æ¨¡å—é—´çš„äº¤äº’æ–¹å¼
   - å…³é”®æ¥å£å’Œåè®®

4. **è®¾è®¡æ¨¡å¼å’ŒåŸåˆ™**ï¼š
   - é¡¹ç›®ä¸­ä½¿ç”¨çš„è®¾è®¡æ¨¡å¼
   - æ¶æ„è®¾è®¡åŸåˆ™
   - ä»£ç ç»„ç»‡æ–¹å¼

5. **æ‰©å±•æ€§è®¾è®¡**ï¼š
   - ç³»ç»Ÿçš„æ‰©å±•ç‚¹
   - æ’ä»¶æœºåˆ¶ï¼ˆå¦‚æœæœ‰ï¼‰
   - æœªæ¥å‘å±•æ–¹å‘

6. **æŠ€æœ¯æ ˆè¯´æ˜**ï¼š
   - ä¸»è¦æŠ€æœ¯é€‰å‹
   - ä¾èµ–åº“çš„ä½œç”¨
   - æŠ€æœ¯å†³ç­–çš„è€ƒè™‘å› ç´ 

{project_info}

æ³¨æ„ï¼š
- é‡ç‚¹ç»“åˆè„šæœ¬ç®€ä»‹æ¥åˆ†ææ¶æ„
- æ¶æ„å›¾å°†å•ç‹¬ç”Ÿæˆä¸º drawio æ–‡ä»¶
- ä½¿ç”¨ä¸“ä¸šçš„æŠ€æœ¯æœ¯è¯­
- æä¾›æ¸…æ™°çš„å±‚æ¬¡ç»“æ„
- ä½¿ç”¨æ ‡å‡†çš„Markdownæ ¼å¼
- åŒ…å«å®ç”¨çš„æ¶æ„å»ºè®®
"""
    
    def _create_contributing_prompt(self, analysis: Dict) -> str:
        """
        åˆ›å»ºè´¡çŒ®æŒ‡å—æ–‡æ¡£ç”Ÿæˆçš„æç¤ºè¯
        
        æ‰€éœ€è¾“å…¥ä¿¡æ¯ï¼š
        - analysis['git_info']['repo_name']: é¡¹ç›®åç§°
        - analysis['git_info']: Gitä»“åº“ä¿¡æ¯ï¼ˆé‡ç‚¹ä½¿ç”¨ï¼Œç”¨äºè´¡çŒ®æµç¨‹ï¼‰
        - analysis['dependencies']: ä¾èµ–ä¿¡æ¯ï¼ˆç”¨äºå¼€å‘ç¯å¢ƒæ­å»ºï¼‰
        - analysis['modules']: æ¨¡å—åˆ—è¡¨
        - analysis['functions']: å‡½æ•°åˆ—è¡¨
        - analysis['classes']: ç±»åˆ—è¡¨
        - analysis['entry_points']: å…¥å£ç‚¹ä¿¡æ¯
        - self.project_dir: é¡¹ç›®è·¯å¾„
        """
        git_info = analysis.get('git_info', {})
        project_name = git_info.get('repo_name', Path(self.project_dir).name)
        
        # è·å–Gitè´¡çŒ®è€…ä¿¡æ¯
        contributors = self._get_git_contributors()
        
        # æ ¼å¼åŒ–è´¡çŒ®è€…ä¿¡æ¯
        contributors_info = "\né¡¹ç›®è´¡çŒ®è€…ï¼š\n"
        for contributor in contributors[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªè´¡çŒ®è€…
            contributors_info += f"- {contributor['name']} ({contributor['commits']} commits)"
            if contributor['email']:
                contributors_info += f" - {contributor['email']}"
            contributors_info += "\n"
        
        project_info = f"""
é¡¹ç›®ä¿¡æ¯ï¼š
- é¡¹ç›®åç§°: {project_name}
- é¡¹ç›®è·¯å¾„: {self.project_dir}
- æ¨¡å—æ•°é‡: {len(analysis.get('modules', []))}
- å‡½æ•°æ•°é‡: {len(analysis.get('functions', []))}
- ç±»æ•°é‡: {len(analysis.get('classes', []))}
- Gitä¿¡æ¯: {git_info}
- ä¾èµ–ä¿¡æ¯: {analysis.get('dependencies', {})}
- å…¥å£ç‚¹: {analysis.get('entry_points', [])}
"""
        
        return f"""
è¯·åŸºäºé¡¹ç›®çš„Gitä»“åº“ä¿¡æ¯å’Œç°æœ‰è´¡çŒ®è€…ç”Ÿæˆä¸“ä¸šçš„è´¡çŒ®æŒ‡å—æ–‡æ¡£ï¼ŒåŒ…æ‹¬ï¼š

1. **é¡¹ç›®è´¡çŒ®è€…è‡´è°¢**ï¼š
   - å±•ç¤ºç°æœ‰è´¡çŒ®è€…çš„å¤´åƒå’Œè´¡çŒ®ç»Ÿè®¡
   - ä½¿ç”¨GitHubå¤´åƒé“¾æ¥æ ¼å¼ï¼š![avatar](https://github.com/username.png?size=50)
   - æŒ‰è´¡çŒ®æ¬¡æ•°æ’åºå±•ç¤ºè´¡çŒ®è€…

2. **å¦‚ä½•å¼€å§‹è´¡çŒ®**ï¼š
   - Forké¡¹ç›®æµç¨‹
   - å…‹éš†å’Œè®¾ç½®æœ¬åœ°å¼€å‘ç¯å¢ƒ
   - åˆ›å»ºåŠŸèƒ½åˆ†æ”¯çš„æœ€ä½³å®è·µ

3. **å¼€å‘ç¯å¢ƒæ­å»º**ï¼š
   - åŸºäºé¡¹ç›®ä¾èµ–ä¿¡æ¯æä¾›è¯¦ç»†çš„ç¯å¢ƒé…ç½®æ­¥éª¤
   - åŒ…å«è™šæ‹Ÿç¯å¢ƒè®¾ç½®ã€ä¾èµ–å®‰è£…ç­‰

4. **ä»£ç è´¡çŒ®è§„èŒƒ**ï¼š
   - ä»£ç é£æ ¼å’Œæ ¼å¼è¦æ±‚
   - æäº¤ä¿¡æ¯è§„èŒƒï¼ˆåŸºäºç°æœ‰æäº¤å†å²çš„æ¨¡å¼ï¼‰
   - ä»£ç å®¡æŸ¥æµç¨‹

5. **æµ‹è¯•è¦æ±‚**ï¼š
   - å¦‚ä½•è¿è¡Œæµ‹è¯•
   - æ–°åŠŸèƒ½çš„æµ‹è¯•è¦†ç›–è¦æ±‚
   - æµ‹è¯•æœ€ä½³å®è·µ

6. **Pull Requestæµç¨‹**ï¼š
   - PRæ¨¡æ¿å’Œè¦æ±‚
   - ä»£ç å®¡æŸ¥æµç¨‹
   - åˆå¹¶æ ‡å‡†

7. **é—®é¢˜æŠ¥å‘Š**ï¼š
   - BugæŠ¥å‘Šæ¨¡æ¿
   - åŠŸèƒ½è¯·æ±‚æ ¼å¼
   - é—®é¢˜åˆ†ç±»å’Œæ ‡ç­¾

8. **ç¤¾åŒºå‡†åˆ™**ï¼š
   - è¡Œä¸ºå‡†åˆ™
   - æ²Ÿé€šæ–¹å¼
   - è·å–å¸®åŠ©çš„æ¸ é“

{project_info}

æ³¨æ„ï¼š
- ä¸ºæ¯ä¸ªè´¡çŒ®è€…ç”ŸæˆGitHubå¤´åƒé“¾æ¥
- åŸºäºå®é™…çš„Gitä¿¡æ¯æä¾›å…·ä½“çš„è´¡çŒ®æµç¨‹
- ä½¿ç”¨å‹å¥½å’Œé¼“åŠ±æ€§çš„è¯­è°ƒ
- æä¾›æ¸…æ™°çš„æ­¥éª¤è¯´æ˜
- ä½¿ç”¨æ ‡å‡†çš„Markdownæ ¼å¼
- åŒ…å«å®ç”¨çš„ä»£ç ç¤ºä¾‹å’Œå‘½ä»¤
"""
    
    def _create_changelog_prompt(self, analysis: Dict) -> str:
        """
        åˆ›å»ºå¢å¼ºçš„æ›´æ–°æ—¥å¿—æ–‡æ¡£ç”Ÿæˆæç¤ºè¯
        
        æ‰€éœ€è¾“å…¥ä¿¡æ¯ï¼š
        - analysis['git_info']['repo_name']: é¡¹ç›®åç§°
        - analysis['git_info']: Gitä»“åº“ä¿¡æ¯
        - analysis['modules']: æ¨¡å—åˆ—è¡¨
        - analysis['functions']: å‡½æ•°åˆ—è¡¨
        - analysis['classes']: ç±»åˆ—è¡¨
        - analysis['dependencies']: ä¾èµ–ä¿¡æ¯
        - analysis['entry_points']: å…¥å£ç‚¹ä¿¡æ¯
        - self.project_dir: é¡¹ç›®è·¯å¾„
        """
        git_info = analysis.get('git_info', {})
        project_name = git_info.get('repo_name', Path(self.project_dir).name)
        
        # è·å–å¢å¼ºçš„Gitæäº¤å†å²
        commit_history = self._get_git_commit_history(limit=30)
        
        # è·å–Gitæ ‡ç­¾ä¿¡æ¯
        tags = self._get_git_tags()
        
        # åˆ†ææäº¤ç»Ÿè®¡
        commit_stats = self._analyze_commit_statistics(commit_history)
        
        # æ ¼å¼åŒ–è¯¦ç»†çš„æäº¤å†å²
        commit_info = "\n=== è¯¦ç»†æäº¤å†å²åˆ†æ ===\n"
        
        # æŒ‰ç±»å‹åˆ†ç»„æ˜¾ç¤ºæäº¤
        commits_by_type = {}
        for commit in commit_history:
            commit_type = commit.get('type', 'other')
            if commit_type not in commits_by_type:
                commits_by_type[commit_type] = []
            commits_by_type[commit_type].append(commit)
        
        for commit_type, commits in commits_by_type.items():
            commit_info += f"\n{commit_type.upper()} ç±»å‹æäº¤ ({len(commits)} ä¸ª):\n"
            for commit in commits[:5]:  # æ¯ç§ç±»å‹æœ€å¤šæ˜¾ç¤º5ä¸ª
                files_info = f" (å½±å“ {len(commit.get('files_changed', []))} ä¸ªæ–‡ä»¶)" if commit.get('files_changed') else ""
                breaking_mark = " [BREAKING]" if commit.get('is_breaking') else ""
                commit_info += f"  - {commit['date']} [{commit['hash']}] {commit['message']}{files_info}{breaking_mark}\n"
                
                # æ˜¾ç¤ºä¸»è¦å˜æ›´æ–‡ä»¶
                if commit.get('files_changed'):
                    main_files = [f['file'] for f in commit['files_changed'][:3]]
                    commit_info += f"    ä¸»è¦æ–‡ä»¶: {', '.join(main_files)}\n"
        
        # æ·»åŠ æ ‡ç­¾ä¿¡æ¯
        tags_info = "\n=== ç‰ˆæœ¬æ ‡ç­¾å†å² ===\n"
        if tags:
            for tag in tags[:10]:
                tags_info += f"- {tag['name']} ({tag['date']}) - {tag['message']}\n"
        else:
            tags_info += "æš‚æ— ç‰ˆæœ¬æ ‡ç­¾\n"
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        stats_info = f"\n=== æäº¤ç»Ÿè®¡åˆ†æ ===\n"
        stats_info += f"- æ€»æäº¤æ•°: {len(commit_history)}\n"
        stats_info += f"- åŠŸèƒ½æäº¤: {commit_stats.get('feat', 0)} ä¸ª\n"
        stats_info += f"- ä¿®å¤æäº¤: {commit_stats.get('fix', 0)} ä¸ª\n"
        stats_info += f"- æ–‡æ¡£æäº¤: {commit_stats.get('docs', 0)} ä¸ª\n"
        stats_info += f"- é‡æ„æäº¤: {commit_stats.get('refactor', 0)} ä¸ª\n"
        stats_info += f"- ç ´åæ€§å˜æ›´: {sum(1 for c in commit_history if c.get('is_breaking'))} ä¸ª\n"
        stats_info += f"- ä¸»è¦è´¡çŒ®è€…: {', '.join(list(set([c['author'] for c in commit_history[:10]])))[:100]}...\n"
        
        project_info = f"""
é¡¹ç›®ä¿¡æ¯ï¼š
- é¡¹ç›®åç§°: {project_name}
- é¡¹ç›®è·¯å¾„: {self.project_dir}
- æ¨¡å—æ•°é‡: {len(analysis.get('modules', []))}
- å‡½æ•°æ•°é‡: {len(analysis.get('functions', []))}
- ç±»æ•°é‡: {len(analysis.get('classes', []))}
- Gitä¿¡æ¯: {git_info}
- ä¾èµ–ä¿¡æ¯: {analysis.get('dependencies', {})}
- å…¥å£ç‚¹: {analysis.get('entry_points', [])}

{commit_info}
{tags_info}
{stats_info}
"""
        
        return f"""
è¯·åŸºäºé¡¹ç›®çš„è¯¦ç»†Gitæäº¤å†å²å’Œåˆ†æç»“æœç”Ÿæˆä¸“ä¸šçš„æ›´æ–°æ—¥å¿—æ–‡æ¡£ï¼ŒåŒ…æ‹¬ï¼š

1. **ç‰ˆæœ¬ç®¡ç†è§„èŒƒ**ï¼š
   - è¯­ä¹‰åŒ–ç‰ˆæœ¬æ§åˆ¶ (Semantic Versioning) è¯´æ˜
   - ç‰ˆæœ¬å·æ ¼å¼ï¼šMAJOR.MINOR.PATCH
   - ç‰ˆæœ¬å‘å¸ƒç­–ç•¥å’Œå‘¨æœŸ

2. **æ›´æ–°æ—¥å¿—ç»“æ„**ï¼š
   - æŒ‰ç‰ˆæœ¬æ—¶é—´å€’åºç»„ç»‡
   - æ ‡å‡†åˆ†ç±»ï¼šAddedï¼ˆæ–°å¢ï¼‰ã€Changedï¼ˆå˜æ›´ï¼‰ã€Deprecatedï¼ˆå¼ƒç”¨ï¼‰ã€Removedï¼ˆç§»é™¤ï¼‰ã€Fixedï¼ˆä¿®å¤ï¼‰ã€Securityï¼ˆå®‰å…¨ï¼‰
   - ç ´åæ€§å˜æ›´å•ç‹¬æ ‡æ³¨ [BREAKING CHANGE]

3. **åŸºäºå®é™…æäº¤å†å²çš„æ™ºèƒ½åˆ†æ**ï¼š
   - æ ¹æ®æäº¤ç±»å‹ç»Ÿè®¡è‡ªåŠ¨ç”Ÿæˆç‰ˆæœ¬æ¡ç›®
   - å°†æŠ€æœ¯æ€§æäº¤ä¿¡æ¯è½¬æ¢ä¸ºç”¨æˆ·å‹å¥½çš„æè¿°
   - åˆå¹¶ç›¸å…³æäº¤ä¸ºæœ‰æ„ä¹‰çš„åŠŸèƒ½å˜æ›´
   - è¯†åˆ«å’Œçªå‡ºæ˜¾ç¤ºç ´åæ€§å˜æ›´
   - åŸºäºæ–‡ä»¶å˜æ›´èŒƒå›´è¯„ä¼°å˜æ›´å½±å“

4. **ç‰ˆæœ¬å‘å¸ƒå»ºè®®**ï¼š
   - åŸºäºæäº¤ç±»å‹å»ºè®®ä¸‹ä¸€ä¸ªç‰ˆæœ¬å·
   - æ ¹æ®ç ´åæ€§å˜æ›´å»ºè®®ä¸»ç‰ˆæœ¬å‡çº§
   - åŸºäºåŠŸèƒ½æäº¤å»ºè®®æ¬¡ç‰ˆæœ¬å‡çº§
   - åŸºäºä¿®å¤æäº¤å»ºè®®è¡¥ä¸ç‰ˆæœ¬å‡çº§

5. **è¯¦ç»†çš„ç‰ˆæœ¬æ¡ç›®ç¤ºä¾‹**ï¼š
   - æ ¹æ®å®é™…æäº¤å†å²ç”Ÿæˆå…·ä½“ç‰ˆæœ¬
   - å±•ç¤ºå®Œæ•´çš„å˜æ›´åˆ†ç±»å’Œæè¿°
   - åŒ…å«è´¡çŒ®è€…ä¿¡æ¯å’Œæäº¤é“¾æ¥
   - æ˜¾ç¤ºæ¯ä¸ªç‰ˆæœ¬çš„å½±å“èŒƒå›´å’Œé‡è¦æ€§

6. **ç»´æŠ¤æŒ‡å—**ï¼š
   - å¦‚ä½•ç»´æŠ¤æ›´æ–°æ—¥å¿—
   - æäº¤ä¿¡æ¯è§„èŒƒå»ºè®®
   - ç‰ˆæœ¬å‘å¸ƒæµç¨‹è¯´æ˜

7. **è´¡çŒ®è€…è‡´è°¢**ï¼š
   - æŒ‰ç‰ˆæœ¬åˆ—å‡ºä¸»è¦è´¡çŒ®è€…
   - æ„Ÿè°¢ç¤¾åŒºè´¡çŒ®å’Œåé¦ˆ

{project_info}

ç‰¹åˆ«è¦æ±‚ï¼š
- æ·±åº¦åˆ†ææäº¤å†å²ï¼Œç”ŸæˆçœŸå®å¯ä¿¡çš„ç‰ˆæœ¬å˜æ›´
- æ™ºèƒ½è¯†åˆ«åŠŸèƒ½æ¨¡å—ï¼ŒæŒ‰æ¨¡å—ç»„ç»‡å˜æ›´è¯´æ˜
- å°†æŠ€æœ¯æ€§æäº¤è½¬æ¢ä¸ºä¸šåŠ¡ä»·å€¼æè¿°
- çªå‡ºæ˜¾ç¤ºç”¨æˆ·å…³å¿ƒçš„åŠŸèƒ½æ”¹è¿›å’Œé—®é¢˜ä¿®å¤
- åŸºäºæ–‡ä»¶å˜æ›´ç»Ÿè®¡è¯„ä¼°æ¯ä¸ªç‰ˆæœ¬çš„å½±å“èŒƒå›´
- ä½¿ç”¨ Keep a Changelog æ ‡å‡†æ ¼å¼
- æä¾›ç‰ˆæœ¬é—´çš„å‡çº§æŒ‡å¯¼å’Œæ³¨æ„äº‹é¡¹
- åŒ…å«å…·ä½“çš„ä»£ç ç¤ºä¾‹å’Œä½¿ç”¨è¯´æ˜ï¼ˆå¦‚é€‚ç”¨ï¼‰
- ç”Ÿæˆå¯æ“ä½œçš„ç‰ˆæœ¬å‘å¸ƒæ£€æŸ¥æ¸…å•
"""
        
    def _create_mkdocs_config(self, analysis: Dict) -> Dict:
        """åˆ›å»ºMkDocsé…ç½®"""
        git_info = analysis.get('git_info', {})
        repo_name = git_info.get('repo_name', 'project')
        github_username = git_info.get('github_username', '')
        
        # å¤„ç†repo_urlï¼Œç¡®ä¿ä½¿ç”¨httpsæ ¼å¼
        remote_url = git_info.get('remote_url', '')
        repo_url = self._convert_git_url_to_https(remote_url)
        
        config = {
            'site_name': f'{repo_name} æ–‡æ¡£',
            'site_description': f'{repo_name} é¡¹ç›®æ–‡æ¡£',
            'site_author': github_username,
            'repo_url': repo_url,
            'repo_name': f'{github_username}/{repo_name}' if github_username else repo_name,
            
            'theme': {
                'name': 'material',
                'language': 'zh',
                'features': [
                    'navigation.tabs',
                    'navigation.sections',
                    'navigation.expand',
                    'navigation.top',
                    'search.highlight',
                    'search.share',
                    'content.code.copy'
                ],
                'palette': [
                    {
                        'scheme': 'default',
                        'primary': 'blue',
                        'accent': 'blue',
                        'toggle': {
                            'icon': 'material/brightness-7',
                            'name': 'åˆ‡æ¢åˆ°æ·±è‰²æ¨¡å¼'
                        }
                    },
                    {
                        'scheme': 'slate',
                        'primary': 'blue',
                        'accent': 'blue',
                        'toggle': {
                            'icon': 'material/brightness-4',
                            'name': 'åˆ‡æ¢åˆ°æµ…è‰²æ¨¡å¼'
                        }
                    }
                ]
            },
            
            'nav': [
                {'é¦–é¡µ': 'index.md'},
                {'å®‰è£…': 'installation.md'},
                {'ä½¿ç”¨è¯´æ˜': 'usage.md'},
                {'APIæ–‡æ¡£': 'api/index.md'},
                {'ç¤ºä¾‹': 'examples.md'},
                {'æ¶æ„': 'architecture.md'},
                {'è´¡çŒ®æŒ‡å—': 'contributing.md'},
                {'æ›´æ–°æ—¥å¿—': 'changelog.md'}
            ],
            
            'markdown_extensions': [
                'codehilite',
                'admonition',
                'pymdownx.details',
                'pymdownx.superfences',
                'pymdownx.tabbed',
                'toc'
            ],
            
            'plugins': [
                'search',
                'drawio'
            ]
        }
        
        return config
        
    def _dict_to_yaml_string(self, data: Dict, indent: int = 0) -> str:
        """å°†å­—å…¸è½¬æ¢ä¸ºYAMLæ ¼å¼å­—ç¬¦ä¸²ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼Œç¡®ä¿å­—ç¬¦ä¸²å€¼è¢«æ­£ç¡®å¼•ç”¨ï¼‰"""
        yaml_lines = []
        indent_str = '  ' * indent
        
        for key, value in data.items():
            if isinstance(value, dict):
                yaml_lines.append(f"{indent_str}{key}:")
                yaml_lines.append(self._dict_to_yaml_string(value, indent + 1))
            elif isinstance(value, list):
                yaml_lines.append(f"{indent_str}{key}:")
                for item in value:
                    if isinstance(item, dict):
                        yaml_lines.append(f"{indent_str}  -")
                        for sub_key, sub_value in item.items():
                            formatted_value = self._format_yaml_value(sub_value)
                            yaml_lines.append(f"{indent_str}    {sub_key}: {formatted_value}")
                    else:
                        formatted_item = self._format_yaml_value(item)
                        yaml_lines.append(f"{indent_str}  - {formatted_item}")
            else:
                formatted_value = self._format_yaml_value(value)
                yaml_lines.append(f"{indent_str}{key}: {formatted_value}")
                
        return '\n'.join(yaml_lines)
    
    def _format_yaml_value(self, value) -> str:
        """æ ¼å¼åŒ–YAMLå€¼ï¼Œç¡®ä¿å­—ç¬¦ä¸²è¢«æ­£ç¡®å¼•ç”¨"""
        if isinstance(value, str):
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¼•ç”¨
            if (value.isdigit() or 
                value.lower() in ['true', 'false', 'null', 'yes', 'no'] or
                ':' in value or 
                value.startswith('#') or
                '\n' in value or
                value.strip() != value):
                return f'"{value}"'
            return value
        elif isinstance(value, bool):
            return 'true' if value else 'false'
        elif value is None:
            return 'null'
        else:
            return str(value)
    
    # ASTè§£æè¾…åŠ©æ–¹æ³•
    def _extract_functions_from_ast(self, tree: ast.AST, file_path: Path, content: str) -> List[Dict]:
        """ä»ASTä¸­æå–å‡½æ•°ä¿¡æ¯"""
        functions = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                func_info = {
                    'name': node.name,
                    'module': self._get_module_name(file_path),
                    'file_path': str(file_path),
                    'line_start': node.lineno,
                    'line_end': getattr(node, 'end_lineno', node.lineno),
                    'definition': self._extract_function_definition(node, content),
                    'context': self._extract_function_context(node, content),
                    'metadata': self._extract_function_metadata(node),
                    'lines': getattr(node, 'end_lineno', node.lineno) - node.lineno + 1
                }
                functions.append(func_info)
                
        return functions
        
    def _extract_classes_from_ast(self, tree: ast.AST, file_path: Path, content: str) -> List[Dict]:
        """ä»ASTä¸­æå–ç±»ä¿¡æ¯"""
        classes = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.ClassDef):
                class_info = {
                    'name': node.name,
                    'module': self._get_module_name(file_path),
                    'file_path': str(file_path),
                    'line_start': node.lineno,
                    'line_end': getattr(node, 'end_lineno', node.lineno),
                    'definition': self._extract_class_definition(node, content),
                    'context': self._extract_class_context(node, content),
                    'metadata': self._extract_class_metadata(node),
                    'methods': self._extract_class_methods(node)
                }
                classes.append(class_info)
                
        return classes
        
    def _get_module_name(self, file_path: Path) -> str:
        """è·å–æ¨¡å—å"""
        relative_path = file_path.relative_to(self.project_dir)
        return str(relative_path).replace('/', '.').replace('\\', '.').replace('.py', '')
        
    def _extract_function_definition(self, node: ast.FunctionDef, content: str) -> str:
        """æå–å‡½æ•°å®šä¹‰"""
        lines = content.split('\n')
        start_line = node.lineno - 1
        end_line = getattr(node, 'end_lineno', node.lineno)
        
        # æå–å‡½æ•°ç­¾åå’Œæ–‡æ¡£å­—ç¬¦ä¸²
        definition_lines = []
        
        # æ·»åŠ è£…é¥°å™¨
        for decorator in node.decorator_list:
            decorator_line = start_line - len(node.decorator_list) + node.decorator_list.index(decorator)
            if 0 <= decorator_line < len(lines):
                definition_lines.append(lines[decorator_line].strip())
                
        # æ·»åŠ å‡½æ•°ç­¾å
        if start_line < len(lines):
            func_line = lines[start_line].strip()
            definition_lines.append(func_line)
            
        # æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²
        if (isinstance(node.body[0], ast.Expr) and 
            isinstance(node.body[0].value, ast.Constant) and 
            isinstance(node.body[0].value.value, str)):
            docstring = node.body[0].value.value
            definition_lines.append(f'    """\n    {docstring}\n    """')
            
        return '\n'.join(definition_lines)
        
    def _extract_class_definition(self, node: ast.ClassDef, content: str) -> str:
        """æå–ç±»å®šä¹‰"""
        lines = content.split('\n')
        start_line = node.lineno - 1
        
        definition_lines = []
        
        # æ·»åŠ è£…é¥°å™¨
        for decorator in node.decorator_list:
            decorator_line = start_line - len(node.decorator_list) + node.decorator_list.index(decorator)
            if 0 <= decorator_line < len(lines):
                definition_lines.append(lines[decorator_line].strip())
                
        # æ·»åŠ ç±»ç­¾å
        if start_line < len(lines):
            class_line = lines[start_line].strip()
            definition_lines.append(class_line)
            
        # æ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²
        if (node.body and isinstance(node.body[0], ast.Expr) and 
            isinstance(node.body[0].value, ast.Constant) and 
            isinstance(node.body[0].value.value, str)):
            docstring = node.body[0].value.value
            definition_lines.append(f'    """\n    {docstring}\n    """')
            
        return '\n'.join(definition_lines)
        
    def _extract_function_context(self, node: ast.FunctionDef, content: str) -> str:
        """æå–å‡½æ•°ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        lines = content.split('\n')
        start_line = max(0, node.lineno - 5)  # å‰5è¡Œ
        end_line = min(len(lines), getattr(node, 'end_lineno', node.lineno) + 3)  # å3è¡Œ
        
        context_lines = lines[start_line:end_line]
        return '\n'.join(context_lines)
        
    def _extract_class_context(self, node: ast.ClassDef, content: str) -> str:
        """æå–ç±»ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        lines = content.split('\n')
        start_line = max(0, node.lineno - 3)
        end_line = min(len(lines), node.lineno + 10)  # ç±»çš„å‰å‡ è¡Œ
        
        context_lines = lines[start_line:end_line]
        return '\n'.join(context_lines)
        
    def _extract_function_metadata(self, node: ast.FunctionDef) -> Dict:
        """æå–å‡½æ•°å…ƒæ•°æ®"""
        metadata = {
            'args': [arg.arg for arg in node.args.args],
            'defaults': len(node.args.defaults),
            'returns': bool(node.returns),
            'is_async': isinstance(node, ast.AsyncFunctionDef),
            'decorators': [ast.unparse(d) for d in node.decorator_list] if hasattr(ast, 'unparse') else [],
            'complexity': self._calculate_complexity(node)
        }
        return metadata
        
    def _extract_class_metadata(self, node: ast.ClassDef) -> Dict:
        """æå–ç±»å…ƒæ•°æ®"""
        metadata = {
            'bases': [ast.unparse(base) for base in node.bases] if hasattr(ast, 'unparse') else [],
            'decorators': [ast.unparse(d) for d in node.decorator_list] if hasattr(ast, 'unparse') else [],
            'methods': len([n for n in node.body if isinstance(n, ast.FunctionDef)]),
            'properties': len([n for n in node.body if isinstance(n, ast.FunctionDef) and 
                             any(isinstance(d, ast.Name) and d.id == 'property' for d in n.decorator_list)])
        }
        return metadata
        
    def _extract_class_methods(self, node: ast.ClassDef) -> List[str]:
        """æå–ç±»æ–¹æ³•ååˆ—è¡¨"""
        methods = []
        for item in node.body:
            if isinstance(item, ast.FunctionDef):
                methods.append(item.name)
        return methods
        
    def _calculate_complexity(self, node: ast.FunctionDef) -> int:
        """è®¡ç®—å‡½æ•°å¤æ‚åº¦ï¼ˆç®€å•ç‰ˆæœ¬ï¼‰"""
        complexity = 1  # åŸºç¡€å¤æ‚åº¦
        
        for child in ast.walk(node):
            if isinstance(child, (ast.If, ast.While, ast.For, ast.Try, ast.With)):
                complexity += 1
            elif isinstance(child, ast.BoolOp):
                complexity += len(child.values) - 1
                
        return complexity
        
    # ä¾èµ–è§£æè¾…åŠ©æ–¹æ³•
    def _parse_python_deps(self, file_path: Path) -> List[str]:
        """è§£æPythonä¾èµ–"""
        deps = []
        filename = file_path.name.lower()
        
        try:
            if filename == 'requirements.txt' or filename.endswith('.txt'):
                deps = self._parse_requirements_txt(file_path)
            elif filename == 'pyproject.toml':
                deps = self._parse_pyproject_toml(file_path)
            elif filename == 'setup.py':
                deps = self._parse_setup_py(file_path)
            elif filename == 'pipfile':
                deps = self._parse_pipfile(file_path)
            elif filename == 'setup.cfg':
                deps = self._parse_setup_cfg(file_path)
            elif filename == 'environment.yml':
                deps = self._parse_conda_env(file_path)
            elif filename == 'poetry.lock':
                deps = self._parse_poetry_lock(file_path)
                
        except Exception as e:
            if self.verbose:
                self.console.print(f"[yellow]Warning: Error parsing {file_path}: {e}[/yellow]")
                
        return deps
    
    def _parse_requirements_txt(self, file_path: Path) -> List[str]:
        """è§£ærequirements.txtæ–‡ä»¶"""
        deps = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                # è·³è¿‡æ³¨é‡Šã€ç©ºè¡Œå’Œ-r/-eé€‰é¡¹
                if line and not line.startswith('#') and not line.startswith('-'):
                    # å¤„ç†git+https://ç­‰URLä¾èµ–
                    if line.startswith('git+') or line.startswith('http'):
                        # å°è¯•ä»URLä¸­æå–åŒ…å
                        if '#egg=' in line:
                            pkg_name = line.split('#egg=')[1].split('&')[0]
                        else:
                            continue
                    else:
                        # æå–åŒ…åï¼ˆå»é™¤ç‰ˆæœ¬å·å’Œé¢å¤–é€‰é¡¹ï¼‰
                        pkg_name = re.split(r'[>=<!=\[\s]', line)[0].strip()
                    
                    if pkg_name and pkg_name not in deps:
                        deps.append(pkg_name)
        return deps
    
    def _parse_pyproject_toml(self, file_path: Path) -> List[str]:
        """è§£æpyproject.tomlæ–‡ä»¶"""
        deps = []
        
        try:
            import tomli
            with open(file_path, 'rb') as f:
                data = tomli.load(f)
                
            # ä»project.dependenciesä¸­æå–
            project_deps = data.get('project', {}).get('dependencies', [])
            for dep in project_deps:
                pkg_name = re.split(r'[>=<!=\[\s]', dep)[0].strip()
                if pkg_name:
                    deps.append(pkg_name)
            
            # ä»tool.poetry.dependenciesä¸­æå–ï¼ˆPoetryæ ¼å¼ï¼‰
            poetry_deps = data.get('tool', {}).get('poetry', {}).get('dependencies', {})
            for pkg_name in poetry_deps.keys():
                if pkg_name != 'python':  # æ’é™¤pythonç‰ˆæœ¬è¦æ±‚
                    deps.append(pkg_name)
                    
        except ImportError:
            # å¦‚æœæ²¡æœ‰tomliï¼Œå°è¯•ç®€å•è§£æ
            deps = self._parse_toml_fallback(file_path)
            
        return deps
    
    def _parse_toml_fallback(self, file_path: Path) -> List[str]:
        """TOMLæ–‡ä»¶çš„fallbackè§£ææ–¹æ³•"""
        deps = []
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # åŒ¹é…dependenciesæ•°ç»„
        deps_patterns = [
            r'dependencies\s*=\s*\[(.*?)\]',
            r'\[tool\.poetry\.dependencies\](.*?)(?=\[|$)'
        ]
        
        for pattern in deps_patterns:
            matches = re.findall(pattern, content, re.DOTALL)
            for match in matches:
                # æå–å¼•å·å†…çš„ä¾èµ–
                dep_matches = re.findall(r'["\']([^"\'><=!\[]+)', match)
                for dep in dep_matches:
                    if dep and dep != 'python':
                        deps.append(dep)
                        
        return deps
    
    def _parse_setup_py(self, file_path: Path) -> List[str]:
        """è§£æsetup.pyæ–‡ä»¶"""
        deps = []
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # åŒ¹é…install_requires
        install_requires_match = re.search(r'install_requires\s*=\s*\[(.*?)\]', content, re.DOTALL)
        if install_requires_match:
            deps_str = install_requires_match.group(1)
            dep_matches = re.findall(r'["\']([^"\'><=!\[]+)', deps_str)
            deps.extend(dep_matches)
            
        return deps
    
    def _parse_pipfile(self, file_path: Path) -> List[str]:
        """è§£æPipfileæ–‡ä»¶"""
        deps = []
        try:
            import tomli
            with open(file_path, 'rb') as f:
                data = tomli.load(f)
                
            # ä»packageså’Œdev-packagesä¸­æå–
            for section in ['packages', 'dev-packages']:
                if section in data:
                    deps.extend(data[section].keys())
                    
        except ImportError:
            # fallbackè§£æ
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            sections = re.findall(r'\[(packages|dev-packages)\](.*?)(?=\[|$)', content, re.DOTALL)
            for section_name, section_content in sections:
                dep_matches = re.findall(r'^([a-zA-Z0-9_-]+)\s*=', section_content, re.MULTILINE)
                deps.extend(dep_matches)
                
        return deps
    
    def _parse_setup_cfg(self, file_path: Path) -> List[str]:
        """è§£æsetup.cfgæ–‡ä»¶"""
        deps = []
        try:
            import configparser
            config = configparser.ConfigParser()
            config.read(file_path)
            
            if 'options' in config and 'install_requires' in config['options']:
                install_requires = config['options']['install_requires']
                for line in install_requires.split('\n'):
                    line = line.strip()
                    if line:
                        pkg_name = re.split(r'[>=<!=\[\s]', line)[0].strip()
                        if pkg_name:
                            deps.append(pkg_name)
                            
        except Exception:
            pass
            
        return deps
    
    def _parse_conda_env(self, file_path: Path) -> List[str]:
        """è§£æconda environment.ymlæ–‡ä»¶"""
        deps = []
        try:
            import yaml
            with open(file_path, 'r', encoding='utf-8') as f:
                data = yaml.safe_load(f)
                
            if 'dependencies' in data:
                for dep in data['dependencies']:
                    if isinstance(dep, str):
                        # è·³è¿‡conda-forgeç­‰channelä¿¡æ¯
                        if '::' not in dep:
                            pkg_name = re.split(r'[>=<!=\s]', dep)[0].strip()
                            if pkg_name:
                                deps.append(pkg_name)
                                
        except ImportError:
            pass
        except Exception:
            pass
            
        return deps
    
    def _parse_poetry_lock(self, file_path: Path) -> List[str]:
        """è§£æpoetry.lockæ–‡ä»¶"""
        deps = []
        try:
            import tomli
            with open(file_path, 'rb') as f:
                data = tomli.load(f)
                
            if 'package' in data:
                for package in data['package']:
                    if 'name' in package:
                        deps.append(package['name'])
                        
        except ImportError:
            pass
        except Exception:
            pass
            
        return deps
    
    def _infer_dependencies_from_code(self) -> List[str]:
        """ä»ä»£ç ä¸­æ¨æ–­ä¾èµ–åŒ…"""
        deps = set()
        
        # å¸¸è§çš„ç¬¬ä¸‰æ–¹åŒ…æ˜ å°„
        import_to_package = {
            'numpy': 'numpy', 'np': 'numpy',
            'pandas': 'pandas', 'pd': 'pandas',
            'requests': 'requests',
            'flask': 'Flask',
            'django': 'Django',
            'fastapi': 'fastapi',
            'click': 'click',
            'rich': 'rich',
            'typer': 'typer',
            'pydantic': 'pydantic',
            'sqlalchemy': 'SQLAlchemy',
            'pytest': 'pytest',
            'matplotlib': 'matplotlib',
            'seaborn': 'seaborn',
            'sklearn': 'scikit-learn',
            'cv2': 'opencv-python',
            'PIL': 'Pillow',
            'yaml': 'PyYAML',
            'dotenv': 'python-dotenv',
            'openai': 'openai',
            'transformers': 'transformers',
            'torch': 'torch',
            'tensorflow': 'tensorflow',
            'streamlit': 'streamlit',
            'gradio': 'gradio'
        }
        
        python_files = list(self.project_dir.rglob('*.py'))
        
        for file_path in python_files[:50]:  # é™åˆ¶æ–‡ä»¶æ•°é‡é¿å…è¿‡æ…¢
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # åŒ¹é…importè¯­å¥
                import_patterns = [
                    r'^import\s+([a-zA-Z_][a-zA-Z0-9_]*)',
                    r'^from\s+([a-zA-Z_][a-zA-Z0-9_]*)\s+import',
                    r'^\s*import\s+([a-zA-Z_][a-zA-Z0-9_]*)',
                    r'^\s*from\s+([a-zA-Z_][a-zA-Z0-9_]*)\s+import'
                ]
                
                for pattern in import_patterns:
                    matches = re.findall(pattern, content, re.MULTILINE)
                    for match in matches:
                        # åªå–ç¬¬ä¸€çº§åŒ…å
                        pkg_name = match.split('.')[0]
                        if pkg_name in import_to_package:
                            deps.add(import_to_package[pkg_name])
                        elif not pkg_name.startswith('_') and len(pkg_name) > 2:
                            # å¯èƒ½æ˜¯ç¬¬ä¸‰æ–¹åŒ…
                            deps.add(pkg_name)
                            
            except Exception:
                continue
                
        return list(deps)
    
    def _detect_other_dependencies(self) -> List[str]:
        """æ£€æµ‹å…¶ä»–ç±»å‹çš„ä¾èµ–"""
        other_deps = []
        
        # Goè¯­è¨€
        if (self.project_dir / 'go.mod').exists():
            other_deps.extend(self._parse_go_mod(self.project_dir / 'go.mod'))
        if (self.project_dir / 'go.sum').exists():
            other_deps.append('Go modules')
            
        # Rustè¯­è¨€
        if (self.project_dir / 'Cargo.toml').exists():
            other_deps.extend(self._parse_cargo_toml(self.project_dir / 'Cargo.toml'))
        if (self.project_dir / 'Cargo.lock').exists():
            other_deps.append('Rust crates')
            
        # Java/Kotlin
        if (self.project_dir / 'pom.xml').exists():
            other_deps.extend(self._parse_maven_pom(self.project_dir / 'pom.xml'))
        if (self.project_dir / 'build.gradle').exists() or (self.project_dir / 'build.gradle.kts').exists():
            other_deps.append('Gradle dependencies')
            
        # C/C++
        if (self.project_dir / 'CMakeLists.txt').exists():
            other_deps.append('CMake')
        if (self.project_dir / 'conanfile.txt').exists() or (self.project_dir / 'conanfile.py').exists():
            other_deps.append('Conan packages')
            
        # Ruby
        if (self.project_dir / 'Gemfile').exists():
            other_deps.extend(self._parse_gemfile(self.project_dir / 'Gemfile'))
            
        # PHP
        if (self.project_dir / 'composer.json').exists():
            other_deps.extend(self._parse_composer_json(self.project_dir / 'composer.json'))
        
        # æ£€æŸ¥Docker
        if (self.project_dir / 'Dockerfile').exists():
            other_deps.append('Docker')
        if (self.project_dir / 'docker-compose.yml').exists():
            other_deps.append('Docker Compose')
            
        # æ£€æŸ¥æ•°æ®åº“
        db_files = ['*.db', '*.sqlite', '*.sqlite3']
        for pattern in db_files:
            if list(self.project_dir.rglob(pattern)):
                other_deps.append('SQLite')
                break
                
        # æ£€æŸ¥é…ç½®æ–‡ä»¶
        config_files = {
            '.env': 'Environment Variables',
            'config.yaml': 'YAML Config',
            'config.yml': 'YAML Config',
            'config.json': 'JSON Config',
            'settings.py': 'Django Settings',
            'manage.py': 'Django',
            'app.py': 'Flask/FastAPI',
            'main.py': 'Python Application',
            'Makefile': 'Make'
        }
        
        for filename, dep_name in config_files.items():
            if (self.project_dir / filename).exists():
                other_deps.append(dep_name)
                
        # æ£€æŸ¥CI/CD
        ci_files = [
            '.github/workflows',
            '.gitlab-ci.yml',
            '.travis.yml',
            'Jenkinsfile',
            '.circleci'
        ]
        
        for ci_file in ci_files:
            if (self.project_dir / ci_file).exists():
                other_deps.append('CI/CD')
                break
                
        return other_deps
        
    def _parse_npm_deps(self, file_path: Path) -> List[str]:
        """è§£æNPMä¾èµ–"""
        deps = []
        filename = file_path.name.lower()
        
        try:
            if filename == 'package.json':
                deps = self._parse_package_json(file_path)
            elif filename == 'package-lock.json':
                deps = self._parse_package_lock(file_path)
            elif filename == 'yarn.lock':
                deps = self._parse_yarn_lock(file_path)
                
        except Exception as e:
            if self.verbose:
                self.console.print(f"[yellow]Warning: Could not parse {file_path}: {e}[/yellow]")
            
        return deps
    
    def _parse_package_json(self, file_path: Path) -> List[str]:
        """è§£æpackage.jsonæ–‡ä»¶"""
        deps = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        # æå–dependencieså’ŒdevDependencies
        for dep_type in ['dependencies', 'devDependencies', 'peerDependencies', 'optionalDependencies']:
            if dep_type in data:
                deps.extend(data[dep_type].keys())
                
        return deps
    
    def _parse_package_lock(self, file_path: Path) -> List[str]:
        """è§£æpackage-lock.jsonæ–‡ä»¶"""
        deps = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        # ä»dependenciesä¸­æå–
        if 'dependencies' in data:
            deps.extend(data['dependencies'].keys())
        elif 'packages' in data:
            # npm v7+ æ ¼å¼
            for pkg_path, pkg_info in data['packages'].items():
                if pkg_path.startswith('node_modules/'):
                    pkg_name = pkg_path.replace('node_modules/', '')
                    deps.append(pkg_name)
                    
        return deps
    
    def _parse_yarn_lock(self, file_path: Path) -> List[str]:
        """è§£æyarn.lockæ–‡ä»¶"""
        deps = set()
        
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        # åŒ¹é…åŒ…åæ¨¡å¼
        # yarn.lockæ ¼å¼: "package-name@version":
        pkg_patterns = [
            r'^"?([a-zA-Z0-9@/_-]+)@',
            r'^([a-zA-Z0-9@/_-]+)@'
        ]
        
        for pattern in pkg_patterns:
            matches = re.findall(pattern, content, re.MULTILINE)
            for match in matches:
                # æ¸…ç†åŒ…å
                pkg_name = match.split('@')[0] if '@' in match else match
                if pkg_name and not pkg_name.startswith('.'):
                    deps.add(pkg_name)
                    
        return list(deps)
    
    def _parse_go_mod(self, file_path: Path) -> List[str]:
        """è§£ægo.modæ–‡ä»¶"""
        deps = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åŒ¹é…requireå—ä¸­çš„ä¾èµ–
            require_pattern = r'require\s*\(([^)]+)\)'
            require_match = re.search(require_pattern, content, re.DOTALL)
            if require_match:
                require_block = require_match.group(1)
                # åŒ¹é…æ¯ä¸ªä¾èµ–è¡Œ
                dep_pattern = r'([a-zA-Z0-9./\\-_]+)\s+v[0-9.]+'
                deps.extend(re.findall(dep_pattern, require_block))
            
            # åŒ¹é…å•è¡Œrequire
            single_require_pattern = r'require\s+([a-zA-Z0-9./\\-_]+)\s+v[0-9.]+'
            deps.extend(re.findall(single_require_pattern, content))
            
        except Exception as e:
            if self.verbose:
                self.console.print(f"[yellow]Warning: Could not parse {file_path}: {e}[/yellow]")
        
        return deps
    
    def _parse_cargo_toml(self, file_path: Path) -> List[str]:
        """è§£æCargo.tomlæ–‡ä»¶"""
        deps = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å°è¯•ä½¿ç”¨tomliè§£æ
            try:
                import tomli
                data = tomli.loads(content)
                
                # æå–dependencies
                for dep_type in ['dependencies', 'dev-dependencies', 'build-dependencies']:
                    if dep_type in data:
                        deps.extend(data[dep_type].keys())
                        
            except ImportError:
                # ç®€å•çš„æ­£åˆ™åŒ¹é…
                dep_pattern = r'^([a-zA-Z0-9_\\-]+)\s*='
                in_deps_section = False
                
                for line in content.split('\n'):
                    line = line.strip()
                    if line.startswith('[dependencies') or line.startswith('[dev-dependencies') or line.startswith('[build-dependencies'):
                        in_deps_section = True
                        continue
                    elif line.startswith('[') and in_deps_section:
                        in_deps_section = False
                        continue
                    elif in_deps_section and '=' in line:
                        match = re.match(dep_pattern, line)
                        if match:
                            deps.append(match.group(1))
                            
        except Exception as e:
            if self.verbose:
                self.console.print(f"[yellow]Warning: Could not parse {file_path}: {e}[/yellow]")
        
        return deps
    
    def _parse_maven_pom(self, file_path: Path) -> List[str]:
        """è§£æMaven pom.xmlæ–‡ä»¶"""
        deps = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åŒ¹é…dependencyæ ‡ç­¾ä¸­çš„artifactId
            artifact_pattern = r'<artifactId>([^<]+)</artifactId>'
            deps.extend(re.findall(artifact_pattern, content))
            
        except Exception as e:
            if self.verbose:
                self.console.print(f"[yellow]Warning: Could not parse {file_path}: {e}[/yellow]")
        
        return deps
    
    def _parse_gemfile(self, file_path: Path) -> List[str]:
        """è§£æRuby Gemfile"""
        deps = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åŒ¹é…gemå£°æ˜
            gem_pattern = r"gem\s+['\"]([^'\"]+)['\"]"
            deps.extend(re.findall(gem_pattern, content))
            
        except Exception as e:
            if self.verbose:
                self.console.print(f"[yellow]Warning: Could not parse {file_path}: {e}[/yellow]")
        
        return deps
    
    def _parse_composer_json(self, file_path: Path) -> List[str]:
        """è§£æPHP composer.jsonæ–‡ä»¶"""
        deps = []
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æå–requireå’Œrequire-dev
            for dep_type in ['require', 'require-dev']:
                if dep_type in data:
                    deps.extend(data[dep_type].keys())
                    
        except Exception as e:
            if self.verbose:
                self.console.print(f"[yellow]Warning: Could not parse {file_path}: {e}[/yellow]")
        
        return deps
        
    def _parse_pyproject_scripts(self, file_path: Path) -> List[str]:
        """è§£æpyproject.tomlä¸­çš„è„šæœ¬"""
        scripts = []
        
        try:
            import tomli
            with open(file_path, 'rb') as f:
                data = tomli.load(f)
                
            # æå–project.scripts
            project_scripts = data.get('project', {}).get('scripts', {})
            scripts.extend(project_scripts.keys())
            
        except ImportError:
            # ç®€å•è§£æ
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                scripts_match = re.search(r'\[project\.scripts\](.*?)(?=\[|$)', content, re.DOTALL)
                if scripts_match:
                    scripts_section = scripts_match.group(1)
                    for line in scripts_section.split('\n'):
                        if '=' in line:
                            script_name = line.split('=')[0].strip()
                            if script_name:
                                scripts.append(script_name)
                                
        except Exception as e:
            self.console.print(f"[yellow]Warning: Could not parse pyproject.toml: {e}[/yellow]")
            
        return scripts
        
    def _parse_setup_scripts(self, file_path: Path) -> List[str]:
        """è§£æsetup.pyä¸­çš„è„šæœ¬"""
        scripts = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # ç®€å•çš„æ­£åˆ™åŒ¹é…entry_points
            entry_points_match = re.search(r'entry_points\s*=\s*{(.*?)}', content, re.DOTALL)
            if entry_points_match:
                entry_points_str = entry_points_match.group(1)
                console_scripts_match = re.search(r'["\']console_scripts["\']\s*:\s*\[(.*?)\]', entry_points_str, re.DOTALL)
                if console_scripts_match:
                    console_scripts = console_scripts_match.group(1)
                    for line in console_scripts.split(','):
                        line = line.strip().strip('"\'')
                        if '=' in line:
                            script_name = line.split('=')[0].strip()
                            scripts.append(script_name)
                            
        except Exception as e:
            self.console.print(f"[yellow]Warning: Could not parse setup.py: {e}[/yellow]")
            
        return scripts


class APIDocumentationFilter:
    """APIæ–‡æ¡£ç­›é€‰å™¨ - å†³å®šå“ªäº›å‡½æ•°å€¼å¾—ç”Ÿæˆæ–‡æ¡£"""
    
    def __init__(self):
        # ä½ä»·å€¼å‡½æ•°çš„ç‰¹å¾æ¨¡å¼
        self.low_value_patterns = [
            r'^test_.*',  # æµ‹è¯•å‡½æ•°
            r'^_.*',      # æ‰€æœ‰ç§æœ‰å‡½æ•°ï¼ˆä»¥_å¼€å¤´ï¼‰
            r'.*temp.*',  # ä¸´æ—¶å‡½æ•°
            r'.*junk.*',  # åƒåœ¾å‡½æ•°
            r'.*debug.*', # è°ƒè¯•å‡½æ•°
            r'.*tmp.*',   # ä¸´æ—¶å‡½æ•°
            r'^Mock.*',   # Mockç±»
            r'^Test.*',   # æµ‹è¯•ç±»
        ]
        
        # ä½ä»·å€¼æ–‡ä»¶æ¨¡å¼
        self.low_value_files = [
            r'.*test.*\.py$',
            r'.*temp.*\.py$',
            r'.*junk.*\.py$',
            r'.*debug.*\.py$',
            r'setup\.py$',
            r'conftest\.py$',
        ]
        
    def filter_valuable_apis(self, functions: List[Dict], classes: List[Dict]) -> List[Dict]:
        """ç­›é€‰æœ‰ä»·å€¼çš„API"""
        valuable_apis = []
        
        # ç­›é€‰å‡½æ•°
        for func in functions:
            if self._is_valuable_function(func):
                valuable_apis.append({
                    'type': 'function',
                    'name': func['name'],
                    'module': func['module'],
                    'definition': func['definition'],
                    'context': func['context'],
                    'metadata': func['metadata']
                })
                
        # ç­›é€‰ç±»
        for cls in classes:
            if self._is_valuable_class(cls):
                valuable_apis.append({
                    'type': 'class',
                    'name': cls['name'],
                    'module': cls['module'],
                    'definition': cls['definition'],
                    'context': cls['context'],
                    'metadata': cls['metadata']
                })
                
        return valuable_apis
        
    def _is_valuable_function(self, func: Dict) -> bool:
        """åˆ¤æ–­å‡½æ•°æ˜¯å¦æœ‰ä»·å€¼"""
        name = func['name']
        file_path = func.get('file_path', '')
        
        # æ£€æŸ¥å‡½æ•°åæ¨¡å¼
        for pattern in self.low_value_patterns:
            if re.match(pattern, name, re.IGNORECASE):
                return False
                
        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ¨¡å¼
        for pattern in self.low_value_files:
            if re.search(pattern, file_path, re.IGNORECASE):
                return False
                
        # æ£€æŸ¥å‡½æ•°å¤æ‚åº¦å’Œæ–‡æ¡£è´¨é‡
        if self._is_trivial_function(func):
            return False
            
        return True
        
    def _is_valuable_class(self, cls: Dict) -> bool:
        """åˆ¤æ–­ç±»æ˜¯å¦æœ‰ä»·å€¼"""
        name = cls['name']
        file_path = cls.get('file_path', '')
        
        # æ£€æŸ¥ç±»åæ¨¡å¼
        for pattern in self.low_value_patterns:
            if re.match(pattern, name, re.IGNORECASE):
                return False
                
        # æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ¨¡å¼
        for pattern in self.low_value_files:
            if re.search(pattern, file_path, re.IGNORECASE):
                return False
                
        return True
        
    def _is_trivial_function(self, func: Dict) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç®€å•çš„è¾…åŠ©å‡½æ•°"""
        # æ£€æŸ¥å‡½æ•°è¡Œæ•°ã€å¤æ‚åº¦ç­‰
        lines = func.get('lines', 0)
        if lines < 5:  # è¿‡äºç®€å•çš„å‡½æ•°
            return True
            
        # æ£€æŸ¥æ˜¯å¦åªæ˜¯ç®€å•çš„getter/setter
        definition = func.get('definition', '')
        if 'return self.' in definition and lines < 8:
            return True
            
        # è¿‡æ»¤æ‰ä¸€äº›å†…éƒ¨å·¥å…·å‡½æ•°
        name = func.get('name', '')
        if any(keyword in name.lower() for keyword in ['helper', 'util', 'internal', 'format', 'parse', 'extract']):
            return True
            
        return False


class APIDocumentationGenerator:
    """APIæ–‡æ¡£ç”Ÿæˆå™¨ - ä¸ºå•ä¸ªAPIç”Ÿæˆè¯¦ç»†æ–‡æ¡£"""
    
    def __init__(self, model_client: ModelClient, debug: bool = False):
        self.model_client = model_client
        self.debug = debug
        
    def generate_api_documentation(self, definition: str, context: str, metadata: Dict) -> str:
        """ä¸ºå•ä¸ªAPIç”Ÿæˆè¯¦ç»†çš„markdownæ–‡æ¡£"""
        if self.debug:
            # Debugæ¨¡å¼ä¸‹è·³è¿‡å¤§æ¨¡å‹è°ƒç”¨ï¼Œè¿”å›ç®€å•çš„APIæ–‡æ¡£
            return self._generate_debug_api_documentation(definition, context, metadata)
        
        # æ£€æŸ¥model_clientæ˜¯å¦å¯ç”¨
        if self.model_client is None:
            return self._generate_debug_api_documentation(definition, context, metadata)
        
        prompt = self._create_api_documentation_prompt(definition, context, metadata)
        return self.model_client.generate_text(prompt)
    
    def _generate_debug_api_documentation(self, definition: str, context: str, metadata: Dict) -> str:
        """åœ¨debugæ¨¡å¼ä¸‹ç”Ÿæˆç®€å•çš„APIæ–‡æ¡£"""
        api_name = metadata.get('name', 'Unknown API')
        api_type = metadata.get('type', 'function')
        
        return f"""## {api_name}

**ç±»å‹**: {api_type}

### åŠŸèƒ½æè¿°
è¿™æ˜¯ä¸€ä¸ª{api_type}ï¼Œå…·ä½“åŠŸèƒ½è¯·å‚è€ƒæºä»£ç ã€‚

### æºä»£ç 
```python
{definition}
```

### ä½¿ç”¨ç¤ºä¾‹
```python
# ç¤ºä¾‹ä»£ç 
# è¯·æ ¹æ®å®é™…æƒ…å†µè°ƒç”¨æ­¤{api_type}
```

*æ³¨æ„ï¼šæ­¤æ–‡æ¡£åœ¨è°ƒè¯•æ¨¡å¼ä¸‹ç”Ÿæˆï¼Œå†…å®¹å¯èƒ½ä¸å®Œæ•´ã€‚*
"""
        
    def _create_api_documentation_prompt(self, definition: str, context: str, metadata: Dict) -> str:
        """åˆ›å»ºAPIæ–‡æ¡£ç”Ÿæˆçš„æç¤ºè¯"""
        return f"""
è¯·ä¸ºä»¥ä¸‹å‡½æ•°/ç±»ç”Ÿæˆè¯¦ç»†çš„APIæ–‡æ¡£ï¼ŒåŒ…æ‹¬ï¼š

1. åŠŸèƒ½æè¿°
2. å‚æ•°è¯´æ˜ï¼ˆç±»å‹ã€æè¿°ã€é»˜è®¤å€¼ï¼‰
3. è¿”å›å€¼è¯´æ˜ï¼ˆç±»å‹ã€æè¿°ï¼‰
4. æºä»£ç ï¼ˆåœ¨å•ç‹¬çš„ä»£ç å—ä¸­æ˜¾ç¤ºå®Œæ•´çš„å‡½æ•°/ç±»ä»£ç ï¼ŒåŒ…å«æ­£å¸¸çš„Pythonè¯­æ³•é«˜äº®ï¼‰
5. ä½¿ç”¨ç¤ºä¾‹
6. æ³¨æ„äº‹é¡¹

å‡½æ•°/ç±»å®šä¹‰ï¼š
```python
{definition}
```

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{context}

å…ƒæ•°æ®ï¼š
{json.dumps(metadata, indent=2, ensure_ascii=False)}

è¯·ç”Ÿæˆmarkdownæ ¼å¼çš„æ–‡æ¡£ï¼Œç¡®ä¿åœ¨"æºä»£ç "éƒ¨åˆ†åŒ…å«ä¸€ä¸ªç‹¬ç«‹çš„ä»£ç å—ï¼Œæ˜¾ç¤ºå®Œæ•´çš„å‡½æ•°/ç±»æºä»£ç å¹¶å¸¦æœ‰Pythonè¯­æ³•é«˜äº®ï¼š
"""