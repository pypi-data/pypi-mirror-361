Metadata-Version: 2.4
Name: mono-kit
Version: 0.1.4
Summary: ML toolkit for developers to build document, audio, and image similarity retrieval systems with pretrained and finetunable models‚Äîready to use out of the box.
Description-Content-Type: text/markdown
Requires-Dist: chromadb==1.0.13
Requires-Dist: librosa==0.11.0
Requires-Dist: tensorflow_hub==0.16.1
Requires-Dist: tensorflow==2.19.0
Requires-Dist: semantic_text_splitter==0.27.0
Requires-Dist: numpy==2.1.3
Requires-Dist: Pillow==11.2.1
Dynamic: description
Dynamic: description-content-type
Dynamic: requires-dist
Dynamic: summary


# üìö Mono-Kit Library Documentation

**`mono-kit`** is a versatile machine learning library designed to help developers build advanced **similarity retrieval systems** such as **Google Lens (image similarity retrieval)**, **hum-to-search (audio similarity retrieval)**, and **RAG-style retrieval systems**. It supports **document**, **audio**, and **image** inputs, offering a suite of pretrained embedding models as well as finetunable custom built-in models. With `mono-kit`, you can perform similarity-based retrieval effortlessly‚Äîno need to implement complex pipelines. Everything you need comes ready to use, right out of the box.

## Available Models

`mono-kit` comes with powerful, production-ready models tailored for each modality:

- **Image**  
  - **Default**: `ResNet-50`  
  - **Custom**: Finetunable customized `ResNet-50` for domain-specific tasks

- **Audio**  
  - **Default**: `VGGish`  
  - **Custom**: Finetunable custom **Siamese network** with a **custom loss function** for enhanced similarity learning

- **Document**  
  - **Default**: `all-MiniLM-L6-v2` ‚Äì a compact and efficient transformer model ideal for semantic document embeddings


---

## üì¶ Installation

Install the library via pip:

```bash

pip install mono-kit

```


## üîß Initialization

`mono-kit` uses **ChromaDB** by default for embedding storage and retrieval.

Start by initializing a `chromadb` client:

```python
import chromadb

client = chromadb.PersistentClient(path="path_to_save")
```

> ‚úÖ **You can use any `chromadb` client (e.g., `EphemeralClient`, `HttpClient`, etc.), not just `PersistentClient`.**

> ‚ö†Ô∏è **Collection Name Constraint:**
> Each of `mono_document`, `mono_audio`, and `mono_image` **must use unique collection names**.
> You can reuse a collection name across default and custom models.

---

## üìù Text Search: `mono_document`

### 1. Initialize Document Handler

```python
mono_docs = mono_document(client, "unique_text_collection")
```

### 2. Text Splitting and Mounting

```python
text = """Your long text block here..."""
docs = mono_docs.text_splitter(text, (150, 200), 20, False)

for id, doc in enumerate(docs):
    mono_docs.mount_document(doc, str(id))
```

* `(150, 200)`: Min/max character chunk size
* `20`: Overlap in characters
* `False`: If `True`, will retain sentence boundaries (optional feature)

### 3. Semantic Search

```python
result = mono_docs.find_similar_documents("search query here", k=3)
print(result)
```

---

## üîä Audio Search: `mono_audio`

### 1. Initialize Audio Handler

```python
mono_aud = mono_audio(client, "unique_audio_collection")
```

### 2. Mount Audio Files

```python
mono_aud.mount_audio("path/to/audio1.mp3")
mono_aud.mount_audio("path/to/audio2.mp3")
```

### 3. Batch Mounting

```python
mono_aud.mount_audio_batch("path/to/audio_directory")
```

### 4. Find Similar Audio

```python
result = mono_aud.find_similar_audio("path/to/query.mp3", k=3)
print(result)
```

---

### ‚úÖ With Custom Audio Model

#### 1. Train Custom Audio Model

```python
x = "path/to/reference_audio"
y = "path/to/target_audio"
mono_aud.create_audio_model(directory_x=x, directory_y=y)
```

#### 2. Mount and Search with Custom Model

```python
model_path = "custom_trained_audio_embedding_model/audio_model.keras"

mono_aud.mount_audio("audio.mp3", model_path=model_path)
mono_aud.mount_audio_batch("audio_directory", model_path=model_path)

result = mono_aud.find_similar_audio("query.mp3", k=2, model_path=model_path)
print(result)
```

---

## üñºÔ∏è Image Search: `mobo_image`

### 1. Initialize Image Handler

```python
mono_img = mono_image(client, "unique_image_collection")
```

### 2. Mount Images

```python
mono_img.mount_image("path/to/image.jpg")
```

### 3. Batch Mounting

```python
mono_img.mount_image_batch("path/to/image_directory")
```

### 4. Find Similar Images

```python
result = mono_img.find_similar_image("path/to/query_image.jpg", k=3)
print(result)
```

---

### ‚úÖ With Custom Image Model

#### 1. Train Custom Image Model

```python
x = "path/to/reference_images"
y = "path/to/target_images"
mono_img.create_image_model(directory_x=x, directory_y=y)
```

#### 2. Mount and Search with Custom Model

```python
model = "/path/to/custom_trained_image_embedding_model/image_model.keras"

mono_img.mount_image_batch("image_directory", model_path=model)

result = mono_img.find_similar_image("query.jpg", k=3, model_path=model)
print(result)
```

---

## ‚úÖ Summary of Key Functions

| Operation          | Document                 | Audio                | Image                |
| ------------------ | ------------------------ | -------------------- | -------------------- |
| Mount file         | `mount_document`         | `mount_audio`        | `mount_image`        |
| Mount batch        | ‚Äî                        | `mount_audio_batch`  | `mount_image_batch`  |
| Similarity search  | `find_similar_documents` | `find_similar_audio` | `find_similar_image` |
| Train custom model | ‚Äî                        | `create_audio_model` | `create_image_model` |
| Use custom model   | ‚Äî                        | via `model_path`     | via `model_path`     |

---

