{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66af76d8-4c64-4d80-bb9a-bae2d96a62e2",
   "metadata": {},
   "source": [
    "# Building the `geosnap` Census data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "female-chosen",
   "metadata": {},
   "source": [
    "This notebook demonstrates internal functions the geosnap team uses to build its curated datasets from the U.S. Census bureau. Most users will not need these, but we include the code here for tranparency and reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395db34b-dcf0-4d14-8dd7-51b7eb26005c",
   "metadata": {},
   "source": [
    "The process is straightforward, designed to do as little data manipulation as possible, and takes place in four steps:\n",
    "\n",
    "1. download bulk data from the Census FTP Server\n",
    "2. rename variables to match the detailed tables API, and reformat data into high efficiency parquet files\n",
    "3. compute additional variables to match the LTDB set and attach geometries\n",
    "4. upload all data to `quilt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b75ee3-2af6-47bf-8b9d-ce63276774fa",
   "metadata": {},
   "source": [
    "As a result, the raw (but efficient!) data are available [here](https://open.quiltdata.com/b/spatial-ucr/tree/census/demographic_profile/), and the convenient data with the most commonly used variables (with simple names) are available [here](https://open.quiltdata.com/b/spatial-ucr/tree/census/acs/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intended-bangkok",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T01:26:21.350297Z",
     "iopub.status.busy": "2021-10-21T01:26:21.349678Z",
     "iopub.status.idle": "2021-10-21T01:26:25.346902Z",
     "shell.execute_reply": "2021-10-21T01:26:25.346074Z",
     "shell.execute_reply.started": "2021-10-21T01:26:21.350192Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ogrio\n",
    "from geosnap.io.util import get_census_gdb_wget, convert_census_gdb\n",
    "from geosnap.util import process_acs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressed-label",
   "metadata": {},
   "source": [
    "The `get_census_gdb` function will fetch geodatabases containing ACS demographic profile data (which contains most of the useful variables) and store them locally for processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae9559-1019-42f5-ba95-d0d93f645573",
   "metadata": {},
   "source": [
    "## 1. Collecting raw data from census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "short-swimming",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-20T21:47:28.812376Z",
     "iopub.status.busy": "2021-10-20T21:47:28.812023Z",
     "iopub.status.idle": "2021-10-20T21:47:28.855777Z",
     "shell.execute_reply": "2021-10-20T21:47:28.855156Z",
     "shell.execute_reply.started": "2021-10-20T21:47:28.812352Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mget_census_gdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myears\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeom_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blockgroup'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Fetch file geodatabases of ACS demographic profile data from the Census bureau server.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "years : list, optional\n",
       "    set of years to download (2010 onward), defaults to 2010-2018\n",
       "geom_level : str, optional\n",
       "    geographic unit to download (tract or blockgroup), by default \"blockgroup\"\n",
       "output_dir : str, optional\n",
       "    output directory to write files, by default None\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Dropbox/projects/geosnap/geosnap/io/util.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_census_gdb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-calvin",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-21T01:26:25.388649Z",
     "iopub.status.busy": "2021-10-21T01:26:25.388336Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D: 35% -  1.3GiB  /  3.6GiB  eta 1:20:255:02:42\r"
     ]
    }
   ],
   "source": [
    "get_census_gdb(years=['2018'],  geom_level='blockgroup', output_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f837e9a-b44a-4feb-85b9-07defae30239",
   "metadata": {},
   "source": [
    "## 2. Converting to efficient data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sound-census",
   "metadata": {},
   "source": [
    "Using `ogrio` we can quickly list all the layers present in the geodatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "martial-amsterdam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ACS_2014_5YR_BG',\n",
       " 'BG_METADATA_2014',\n",
       " 'X00_COUNTS',\n",
       " 'X01_AGE_AND_SEX',\n",
       " 'X02_RACE',\n",
       " 'X03_HISPANIC_OR_LATINO_ORIGIN',\n",
       " 'X07_MIGRATION',\n",
       " 'X08_COMMUTING',\n",
       " 'X09_CHILDREN_HOUSEHOLD_RELATIONSHIP',\n",
       " 'X11_HOUSEHOLD_FAMILY_SUBFAMILIES',\n",
       " 'X12_MARITAL_STATUS_AND_HISTORY',\n",
       " 'X14_SCHOOL_ENROLLMENT',\n",
       " 'X15_EDUCATIONAL_ATTAINMENT',\n",
       " 'X16_LANGUAGE_SPOKEN_AT_HOME',\n",
       " 'X17_POVERTY',\n",
       " 'X19_INCOME',\n",
       " 'X20_EARNINGS',\n",
       " 'X21_VETERAN_STATUS',\n",
       " 'X22_FOOD_STAMPS',\n",
       " 'X23_EMPLOYMENT_STATUS',\n",
       " 'X24_INDUSTRY_OCCUPATION',\n",
       " 'X27_HEALTH_INSURANCE',\n",
       " 'X99_IMPUTATION',\n",
       " 'X25_HOUSING_CHARACTERISTICS']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns an array of arrays, with the inner = [name, geometry]\n",
    "# we only need the name\n",
    "[layer[0] fpr layer in ogrio.list_layers(\"ACS_2018_5YR_BG.gdb.zip\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-mediterranean",
   "metadata": {},
   "source": [
    "File geodatabases can be convient, but they are also painfuly slow to process in python, so the `convert_census_gdb` will convert the layers in a gdb to a parquet file instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "novel-vinyl",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mconvert_census_gdb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0myear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msave_intermediate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Convert file geodatabases from Census into (set of) parquet files.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "file : str\n",
       "    path to file geodatabase\n",
       "layers : list\n",
       "    set of layers to extract from gdb\n",
       "year : str, optional\n",
       "    [description], by default None\n",
       "level : str, optional\n",
       "    geographic level of data ('bg' for blockgroups or 'tr' for tract), by default \"bg\"\n",
       "save_intermediate : bool, optional\n",
       "    if true, each layer will be stored separately as a parquet file, by default True\n",
       "output_dir : str, optional\n",
       "    path to directory where parquet files will be written, by default \".\"\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Dropbox/projects/geosnap/geosnap/io/util.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "convert_census_gdb?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "divine-encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X00_COUNTS\n"
     ]
    }
   ],
   "source": [
    "convert_census_gdb(file='ACS_2014_5YR_BG.gdb.zip', save_intermediate=True, layers=['X00_COUNTS'], year='2014', level='tract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "powered-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "confident-perry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B00001_001E</th>\n",
       "      <th>B00002_001E</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEOID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15000US020130001001</th>\n",
       "      <td>283.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000US020130001002</th>\n",
       "      <td>410.0</td>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000US020130001003</th>\n",
       "      <td>473.0</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000US020160001001</th>\n",
       "      <td>418.0</td>\n",
       "      <td>486.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000US020160002001</th>\n",
       "      <td>561.0</td>\n",
       "      <td>211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000US560459511001</th>\n",
       "      <td>223.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000US560459511002</th>\n",
       "      <td>234.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000US560459513001</th>\n",
       "      <td>95.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000US560459513002</th>\n",
       "      <td>92.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000US560459513003</th>\n",
       "      <td>125.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>220333 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     B00001_001E  B00002_001E\n",
       "GEOID                                        \n",
       "15000US020130001001        283.0         89.0\n",
       "15000US020130001002        410.0        138.0\n",
       "15000US020130001003        473.0        183.0\n",
       "15000US020160001001        418.0        486.0\n",
       "15000US020160002001        561.0        211.0\n",
       "...                          ...          ...\n",
       "15000US560459511001        223.0        124.0\n",
       "15000US560459511002        234.0         63.0\n",
       "15000US560459513001         95.0         46.0\n",
       "15000US560459513002         92.0         46.0\n",
       "15000US560459513003        125.0         50.0\n",
       "\n",
       "[220333 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet('acs_2014_X00_COUNTS_tract.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbfc4d9-2ea1-4bbc-a677-b14c62ee2889",
   "metadata": {},
   "source": [
    "## 3. Computing intermediate variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-strength",
   "metadata": {},
   "source": [
    "The resulting (combined) parquet files can be processed with `process_acs` to generate the datasets described in the geosnap codebook. For each year, we merge all the files for a single geography into a single, massive dataset, then compute any variables we need and keeping that subset. \n",
    "\n",
    "\n",
    "Note, unless *all* layers are processed from the geodatabase, several variables will be unavailable. You can merge them all together with something like the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0dbc5c-52b3-4ab7-aa3b-115ad27bed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for file in [file for file in os.listdir(\"/Users/knaaptime/Dropbox/projects/geosnap/data/census/2019/\") if file.endswith('bg.parquet')]:\n",
    "    if not file not in ['acs_2019_bg.parquet', 'acs_2019_ACS_2019_5YR_BG_bg.parquet']:\n",
    "        df = gpd.read_parquet(\"/Users/knaaptime/Dropbox/projects/geosnap/data/census/2019/\"+file)\n",
    "        dfs.append(df)\n",
    "df = pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-sharing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_acs(df.reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c54152b-3a89-453e-9147-527265ca94d4",
   "metadata": {},
   "source": [
    "to complete the process, you need to merge the geometries(`acs_{year}_ACS_{year}_5YR_{geom_level}_{geom_level}.parquet`) with the processed variables (`df`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5e4ac-9544-447d-825a-cd832b794b90",
   "metadata": {},
   "source": [
    "## 4. Uploading to quilt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fa6164-813c-406c-9b2f-e7703e5e5d18",
   "metadata": {},
   "source": [
    "Follow the [packaging instructions](https://docs.quiltdata.com/walkthrough/uploading-a-package) from `quilt`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc99b6e8-c8c5-4dae-9358-2652461603df",
   "metadata": {},
   "source": [
    "To authenticate to the spatial-ucr s3 server, you need to have the `.aws` config file with auth parameters in your home directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55663bef-3f4d-4a07-a623-e3bf07304f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geosnap]",
   "language": "python",
   "name": "conda-env-geosnap-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
