#!/usr/bin/env python3
"""
aria3å¤šçº¿ç¨‹ä¸‹è½½å™¨çš„å‘½ä»¤è¡Œç•Œé¢ã€‚

æœ¬æ¨¡å—ä¸ºä½¿ç”¨aria3åº“åŠå…¶æ‰€æœ‰é«˜çº§åŠŸèƒ½ä¸‹è½½æ–‡ä»¶æä¾›å‘½ä»¤è¡Œç•Œé¢ã€‚
"""

import argparse
import json
import logging
import os
import sys
from pathlib import Path
from typing import List, Dict, Any

# å¦‚æœç›´æ¥è¿è¡Œï¼Œå°†srcç›®å½•æ·»åŠ åˆ°è·¯å¾„
if __name__ == '__main__':
    sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from .downloader import MultiThreadDownloader, DownloadConfig
except ImportError:
    from aria3.downloader import MultiThreadDownloader, DownloadConfig


def parse_headers(header_strings: List[str]) -> Dict[str, str]:
    """å°†æ ¼å¼ä¸º'Key: Value'çš„è¯·æ±‚å¤´å­—ç¬¦ä¸²è§£æä¸ºå­—å…¸ã€‚"""
    headers = {}
    for header_str in header_strings:
        if ':' in header_str:
            key, value = header_str.split(':', 1)
            headers[key.strip()] = value.strip()
        else:
            print(f"è­¦å‘Š: æ— æ•ˆçš„è¯·æ±‚å¤´æ ¼å¼ '{header_str}'ï¼ŒæœŸæœ›æ ¼å¼ä¸º 'Key: Value'")
    return headers


def parse_cookies(cookie_strings: List[str]) -> Dict[str, str]:
    """å°†æ ¼å¼ä¸º'name=value'çš„Cookieå­—ç¬¦ä¸²è§£æä¸ºå­—å…¸ã€‚"""
    cookies = {}
    for cookie_str in cookie_strings:
        if '=' in cookie_str:
            name, value = cookie_str.split('=', 1)
            cookies[name.strip()] = value.strip()
        else:
            print(f"è­¦å‘Š: æ— æ•ˆçš„Cookieæ ¼å¼ '{cookie_str}'ï¼ŒæœŸæœ›æ ¼å¼ä¸º 'name=value'")
    return cookies


def setup_logging(verbose: bool, quiet: bool) -> None:
    """æ ¹æ®è¯¦ç»†ç¨‹åº¦æ ‡å¿—è®¾ç½®æ—¥å¿—è®°å½•ã€‚"""
    if quiet:
        level = logging.ERROR
    elif verbose:
        level = logging.DEBUG
    else:
        level = logging.INFO

    logging.basicConfig(
        level=level,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )


def create_config(args: argparse.Namespace) -> DownloadConfig:
    """ä»å‘½ä»¤è¡Œå‚æ•°åˆ›å»ºDownloadConfigã€‚"""
    headers = parse_headers(args.headers) if args.headers else {}
    cookies = parse_cookies(args.cookies) if args.cookies else {}

    return DownloadConfig(
        max_chunk_size=args.chunk_size,
        max_threads=args.threads,
        timeout=args.timeout,
        retry_attempts=args.retries,
        retry_delay=args.retry_delay,
        speed_threshold=args.speed_threshold,
        headers=headers,
        cookies=cookies,
        user_agent=args.user_agent
    )


def download_command(args: argparse.Namespace) -> int:
    """æ‰§è¡Œä¸‹è½½å‘½ä»¤ã€‚"""
    # å¦‚æœè¾“å‡ºç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»º
    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # åˆ›å»ºé…ç½®
    config = create_config(args)

    # åˆ›å»ºä¸‹è½½å™¨
    downloader = MultiThreadDownloader(config)

    # æ·»åŠ å¸¦ä¼˜å…ˆçº§çš„æº
    if args.priorities:
        if len(args.priorities) != len(args.urls):
            print("é”™è¯¯: ä¼˜å…ˆçº§æ•°é‡å¿…é¡»ä¸URLæ•°é‡åŒ¹é…")
            return 1
        priorities = args.priorities
    else:
        priorities = [1.0] * len(args.urls)

    downloader.add_sources(args.urls, priorities)

    # å¼€å§‹ä¸‹è½½
    print(f"å¼€å§‹ä¸‹è½½åˆ°: {args.output}")
    print(f"æºæ•°é‡: {len(args.urls)}")
    print(f"æœ€å¤§çº¿ç¨‹æ•°: {args.threads}")
    print(f"å—å¤§å°: {args.chunk_size // 1024}KB")

    success = downloader.download(str(output_path))
    
    if success:
        print(f"\nâœ“ ä¸‹è½½æˆåŠŸå®Œæˆ: {args.output}")

        if args.stats:
            # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
            info = downloader.get_download_info()
            print("\nä¸‹è½½ç»Ÿè®¡:")
            print(f"  æ€»å¤§å°: {info['total_size']} å­—èŠ‚")
            print(f"  å·²ä¸‹è½½: {info['downloaded']} å­—èŠ‚")
            print(f"  å¹³å‡é€Ÿåº¦: {info['speed']:.2f} å­—èŠ‚/ç§’")

            print("\næºç»Ÿè®¡:")
            for i, source in enumerate(info['sources']):
                print(f"  æº {i+1}:")
                print(f"    URL: {source['url']}")
                print(f"    ä¼˜å…ˆçº§: {source['priority']:.2f}")
                print(f"    é€Ÿåº¦: {source['speed']:.2f} å­—èŠ‚/ç§’")
                print(f"    å·²ä¸‹è½½: {source['downloaded']} å­—èŠ‚")
                print(f"    å¤±è´¥æ¬¡æ•°: {source['failures']}")

        return 0
    else:
        print("\nâœ— ä¸‹è½½å¤±è´¥")
        return 1


def info_command(args: argparse.Namespace) -> int:
    """æ‰§è¡Œinfoå‘½ä»¤è·å–æ–‡ä»¶ä¿¡æ¯ã€‚"""
    config = create_config(args)
    downloader = MultiThreadDownloader(config)

    print(f"æ­£åœ¨ä»ä»¥ä¸‹åœ°å€è·å–æ–‡ä»¶ä¿¡æ¯: {args.url}")

    try:
        file_size, supports_ranges = downloader._get_file_info(args.url)

        print(f"\næ–‡ä»¶ä¿¡æ¯:")
        print(f"  URL: {args.url}")
        print(f"  å¤§å°: {file_size} å­—èŠ‚ ({file_size / 1024 / 1024:.2f} MB)")
        print(f"  æ”¯æŒèŒƒå›´è¯·æ±‚: {'æ˜¯' if supports_ranges else 'å¦'}")

        if supports_ranges:
            estimated_chunks = max(1, file_size // config.max_chunk_size)
            print(f"  é¢„è®¡å—æ•°: {estimated_chunks}")

        return 0

    except Exception as e:
        print(f"è·å–æ–‡ä»¶ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        return 1


def main():
    """ä¸»CLIå…¥å£ç‚¹ã€‚"""
    try:
        return _main_impl()
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
        return 130  # æ ‡å‡†çš„SIGINTé€€å‡ºç 

def _main_impl():
    """ä¸»CLIå®ç°ã€‚"""
    parser = argparse.ArgumentParser(
        description="aget - é«˜çº§å¤šçº¿ç¨‹ä¸‹è½½å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ç®€å•ä¸‹è½½
  aget download https://example.com/file.zip output.zip

  # ä½¿ç”¨è‡ªå®šä¹‰è®¾ç½®çš„å¤šæºä¸‹è½½
  aget download -t 8 -c 2048 https://mirror1.com/file.zip https://mirror2.com/file.zip output.zip

  # ä½¿ç”¨è‡ªå®šä¹‰è¯·æ±‚å¤´å’ŒCookieä¸‹è½½
  aget download -H "Authorization: Bearer token" -C "session=abc123" https://api.example.com/file output

  # è·å–æ–‡ä»¶ä¿¡æ¯
  aget info https://example.com/largefile.zip
        """
    )
    
    # å…¨å±€é€‰é¡¹
    parser.add_argument('-v', '--verbose', action='store_true', help='è¯¦ç»†è¾“å‡º')
    parser.add_argument('-q', '--quiet', action='store_true', help='å®‰é™è¾“å‡ºï¼ˆä»…é”™è¯¯ï¼‰')

    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')

    # ä¸‹è½½å‘½ä»¤
    download_parser = subparsers.add_parser('download', help='ä¸‹è½½æ–‡ä»¶')
    download_parser.add_argument('urls', nargs='+', help='æºURL')
    download_parser.add_argument('output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    
    # Download options
    download_parser.add_argument('-t', '--threads', type=int, default=4,
                                help='Maximum number of threads (default: 4)')
    download_parser.add_argument('-c', '--chunk-size', type=int, default=1024*1024,
                                help='Maximum chunk size in bytes (default: 1MB)')
    download_parser.add_argument('--timeout', type=int, default=30,
                                help='Request timeout in seconds (default: 30)')
    download_parser.add_argument('--retries', type=int, default=3,
                                help='Number of retry attempts (default: 3)')
    download_parser.add_argument('--retry-delay', type=float, default=1.0,
                                help='Delay between retries in seconds (default: 1.0)')
    download_parser.add_argument('--speed-threshold', type=float, default=1024,
                                help='Speed threshold for slow sources in bytes/s (default: 1024)')
    download_parser.add_argument('-H', '--headers', action='append',
                                help='Custom headers in format "Key: Value"')
    download_parser.add_argument('-C', '--cookies', action='append',
                                help='Custom cookies in format "name=value"')
    download_parser.add_argument('--user-agent', default='aget/1.0',
                                help='User agent string (default: aget/1.0)')
    download_parser.add_argument('-p', '--priorities', type=float, nargs='+',
                                help='Priority for each URL (default: 1.0 for all)')
    download_parser.add_argument('--stats', action='store_true',
                                help='Show detailed download statistics')
    
    # Info command
    info_parser = subparsers.add_parser('info', help='Get file information')
    info_parser.add_argument('url', help='File URL')
    info_parser.add_argument('--timeout', type=int, default=30,
                            help='Request timeout in seconds (default: 30)')
    info_parser.add_argument('-H', '--headers', action='append',
                            help='Custom headers in format "Key: Value"')
    info_parser.add_argument('-C', '--cookies', action='append',
                            help='Custom cookies in format "name=value"')
    info_parser.add_argument('--user-agent', default='aget/1.0',
                            help='User agent string (default: aget/1.0)')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return 1
    
    # Set up logging
    setup_logging(args.verbose, args.quiet)
    
    # Execute command
    if args.command == 'download':
        return download_command(args)
    elif args.command == 'info':
        return info_command(args)
    else:
        print(f"Unknown command: {args.command}")
        return 1


if __name__ == '__main__':
    sys.exit(main())
