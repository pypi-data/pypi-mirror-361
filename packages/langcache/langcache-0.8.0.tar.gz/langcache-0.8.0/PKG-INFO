Metadata-Version: 2.3
Name: langcache
Version: 0.8.0
Summary: Python Client SDK for LangCache Redis Service
Author: Redis AI Services Team
Requires-Python: >=3.9.2
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Dist: httpcore (>=1.0.9)
Requires-Dist: httpx (>=0.28.1)
Requires-Dist: pydantic (>=2.11.2)
Project-URL: Repository, https://github.com/redis/langcache-sdks.git
Description-Content-Type: text/markdown

# langcache

Developer-friendly & type-safe Python SDK specifically catered to leverage *langcache* API.

<div align="left">
    <a href="https://www.speakeasy.com/?utm_source=langcache&utm_campaign=python"><img src="https://custom-icon-badges.demolab.com/badge/-Built%20By%20Speakeasy-212015?style=for-the-badge&logoColor=FBE331&logo=speakeasy&labelColor=545454" /></a>
    <a href="https://opensource.org/licenses/MIT">
        <img src="https://img.shields.io/badge/License-MIT-blue.svg" style="width: 100px; height: 28px;" />
    </a>
</div>


<br /><br />
> [!IMPORTANT]
> This SDK is not yet ready for production use. To complete setup please follow the steps outlined in your [workspace](https://app.speakeasy.com/org/redis/ai-services). Delete this section before > publishing to a package manager.

<!-- Start Summary [summary] -->
## Summary

Redis LangCache Service: API for managing a Redis LangCache
<!-- End Summary [summary] -->

<!-- Start Table of Contents [toc] -->
## Table of Contents
<!-- $toc-max-depth=2 -->
* [langcache](https://github.com/redis/langcache-sdks/blob/master/#langcache)
  * [SDK Installation](https://github.com/redis/langcache-sdks/blob/master/#sdk-installation)
  * [IDE Support](https://github.com/redis/langcache-sdks/blob/master/#ide-support)
  * [SDK Example Usage](https://github.com/redis/langcache-sdks/blob/master/#sdk-example-usage)
  * [Authentication](https://github.com/redis/langcache-sdks/blob/master/#authentication)
  * [Available Resources and Operations](https://github.com/redis/langcache-sdks/blob/master/#available-resources-and-operations)
  * [Global Parameters](https://github.com/redis/langcache-sdks/blob/master/#global-parameters)
  * [Retries](https://github.com/redis/langcache-sdks/blob/master/#retries)
  * [Error Handling](https://github.com/redis/langcache-sdks/blob/master/#error-handling)
  * [Custom HTTP Client](https://github.com/redis/langcache-sdks/blob/master/#custom-http-client)
  * [Resource Management](https://github.com/redis/langcache-sdks/blob/master/#resource-management)
  * [Debugging](https://github.com/redis/langcache-sdks/blob/master/#debugging)
* [Development](https://github.com/redis/langcache-sdks/blob/master/#development)
  * [Maturity](https://github.com/redis/langcache-sdks/blob/master/#maturity)
  * [Contributions](https://github.com/redis/langcache-sdks/blob/master/#contributions)

<!-- End Table of Contents [toc] -->

<!-- Start SDK Installation [installation] -->
## SDK Installation

> [!NOTE]
> **Python version upgrade policy**
>
> Once a Python version reaches its [official end of life date](https://devguide.python.org/versions/), a 3-month grace period is provided for users to upgrade. Following this grace period, the minimum python version supported in the SDK will be updated.

The SDK can be installed with either *pip* or *poetry* package managers.

### PIP

*PIP* is the default package installer for Python, enabling easy installation and management of packages from PyPI via the command line.

```bash
pip install langcache
```

### Poetry

*Poetry* is a modern tool that simplifies dependency management and package publishing by using a single `pyproject.toml` file to handle project metadata and dependencies.

```bash
poetry add langcache
```

### Shell and script usage with `uv`

You can use this SDK in a Python shell with [uv](https://docs.astral.sh/uv/) and the `uvx` command that comes with it like so:

```shell
uvx --from langcache python
```

It's also possible to write a standalone Python script without needing to set up a whole project like so:

```python
#!/usr/bin/env -S uv run --script
# /// script
# requires-python = ">=3.9"
# dependencies = [
#     "langcache",
# ]
# ///

from langcache import LangCache

sdk = LangCache(
  # SDK arguments
)

# Rest of script here...
```

Once that is saved to a file, you can run it with `uv run script.py` where
`script.py` can be replaced with the actual file name.
<!-- End SDK Installation [installation] -->

<!-- Start IDE Support [idesupport] -->
## IDE Support

### PyCharm

Generally, the SDK will work well with most IDEs out of the box. However, when using PyCharm, you can enjoy much better integration with Pydantic by installing an additional plugin.

- [PyCharm Pydantic Plugin](https://docs.pydantic.dev/latest/integrations/pycharm/)
<!-- End IDE Support [idesupport] -->

<!-- Start SDK Example Usage [usage] -->
## SDK Example Usage

### Save an entry

Save an entry to the cache

```python
# Synchronous Example
from langcache import LangCache
import os


with LangCache(
    server_url="https://api.example.com",
    cache_id="<id>",
    service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
) as lang_cache:

    res = lang_cache.set(prompt="How does semantic caching work?", response="Semantic caching stores and retrieves data based on meaning, not exact matches.", attributes={
        "language": "en",
        "topic": "ai",
    })

    # Handle response
    print(res)
```

</br>

The same SDK client can also be used to make asychronous requests by importing asyncio.
```python
# Asynchronous Example
import asyncio
from langcache import LangCache
import os

async def main():

    async with LangCache(
        server_url="https://api.example.com",
        cache_id="<id>",
        service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
    ) as lang_cache:

        res = await lang_cache.set_async(prompt="How does semantic caching work?", response="Semantic caching stores and retrieves data based on meaning, not exact matches.", attributes={
            "language": "en",
            "topic": "ai",
        })

        # Handle response
        print(res)

asyncio.run(main())
```

### Search for entries

Search for entries in the cache

```python
# Synchronous Example
from langcache import LangCache
import os


with LangCache(
    server_url="https://api.example.com",
    cache_id="<id>",
    service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
) as lang_cache:

    res = lang_cache.search(prompt="How does semantic caching work?", similarity_threshold=0.9, attributes={
        "language": "en",
        "topic": "ai",
    })

    # Handle response
    print(res)
```

</br>

The same SDK client can also be used to make asychronous requests by importing asyncio.
```python
# Asynchronous Example
import asyncio
from langcache import LangCache
import os

async def main():

    async with LangCache(
        server_url="https://api.example.com",
        cache_id="<id>",
        service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
    ) as lang_cache:

        res = await lang_cache.search_async(prompt="How does semantic caching work?", similarity_threshold=0.9, attributes={
            "language": "en",
            "topic": "ai",
        })

        # Handle response
        print(res)

asyncio.run(main())
```

### Delete an entry

Delete an entry from the cache by id

```python
# Synchronous Example
from langcache import LangCache
import os


with LangCache(
    server_url="https://api.example.com",
    cache_id="<id>",
    service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
) as lang_cache:

    lang_cache.delete_by_id(entry_id="<id>")

    # Use the SDK ...
```

</br>

The same SDK client can also be used to make asychronous requests by importing asyncio.
```python
# Asynchronous Example
import asyncio
from langcache import LangCache
import os

async def main():

    async with LangCache(
        server_url="https://api.example.com",
        cache_id="<id>",
        service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
    ) as lang_cache:

        await lang_cache.delete_by_id_async(entry_id="<id>")

        # Use the SDK ...

asyncio.run(main())
```

### Delete entries

Delete entries based on attributes

```python
# Synchronous Example
from langcache import LangCache
import os


with LangCache(
    server_url="https://api.example.com",
    cache_id="<id>",
    service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
) as lang_cache:

    res = lang_cache.delete_query(attributes={
        "language": "en",
        "topic": "ai",
    })

    # Handle response
    print(res)
```

</br>

The same SDK client can also be used to make asychronous requests by importing asyncio.
```python
# Asynchronous Example
import asyncio
from langcache import LangCache
import os

async def main():

    async with LangCache(
        server_url="https://api.example.com",
        cache_id="<id>",
        service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
    ) as lang_cache:

        res = await lang_cache.delete_query_async(attributes={
            "language": "en",
            "topic": "ai",
        })

        # Handle response
        print(res)

asyncio.run(main())
```
<!-- End SDK Example Usage [usage] -->

<!-- Start Authentication [security] -->
## Authentication

### Per-Client Security Schemes

This SDK supports the following security scheme globally:

| Name          | Type | Scheme      | Environment Variable    |
| ------------- | ---- | ----------- | ----------------------- |
| `service_key` | http | HTTP Bearer | `LANGCACHE_SERVICE_KEY` |

To authenticate with the API the `service_key` parameter must be set when initializing the SDK client instance. For example:
```python
from langcache import LangCache
import os


with LangCache(
    server_url="https://api.example.com",
    service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
    cache_id="<id>",
) as lang_cache:

    res = lang_cache.search(prompt="How does semantic caching work?", similarity_threshold=0.9, attributes={
        "language": "en",
        "topic": "ai",
    })

    # Handle response
    print(res)

```
<!-- End Authentication [security] -->

<!-- Start Available Resources and Operations [operations] -->
## Available Resources and Operations

<details open>
<summary>Available methods</summary>

### [LangCache SDK](https://github.com/redis/langcache-sdks/blob/master/docs/sdks/langcache/README.md)

* [search](https://github.com/redis/langcache-sdks/blob/master/docs/sdks/langcache/README.md#search) - Search the cache
* [set](https://github.com/redis/langcache-sdks/blob/master/docs/sdks/langcache/README.md#set) - Add a new cache entry to the cache
* [delete_query](https://github.com/redis/langcache-sdks/blob/master/docs/sdks/langcache/README.md#delete_query) - Delete cache entries based on the request parameters
* [delete_by_id](https://github.com/redis/langcache-sdks/blob/master/docs/sdks/langcache/README.md#delete_by_id) - Delete a cache entry by ID

</details>
<!-- End Available Resources and Operations [operations] -->

<!-- Start Global Parameters [global-parameters] -->
## Global Parameters

A parameter is configured globally. This parameter may be set on the SDK client instance itself during initialization. When configured as an option during SDK initialization, This global value will be used as the default on the operations that use it. When such operations are called, there is a place in each to override the global value, if needed.

For example, you can set `cacheId` to `"<id>"` at SDK initialization and then you do not have to pass the same value on calls to operations like `search`. But if you want to do so you may, which will locally override the global setting. See the example code below for a demonstration.


### Available Globals

The following global parameter is available.
Global parameters can also be set via environment variable.

| Name     | Type | Description             | Environment        |
| -------- | ---- | ----------------------- | ------------------ |
| cache_id | str  | The cache_id parameter. | LANGCACHE_CACHE_ID |

### Example

```python
from langcache import LangCache
import os


with LangCache(
    server_url="https://api.example.com",
    cache_id="<id>",
    service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
) as lang_cache:

    res = lang_cache.search(prompt="How does semantic caching work?", similarity_threshold=0.9, attributes={
        "language": "en",
        "topic": "ai",
    })

    # Handle response
    print(res)

```
<!-- End Global Parameters [global-parameters] -->

<!-- Start Retries [retries] -->
## Retries

Some of the endpoints in this SDK support retries. If you use the SDK without any configuration, it will fall back to the default retry strategy provided by the API. However, the default retry strategy can be overridden on a per-operation basis, or across the entire SDK.

To change the default retry strategy for a single API call, simply provide a `RetryConfig` object to the call:
```python
from langcache import LangCache
from langcache.utils import BackoffStrategy, RetryConfig
import os


with LangCache(
    server_url="https://api.example.com",
    cache_id="<id>",
    service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
) as lang_cache:

    res = lang_cache.search(prompt="How does semantic caching work?", similarity_threshold=0.9, attributes={
        "language": "en",
        "topic": "ai",
    },
        RetryConfig("backoff", BackoffStrategy(1, 50, 1.1, 100), False))

    # Handle response
    print(res)

```

If you'd like to override the default retry strategy for all operations that support retries, you can use the `retry_config` optional parameter when initializing the SDK:
```python
from langcache import LangCache
from langcache.utils import BackoffStrategy, RetryConfig
import os


with LangCache(
    server_url="https://api.example.com",
    retry_config=RetryConfig("backoff", BackoffStrategy(1, 50, 1.1, 100), False),
    cache_id="<id>",
    service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
) as lang_cache:

    res = lang_cache.search(prompt="How does semantic caching work?", similarity_threshold=0.9, attributes={
        "language": "en",
        "topic": "ai",
    })

    # Handle response
    print(res)

```
<!-- End Retries [retries] -->

<!-- Start Error Handling [errors] -->
## Error Handling

[`LangCacheError`](https://github.com/redis/langcache-sdks/blob/master/./src/langcache/errors/langcacheerror.py) is the base class for all HTTP error responses. It has the following properties:

| Property           | Type             | Description                                                                             |
| ------------------ | ---------------- | --------------------------------------------------------------------------------------- |
| `err.message`      | `str`            | Error message                                                                           |
| `err.status_code`  | `int`            | HTTP response status code eg `404`                                                      |
| `err.headers`      | `httpx.Headers`  | HTTP response headers                                                                   |
| `err.body`         | `str`            | HTTP body. Can be empty string if no body is returned.                                  |
| `err.raw_response` | `httpx.Response` | Raw HTTP response                                                                       |
| `err.data`         |                  | Optional. Some errors may contain structured data. [See Error Classes](https://github.com/redis/langcache-sdks/blob/master/#error-classes). |

### Example
```python
from langcache import LangCache, errors
import os


with LangCache(
    server_url="https://api.example.com",
    cache_id="<id>",
    service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
) as lang_cache:
    res = None
    try:

        res = lang_cache.search(prompt="How does semantic caching work?", similarity_threshold=0.9, attributes={
            "language": "en",
            "topic": "ai",
        })

        # Handle response
        print(res)


    except errors.LangCacheError as e:
        # The base class for HTTP error responses
        print(e.message)
        print(e.status_code)
        print(e.body)
        print(e.headers)
        print(e.raw_response)

        # Depending on the method different errors may be thrown
        if isinstance(e, errors.BadRequestErrorResponseContent):
            print(e.data.title)  # str
            print(e.data.status)  # Optional[int]
            print(e.data.detail)  # Optional[str]
            print(e.data.type)  # models.BadRequestErrorURI
```

### Error Classes
**Primary errors:**
* [`LangCacheError`](https://github.com/redis/langcache-sdks/blob/master/./src/langcache/errors/langcacheerror.py): The base class for HTTP error responses.
  * [`BadRequestErrorResponseContent`](https://github.com/redis/langcache-sdks/blob/master/./src/langcache/errors/badrequesterrorresponsecontent.py): Bad Request. Status code `400`.
  * [`AuthenticationErrorResponseContent`](https://github.com/redis/langcache-sdks/blob/master/./src/langcache/errors/authenticationerrorresponsecontent.py): Unauthorized. Status code `401`.
  * [`ForbiddenErrorResponseContent`](https://github.com/redis/langcache-sdks/blob/master/./src/langcache/errors/forbiddenerrorresponsecontent.py): Forbidden. Status code `403`.
  * [`InternalServerErrorResponseContent`](https://github.com/redis/langcache-sdks/blob/master/./src/langcache/errors/internalservererrorresponsecontent.py): An unexpected error occurred. Status code `500`.
  * [`ServiceUnavailableErrorResponseContent`](https://github.com/redis/langcache-sdks/blob/master/./src/langcache/errors/serviceunavailableerrorresponsecontent.py): An internal error occurred. Status code `503`.

<details><summary>Less common errors (6)</summary>

<br />

**Network errors:**
* [`httpx.RequestError`](https://www.python-httpx.org/exceptions/#httpx.RequestError): Base class for request errors.
    * [`httpx.ConnectError`](https://www.python-httpx.org/exceptions/#httpx.ConnectError): HTTP client was unable to make a request to a server.
    * [`httpx.TimeoutException`](https://www.python-httpx.org/exceptions/#httpx.TimeoutException): HTTP request timed out.


**Inherit from [`LangCacheError`](https://github.com/redis/langcache-sdks/blob/master/./src/langcache/errors/langcacheerror.py)**:
* [`NotFoundErrorResponseContent`](https://github.com/redis/langcache-sdks/blob/master/./src/langcache/errors/notfounderrorresponsecontent.py): Cache entry not found. Status code `404`. Applicable to 1 of 4 methods.*
* [`ResponseValidationError`](https://github.com/redis/langcache-sdks/blob/master/./src/langcache/errors/responsevalidationerror.py): Type mismatch between the response data and the expected Pydantic model. Provides access to the Pydantic validation error via the `cause` attribute.

</details>

\* Check [the method documentation](https://github.com/redis/langcache-sdks/blob/master/#available-resources-and-operations) to see if the error is applicable.
<!-- End Error Handling [errors] -->

<!-- Start Custom HTTP Client [http-client] -->
## Custom HTTP Client

The Python SDK makes API calls using the [httpx](https://www.python-httpx.org/) HTTP library.  In order to provide a convenient way to configure timeouts, cookies, proxies, custom headers, and other low-level configuration, you can initialize the SDK client with your own HTTP client instance.
Depending on whether you are using the sync or async version of the SDK, you can pass an instance of `HttpClient` or `AsyncHttpClient` respectively, which are Protocol's ensuring that the client has the necessary methods to make API calls.
This allows you to wrap the client with your own custom logic, such as adding custom headers, logging, or error handling, or you can just pass an instance of `httpx.Client` or `httpx.AsyncClient` directly.

For example, you could specify a header for every request that this sdk makes as follows:
```python
from langcache import LangCache
import httpx

http_client = httpx.Client(headers={"x-custom-header": "someValue"})
s = LangCache(client=http_client)
```

or you could wrap the client with your own custom logic:
```python
from langcache import LangCache
from langcache.httpclient import AsyncHttpClient
import httpx

class CustomClient(AsyncHttpClient):
    client: AsyncHttpClient

    def __init__(self, client: AsyncHttpClient):
        self.client = client

    async def send(
        self,
        request: httpx.Request,
        *,
        stream: bool = False,
        auth: Union[
            httpx._types.AuthTypes, httpx._client.UseClientDefault, None
        ] = httpx.USE_CLIENT_DEFAULT,
        follow_redirects: Union[
            bool, httpx._client.UseClientDefault
        ] = httpx.USE_CLIENT_DEFAULT,
    ) -> httpx.Response:
        request.headers["Client-Level-Header"] = "added by client"

        return await self.client.send(
            request, stream=stream, auth=auth, follow_redirects=follow_redirects
        )

    def build_request(
        self,
        method: str,
        url: httpx._types.URLTypes,
        *,
        content: Optional[httpx._types.RequestContent] = None,
        data: Optional[httpx._types.RequestData] = None,
        files: Optional[httpx._types.RequestFiles] = None,
        json: Optional[Any] = None,
        params: Optional[httpx._types.QueryParamTypes] = None,
        headers: Optional[httpx._types.HeaderTypes] = None,
        cookies: Optional[httpx._types.CookieTypes] = None,
        timeout: Union[
            httpx._types.TimeoutTypes, httpx._client.UseClientDefault
        ] = httpx.USE_CLIENT_DEFAULT,
        extensions: Optional[httpx._types.RequestExtensions] = None,
    ) -> httpx.Request:
        return self.client.build_request(
            method,
            url,
            content=content,
            data=data,
            files=files,
            json=json,
            params=params,
            headers=headers,
            cookies=cookies,
            timeout=timeout,
            extensions=extensions,
        )

s = LangCache(async_client=CustomClient(httpx.AsyncClient()))
```
<!-- End Custom HTTP Client [http-client] -->

<!-- Start Resource Management [resource-management] -->
## Resource Management

The `LangCache` class implements the context manager protocol and registers a finalizer function to close the underlying sync and async HTTPX clients it uses under the hood. This will close HTTP connections, release memory and free up other resources held by the SDK. In short-lived Python programs and notebooks that make a few SDK method calls, resource management may not be a concern. However, in longer-lived programs, it is beneficial to create a single SDK instance via a [context manager][context-manager] and reuse it across the application.

[context-manager]: https://docs.python.org/3/reference/datamodel.html#context-managers

```python
from langcache import LangCache
import os
def main():

    with LangCache(
        server_url="https://api.example.com",
        cache_id="<id>",
        service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
    ) as lang_cache:
        # Rest of application here...


# Or when using async:
async def amain():

    async with LangCache(
        server_url="https://api.example.com",
        cache_id="<id>",
        service_key=os.getenv("LANGCACHE_SERVICE_KEY", ""),
    ) as lang_cache:
        # Rest of application here...
```
<!-- End Resource Management [resource-management] -->

<!-- Start Debugging [debug] -->
## Debugging

You can setup your SDK to emit debug logs for SDK requests and responses.

You can pass your own logger class directly into your SDK.
```python
from langcache import LangCache
import logging

logging.basicConfig(level=logging.DEBUG)
s = LangCache(server_url="https://example.com", debug_logger=logging.getLogger("langcache"))
```

You can also enable a default debug logger by setting an environment variable `LANGCACHE_DEBUG` to true.
<!-- End Debugging [debug] -->

<!-- Placeholder for Future Speakeasy SDK Sections -->

# Development

## Maturity

This SDK is in beta, and there may be breaking changes between versions without a major version update. Therefore, we recommend pinning usage
to a specific package version. This way, you can install the same version each time without breaking changes unless you are intentionally
looking for the latest version.

## Contributions

While we value open-source contributions to this SDK, this library is generated programmatically. Any manual changes added to internal files will be overwritten on the next generation. 
We look forward to hearing your feedback. Feel free to open a PR or an issue with a proof of concept and we'll do our best to include it in a future release. 

### SDK Created by [Speakeasy](https://www.speakeasy.com/?utm_source=langcache&utm_campaign=python)

