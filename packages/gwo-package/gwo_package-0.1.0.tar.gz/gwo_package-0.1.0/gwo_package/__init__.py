"""
Grey Wolf Optimizer (GWO) - Nature-Inspired Optimization Algorithm

This module implements the Grey Wolf Optimizer algorithm, a metaheuristic
optimization algorithm that mimics the leadership hierarchy and hunting
mechanism of grey wolves in nature.

Key Features:
- Easy-to-use .fit() interface
- Optional MPI parallelization for large-scale problems
- Flexible bounds and configuration options
- Multiple verbosity levels for monitoring progress
- Comprehensive type hints and documentation

Example usage:
    >>> from gwo import GreyWolfOptimizer
    >>> 
    >>> def objective_function(x):
    >>>     return np.sum(x ** 2)  # Sphere function
    >>> 
    >>> optimizer = GreyWolfOptimizer(
    >>>     n_wolves=50,
    >>>     max_iter=100,
    >>>     bounds=(-10, 10),
    >>>     random_state=42,
    >>>     verbose=1  # 0=silent, 1=basic, 2=detailed
    >>> )
    >>> 
    >>> result = optimizer.fit(objective_function, dimensions=10)
    >>> print(f"Best solution: {result.x}")
    >>> print(f"Best fitness: {result.fun}")

Author: Generated by AI Assistant
Date: July 9, 2025
"""

import numpy as np
import asyncio
from typing import Tuple, Callable, Optional, Union, Any
from dataclasses import dataclass, field
import warnings

# Optional MPI support - gracefully handle if not available
try:
    from mpi4py import MPI
    _MPI_AVAILABLE = True
except ImportError:
    _MPI_AVAILABLE = False
    MPI = None
    warnings.warn(
        "mpi4py not available. MPI parallelization will be disabled. "
        "Install mpi4py for distributed optimization.",
        UserWarning
    )


@dataclass
class OptimizationResult:
    """
    Result object returned by GreyWolfOptimizer.fit().
    
    Contains all information about the optimization run, including
    the best solution found and performance metrics.
    
    Attributes:
        x: Best solution found (position of alpha wolf)
        fun: Best fitness value achieved
        nit: Number of iterations performed
        success: Whether optimization was successful
        message: Descriptive message about optimization result
        nfev: Number of function evaluations performed
        population_: Final population of wolves
        fitness_history_: History of best fitness values per iteration
    """
    x: np.ndarray
    fun: float
    nit: int
    success: bool = True
    message: str = "Optimization completed successfully"
    nfev: int = 0
    population_: Optional[np.ndarray] = None
    fitness_history_: Optional[list] = field(default_factory=list)


class GreyWolfOptimizer:
    """
    Grey Wolf Optimizer - Nature-inspired optimization algorithm.
    
    The GWO algorithm is inspired by the hunting behavior and social hierarchy
    of grey wolves. The algorithm divides the population into four groups:
    - Alpha (α): Best solution (leader)
    - Beta (β): Second best solution (subordinate)
    - Delta (δ): Third best solution (subordinate)
    - Omega (ω): Rest of the solutions (followers)
    
    Parameters:
        n_wolves: int, default=30
            Number of wolves in the pack (population size)
        max_iter: int, default=500
            Maximum number of optimization iterations
        bounds: tuple or array-like, default=(-100, 100)
            Search space bounds. Can be:
            - tuple (lower, upper) for all dimensions
            - array-like of shape (n_dimensions, 2) for per-dimension bounds
        random_state: int or None, default=None
            Random seed for reproducible results
        use_mpi: bool, default=False
            Whether to use MPI parallelization (requires mpi4py)
        verbose: int, default=0
            Verbosity level:
            - 0: Silent (no output)
            - 1: Basic progress (every 50 iterations)
            - 2: Detailed progress (every iteration with leader info)
        
    Attributes:
        best_solution_: np.ndarray
            Best solution found (position of alpha wolf)
        best_fitness_: float
            Best fitness value achieved
        fitness_history_: list
            History of best fitness values per iteration
        n_function_evaluations_: int
            Total number of function evaluations performed
    """
    
    def __init__(
        self,
        n_wolves: int = 30,
        max_iter: int = 500,
        bounds: Union[Tuple[float, float], np.ndarray] = (-100, 100),
        random_state: Optional[int] = None,
        use_mpi: bool = False,
        verbose: int = 0
    ) -> None:
        """
        Initialize the Grey Wolf Optimizer.
        
        Args:
            n_wolves: Number of wolves in the population
            max_iter: Maximum number of optimization iterations
            bounds: Search space bounds for variables
            random_state: Random seed for reproducibility
            use_mpi: Whether to use MPI parallelization
            verbose: Verbosity level (0=silent, 1=basic, 2=detailed)
        """
        self.n_wolves = n_wolves
        self.max_iter = max_iter
        self.bounds = bounds
        self.random_state = random_state
        self.use_mpi = use_mpi and _MPI_AVAILABLE
        self.verbose = verbose
        
        # Validate verbosity level
        if verbose not in [0, 1, 2]:
            raise ValueError("verbose must be 0 (silent), 1 (basic), or 2 (detailed)")
        
        # Initialize random state
        if random_state is not None:
            np.random.seed(random_state)
        
        # Warn if MPI requested but not available
        if use_mpi and not _MPI_AVAILABLE:
            warnings.warn(
                "MPI requested but mpi4py not available. Running in serial mode.",
                UserWarning
            )
        
        # Initialize optimization state
        self._reset_state()
    
    def _reset_state(self) -> None:
        """Reset the optimizer's internal state."""
        self.best_solution_ = None
        self.best_fitness_ = np.inf
        self.fitness_history_ = []
        self.n_function_evaluations_ = 0
        self._population = None
        self._alpha_position = None
        self._beta_position = None
        self._delta_position = None
        self._alpha_fitness = np.inf
        self._beta_fitness = np.inf
        self._delta_fitness = np.inf
    
    def _validate_bounds(self, dimensions: int) -> np.ndarray:
        """
        Validate and normalize bounds for the optimization problem.
        
        Args:
            dimensions: Number of dimensions in the problem
            
        Returns:
            Normalized bounds array of shape (dimensions, 2)
        """
        bounds = np.array(self.bounds)
        
        # Handle different bound formats
        if bounds.ndim == 1 and len(bounds) == 2:
            # Single tuple/list (lower, upper) for all dimensions
            bounds = np.tile(bounds, (dimensions, 1))
        elif bounds.ndim == 2 and bounds.shape == (dimensions, 2):
            # Per-dimension bounds
            pass
        else:
            raise ValueError(
                f"bounds must be either a tuple (lower, upper) or array of shape "
                f"({dimensions}, 2), got shape {bounds.shape}"
            )
        
        # Validate bound values
        if np.any(bounds[:, 0] >= bounds[:, 1]):
            raise ValueError("All lower bounds must be less than upper bounds")
        
        return bounds
    
    def _initialize_population(self, dimensions: int, bounds: np.ndarray) -> np.ndarray:
        """
        Initialize wolf population within the search bounds.
        
        Args:
            dimensions: Number of dimensions in the problem
            bounds: Bounds array of shape (dimensions, 2)
            
        Returns:
            Population array of shape (n_wolves, dimensions)
        """
        population = np.random.uniform(
            bounds[:, 0],
            bounds[:, 1],
            (self.n_wolves, dimensions)
        )
        return population
    
    def _evaluate_population(
        self, 
        population: np.ndarray, 
        objective_function: Callable[[np.ndarray], float]
    ) -> np.ndarray:
        """
        Evaluate fitness for all wolves in the population.
        
        Args:
            population: Population array of shape (n_wolves, dimensions)
            objective_function: Function to minimize
            
        Returns:
            Fitness values array of shape (n_wolves,)
        """
        if self.use_mpi:
            return self._evaluate_population_mpi(population, objective_function)
        else:
            fitness_values = np.array([
                objective_function(wolf) for wolf in population
            ])
            self.n_function_evaluations_ += len(population)
            return fitness_values
    
    def _evaluate_population_mpi(
        self, 
        population: np.ndarray, 
        objective_function: Callable[[np.ndarray], float]
    ) -> np.ndarray:
        """
        Evaluate population using MPI parallelization.
        
        Args:
            population: Population array of shape (n_wolves, dimensions)
            objective_function: Function to minimize
            
        Returns:
            Fitness values array of shape (n_wolves,)
        """
        if not _MPI_AVAILABLE or MPI is None:
            # Fallback to serial evaluation
            return np.array([objective_function(wolf) for wolf in population])
        
        comm = MPI.COMM_WORLD
        rank = comm.Get_rank()
        size = comm.Get_size()
        
        # Calculate workload distribution
        wolves_per_process = self.n_wolves // size
        remainder = self.n_wolves % size
        
        # Determine local workload
        if rank < remainder:
            local_n_wolves = wolves_per_process + 1
            start_idx = rank * local_n_wolves
        else:
            local_n_wolves = wolves_per_process
            start_idx = rank * wolves_per_process + remainder
        
        end_idx = start_idx + local_n_wolves
        
        # Evaluate local portion
        local_fitness = np.array([
            objective_function(population[i]) 
            for i in range(start_idx, end_idx)
        ])
        
        # Gather results
        all_fitness = comm.allgather(local_fitness)
        fitness_values = np.concatenate(all_fitness)
        
        # Update function evaluation count (only on root to avoid duplicates)
        if rank == 0:
            self.n_function_evaluations_ += len(population)
            # Print MPI info for verbose level 2
            if self.verbose == 2:
                print(f"    MPI: Distributed evaluation across {size} processes")
        
        return fitness_values

    def _update_pack_leaders(
        self, 
        fitness_values: np.ndarray, 
        population: np.ndarray
    ) -> None:
        """
        Update the alpha, beta, and delta wolves based on fitness values.
        
        This method maintains the social hierarchy by identifying the three
        best wolves and updating their positions and fitness values.
        
        Args:
            fitness_values: Array of fitness values for all wolves
            population: Array of positions for all wolves
        """
        # Iterate through all wolves to find the best three
        for wolf_index in range(len(population)):
            current_fitness = fitness_values[wolf_index]
            current_position = population[wolf_index]
            
            # Check if current wolf is better than alpha (best wolf)
            if current_fitness < self._alpha_fitness:
                # Demote alpha to beta, beta to delta
                self._delta_fitness = self._beta_fitness
                if self._beta_position is not None:
                    self._delta_position = self._beta_position.copy()
                self._beta_fitness = self._alpha_fitness
                if self._alpha_position is not None:
                    self._beta_position = self._alpha_position.copy()
                
                # Promote current wolf to alpha
                self._alpha_fitness = current_fitness
                self._alpha_position = current_position.copy()
                
            # Check if current wolf is better than beta (second best)
            elif current_fitness < self._beta_fitness:
                # Demote beta to delta
                self._delta_fitness = self._beta_fitness
                if self._beta_position is not None:
                    self._delta_position = self._beta_position.copy()
                
                # Promote current wolf to beta
                self._beta_fitness = current_fitness
                self._beta_position = current_position.copy()
                
            # Check if current wolf is better than delta (third best)
            elif current_fitness < self._delta_fitness:
                # Promote current wolf to delta
                self._delta_fitness = current_fitness
                self._delta_position = current_position.copy()
        
        # Update best solution attributes
        if self._alpha_position is not None:
            self.best_solution_ = self._alpha_position.copy()
            self.best_fitness_ = self._alpha_fitness

    def _calculate_wolf_step(
        self, 
        leader_position: np.ndarray, 
        wolf_position: np.ndarray, 
        convergence_parameter: float
    ) -> np.ndarray:
        """
        Calculate the step towards a leader wolf for position update.
        
        This implements the core GWO position update equation based on
        the hunting behavior of wolves following their leaders.
        
        Args:
            leader_position: Position of the leader wolf (alpha, beta, or delta)
            wolf_position: Current position of the wolf being updated
            convergence_parameter: Parameter 'a' that decreases linearly over iterations
            
        Returns:
            New position step calculated based on leader guidance
        """
        # Generate random coefficients for exploration vs exploitation balance
        random_coefficient_1 = np.random.rand()
        random_coefficient_2 = np.random.rand()
        
        # Calculate coefficient A (controls exploration vs exploitation)
        coefficient_a = 2 * convergence_parameter * random_coefficient_1 - convergence_parameter
        
        # Calculate coefficient C (emphasizes or de-emphasizes leader influence)
        coefficient_c = 2 * random_coefficient_2
        
        # Calculate distance between wolf and leader
        distance_to_leader = np.abs(coefficient_c * leader_position - wolf_position)
        
        # Calculate new position step based on leader guidance
        new_position_step = leader_position - coefficient_a * distance_to_leader
        
        return new_position_step

    def _update_wolf_positions(
        self, 
        population: np.ndarray, 
        bounds: np.ndarray, 
        convergence_parameter: float
    ) -> np.ndarray:
        """
        Update positions of all wolves based on the three pack leaders.
        
        Each wolf's new position is calculated as the average of three
        position steps guided by alpha, beta, and delta wolves.
        
        Args:
            population: Current population array
            bounds: Bounds array of shape (dimensions, 2)
            convergence_parameter: Parameter 'a' that decreases from 2 to 0
                                 Controls transition from exploration to exploitation
                                 
        Returns:
            Updated population array
        """
        new_population = population.copy()
        
        # Update each wolf's position
        for wolf_index in range(len(population)):
            current_wolf_position = population[wolf_index]
            
            # Calculate position steps guided by each leader
            alpha_guided_step = self._calculate_wolf_step(
                self._alpha_position, current_wolf_position, convergence_parameter
            )
            beta_guided_step = self._calculate_wolf_step(
                self._beta_position, current_wolf_position, convergence_parameter
            )
            delta_guided_step = self._calculate_wolf_step(
                self._delta_position, current_wolf_position, convergence_parameter
            )
            
            # Calculate new position as average of the three guided steps
            new_position = (alpha_guided_step + beta_guided_step + delta_guided_step) / 3
            
            # Ensure new position stays within search bounds
            new_population[wolf_index] = np.clip(
                new_position, 
                bounds[:, 0], 
                bounds[:, 1]
            )
        
        return new_population

    def fit(
        self, 
        objective_function: Callable[[np.ndarray], float], 
        dimensions: Optional[int] = None,
        X: Optional[np.ndarray] = None
    ) -> OptimizationResult:
        """
        Run the Grey Wolf Optimization algorithm to minimize the objective function.
        
        This is the main method to perform optimization.
        
        Args:
            objective_function: Function to minimize, takes array and returns scalar
            dimensions: Number of dimensions (required if X is not provided)
            X: Optional initial population of shape (n_wolves, dimensions)
            
        Returns:
            OptimizationResult object containing optimization results
        """
        # Reset state for new optimization
        self._reset_state()
        
        # Determine dimensions
        final_dimensions: int
        if X is not None:
            final_dimensions = X.shape[1]
            if X.shape[0] != self.n_wolves:
                raise ValueError(
                    f"X must have {self.n_wolves} samples (wolves), got {X.shape[0]}"
                )
        elif dimensions is not None:
            final_dimensions = dimensions
        else:
            raise ValueError("Either dimensions or X must be provided")
        
        # Validate and normalize bounds
        bounds = self._validate_bounds(final_dimensions)
        
        # Initialize population
        if X is not None:
            population = X.copy()
        else:
            population = self._initialize_population(final_dimensions, bounds)
        
        self._population = population
        
        # Print initialization info based on verbosity level
        if self.verbose >= 1:
            print(f"Starting Grey Wolf Optimization:")
            print(f"  Population size: {self.n_wolves}")
            print(f"  Dimensions: {final_dimensions}")
            print(f"  Max iterations: {self.max_iter}")
            print(f"  Bounds: {bounds[0] if len(set(map(tuple, bounds))) == 1 else 'Per-dimension'}")
            
            if self.verbose == 2:
                print(f"  MPI enabled: {self.use_mpi}")
                print(f"  Random state: {self.random_state}")
                print(f"  Search bounds per dimension:")
                for i, (lower, upper) in enumerate(bounds[:min(5, len(bounds))]):
                    print(f"    Dim {i+1}: [{lower:.2f}, {upper:.2f}]")
                if len(bounds) > 5:
                    print(f"    ... and {len(bounds) - 5} more dimensions")
            print()
        
        # Initialize leader positions with first three wolves
        if len(population) >= 3:
            self._alpha_position = population[0].copy()
            self._beta_position = population[1].copy()
            self._delta_position = population[2].copy()
        else:
            raise ValueError("Population must have at least 3 wolves")
        
        # Main optimization loop
        iteration = 0
        for iteration in range(self.max_iter):
            # Evaluate population fitness
            fitness_values = self._evaluate_population(population, objective_function)
            
            # Update pack hierarchy based on fitness values
            self._update_pack_leaders(fitness_values, population)
            
            # Store best fitness in history
            self.fitness_history_.append(self.best_fitness_)
            
            # Print progress based on verbosity level
            if self.verbose == 1 and iteration % 50 == 0:
                print(f"Iteration {iteration:4d}: Best fitness = {self.best_fitness_:.6e}")
            elif self.verbose == 2:
                print(f"Iteration {iteration:4d}: Best = {self.best_fitness_:.6e}, "
                      f"Alpha = {self._alpha_fitness:.6e}, Beta = {self._beta_fitness:.6e}, "
                      f"Delta = {self._delta_fitness:.6e}")
            
            # Check for convergence (early stopping)
            if self.best_fitness_ < 1e-15:  # Close to global optimum
                if self.verbose >= 1:
                    print(f"Converged at iteration {iteration}")
                break
            
            # Calculate convergence parameter (decreases linearly from 2 to 0)
            convergence_parameter = 2 - iteration * (2 / self.max_iter)
            
            # Update all wolf positions based on leaders
            population = self._update_wolf_positions(
                population, bounds, convergence_parameter
            )
        
        # Store final population
        self._population = population
        
        # Print final results based on verbosity level
        if self.verbose >= 1:
            print(f"\nOptimization completed after {iteration + 1} iterations")
            print(f"Best fitness achieved: {self.best_fitness_:.6e}")
            print(f"Total function evaluations: {self.n_function_evaluations_}")
            
            if self.verbose == 2:
                print(f"Final pack leaders:")
                print(f"  Alpha fitness: {self._alpha_fitness:.6e}")
                print(f"  Beta fitness:  {self._beta_fitness:.6e}")
                print(f"  Delta fitness: {self._delta_fitness:.6e}")
        
        # Ensure we have a valid best solution
        if self.best_solution_ is None:
            # Fallback: use alpha position if somehow not set
            if self._alpha_position is not None:
                self.best_solution_ = self._alpha_position.copy()
            else:
                # Last resort: use first wolf
                self.best_solution_ = population[0].copy()
                self.best_fitness_ = objective_function(self.best_solution_)
        
        # Create and return result object
        result = OptimizationResult(
            x=self.best_solution_,
            fun=self.best_fitness_,
            nit=iteration + 1,
            success=True,
            message="Optimization completed successfully",
            nfev=self.n_function_evaluations_,
            population_=population,
            fitness_history_=self.fitness_history_
        )
        
        return result

    def predict(self, X: np.ndarray) -> np.ndarray:
        """
        Evaluate distances from input points to the best solution found.
        
        Args:
            X: Input data of shape (n_samples, n_features)
            
        Returns:
            Distances to the best solution for each input point
        """
        if not hasattr(self, 'best_solution_'):
            raise ValueError("Optimizer must be fitted before calling predict")
        
        return np.array([np.linalg.norm(x - self.best_solution_) for x in X])

    def score(self, X: np.ndarray, y: Optional[np.ndarray] = None) -> float:
        """
        Return the negative best fitness value.
        
        Args:
            X: Input data (not used, included for compatibility)
            y: Target values (not used, included for compatibility)
            
        Returns:
            Negative of the best fitness value
        """
        if not hasattr(self, 'best_fitness_'):
            raise ValueError("Optimizer must be fitted before calling score")
        
        return -self.best_fitness_

    def get_params(self, deep: bool = True) -> dict:
        """
        Get parameters for this optimizer.
        
        Args:
            deep: If True, return parameters for sub-estimators too
            
        Returns:
            Dictionary of parameter names to values
        """
        return {
            'n_wolves': self.n_wolves,
            'max_iter': self.max_iter,
            'bounds': self.bounds,
            'random_state': self.random_state,
            'use_mpi': self.use_mpi,
            'verbose': self.verbose
        }

    def set_params(self, **params) -> 'GreyWolfOptimizer':
        """
        Set parameters for this optimizer.
        
        Args:
            **params: Optimizer parameters to set
            
        Returns:
            Self for method chaining
        """
        for key, value in params.items():
            if hasattr(self, key):
                setattr(self, key, value)
            else:
                raise ValueError(f"Invalid parameter {key} for optimizer {type(self).__name__}")
        
        return self



# Example usage and testing functions
def _demo_sphere_function(position_vector: np.ndarray) -> float:
    """
    Sphere function - a classic optimization benchmark function.
    
    This is a simple unimodal function with a global minimum at the origin.
    f(x) = sum(x_i^2) for i = 1 to n
    
    Characteristics:
    - Global minimum: f(0, 0, ..., 0) = 0
    - Search domain: typically [-10, 10]^n
    - Unimodal (single optimum)
    - Separable (can be optimized dimension by dimension)
    
    Args:
        position_vector: Input vector of real numbers
        
    Returns:
        Function value (sum of squared components)
    """
    return np.sum(position_vector ** 2)


def _demo_rastrigin_function(position_vector: np.ndarray) -> float:
    """
    Rastrigin function - a multimodal optimization benchmark function.
    
    f(x) = A*n + sum(x_i^2 - A*cos(2*pi*x_i)) where A = 10
    
    Characteristics:
    - Global minimum: f(0, 0, ..., 0) = 0
    - Many local minima
    - Highly multimodal
    - Non-separable
    
    Args:
        position_vector: Input vector of real numbers
        
    Returns:
        Function value
    """
    A = 10
    n = len(position_vector)
    return A * n + np.sum(position_vector**2 - A * np.cos(2 * np.pi * position_vector))


def _run_demo():
    """
    Demonstrate the Grey Wolf Optimizer with different benchmark functions.
    """
    print("Grey Wolf Optimizer Demo")
    print("=" * 40)
    
    # Test with Sphere function
    print("\n1. Sphere Function (f(x) = sum(x_i^2))")
    print("   Global minimum: f(0, 0, ..., 0) = 0")
    
    optimizer = GreyWolfOptimizer(
        n_wolves=30, max_iter=200, bounds=(-10, 10), 
        random_state=42, verbose=1
    )
    
    result = optimizer.fit(_demo_sphere_function, dimensions=10)
    print(f"Results: Best = {result.fun:.2e}, Iterations = {result.nit}")
    
    # Test with Rastrigin function
    print("\n" + "=" * 40)
    print("\n2. Rastrigin Function (multimodal)")
    print("   Global minimum: f(0, 0, ..., 0) = 0")
    
    optimizer2 = GreyWolfOptimizer(
        n_wolves=50, max_iter=300, bounds=(-5.12, 5.12), 
        random_state=42, verbose=2
    )
    
    result2 = optimizer2.fit(_demo_rastrigin_function, dimensions=5)
    print(f"Results: Best = {result2.fun:.2e}, Iterations = {result2.nit}")
    
    # Demonstrate parameter management
    print("\n" + "=" * 40)
    print("\n3. Parameter Management")
    params = optimizer.get_params()
    print(f"Current parameters: {params}")
    optimizer.set_params(n_wolves=20, max_iter=100)
    print(f"Updated: n_wolves={optimizer.n_wolves}, max_iter={optimizer.max_iter}")


if __name__ == "__main__":
    def sphere_function(position_vector: np.ndarray) -> float:
        """
        Sphere function - a classic optimization benchmark.
        
        f(x) = sum(x_i^2) for i = 1 to n
        Global minimum: f(0, 0, ..., 0) = 0
        
        Args:
            position_vector: Input vector of real numbers
            
        Returns:
            Function value (sum of squared components)
        """
        return np.sum(position_vector ** 2)
    
    # Example usage of the Grey Wolf Optimizer
    print("Grey Wolf Optimizer - Nature-Inspired Optimization")
    print("=" * 50)
    
    # Create optimizer instance
    gwo = GreyWolfOptimizer(
        n_wolves=30,        # Population size
        max_iter=200,       # Maximum iterations
        bounds=(-10, 10),   # Search bounds
        random_state=42,    # For reproducibility
        verbose=1           # Basic progress output
    )
    
    # Run optimization on sphere function
    result = gwo.fit(sphere_function, dimensions=10)
    
    # Display results
    print(f"\nOptimization Results:")
    print(f"Best solution: {result.x}")
    print(f"Best fitness: {result.fun:.2e}")
    print(f"Iterations completed: {result.nit}")
    print(f"Total function evaluations: {result.nfev}")
    print(f"Optimization successful: {result.success}")
    
    # Run comprehensive demo if requested
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == '--demo':
        print("\n" + "=" * 50)
        _run_demo()