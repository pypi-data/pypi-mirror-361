"""
ç•°å¸¸è™•ç†å’Œé‚Šç•Œæ¢ä»¶æ¸¬è©¦
"""

import pytest
import json
import requests
from unittest.mock import patch, Mock
from requests.exceptions import ConnectionError, Timeout, HTTPError, RequestException
from pydantic import ValidationError

from ollama_flow import OllamaClient, ChatMessage
from ollama_flow.models import GenerateResponse, ChatResponse, EmbedResponse
from pydantic import BaseModel, Field


class SampleTestModel(BaseModel):
    """æ¸¬è©¦æ¨¡å‹"""
    name: str = Field(..., description="åç¨±")
    value: int = Field(..., description="æ•¸å€¼")


class TestNetworkErrors:
    """ç¶²çµ¡éŒ¯èª¤æ¸¬è©¦"""
    
    def setup_method(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        self.client = OllamaClient(base_url="http://localhost:11434")
        
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_connection_error(self, mock_request, mock_check_model):
        """æ¸¬è©¦é€£æ¥éŒ¯èª¤"""
        mock_request.side_effect = ConnectionError("Connection failed")
        
        with pytest.raises(Exception) as exc_info:
            self.client.generate(model="test_model", prompt="test", stream=False)
        
        assert "Request failed: Connection failed" in str(exc_info.value)
            
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_timeout_error(self, mock_request, mock_check_model):
        """æ¸¬è©¦è¶…æ™‚éŒ¯èª¤"""
        mock_request.side_effect = Timeout("Request timed out")
        
        with pytest.raises(Exception) as exc_info:
            self.client.generate(model="test_model", prompt="test", stream=False)
        
        assert "Request failed: Request timed out" in str(exc_info.value)
            
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_http_404_error(self, mock_request, mock_check_model):
        """æ¸¬è©¦ 404 éŒ¯èª¤"""
        mock_response = Mock()
        mock_response.status_code = 404
        mock_response.raise_for_status.side_effect = HTTPError("404 Not Found")
        mock_request.return_value = mock_response
        
        with pytest.raises(Exception) as exc_info:
            self.client.generate(model="test_model", prompt="test", stream=False)
        
        assert "Request failed: 404 Not Found" in str(exc_info.value)
            
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_http_500_error(self, mock_request, mock_check_model):
        """æ¸¬è©¦ 500 éŒ¯èª¤"""
        mock_response = Mock()
        mock_response.status_code = 500
        mock_response.raise_for_status.side_effect = HTTPError("500 Internal Server Error")
        mock_request.return_value = mock_response
        
        with pytest.raises(Exception) as exc_info:
            self.client.generate(model="test_model", prompt="test", stream=False)
        
        assert "Request failed: 500 Internal Server Error" in str(exc_info.value)
            
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_malformed_json_response(self, mock_request, mock_check_model):
        """æ¸¬è©¦æ ¼å¼éŒ¯èª¤çš„ JSON å›æ‡‰"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.side_effect = json.JSONDecodeError("Invalid JSON", "", 0)
        mock_request.return_value = mock_response
        
        with pytest.raises(Exception) as exc_info:
            self.client.generate(model="test_model", prompt="test", stream=False)
        
        assert "Invalid JSON" in str(exc_info.value)
            
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_empty_response(self, mock_request, mock_check_model):
        """æ¸¬è©¦ç©ºå›æ‡‰"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {}
        mock_request.return_value = mock_response
        
        with pytest.raises(ValidationError) as exc_info:
            self.client.generate(model="test_model", prompt="test", stream=False)
        
        assert "validation errors for GenerateResponse" in str(exc_info.value)
            
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_missing_required_fields(self, mock_request, mock_check_model):
        """æ¸¬è©¦ç¼ºå°‘å¿…è¦æ¬„ä½çš„å›æ‡‰"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "response": "Test response"
            # ç¼ºå°‘ "done" å’Œ "model" æ¬„ä½
        }
        mock_request.return_value = mock_response
        
        with pytest.raises(ValidationError) as exc_info:
            self.client.generate(model="test_model", prompt="test", stream=False)
        
        assert "validation errors for GenerateResponse" in str(exc_info.value)


class TestInputValidation:
    """è¼¸å…¥é©—è­‰æ¸¬è©¦"""
    
    def setup_method(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        self.client = OllamaClient(base_url="http://localhost:11434")
        
    def test_empty_model_name(self):
        """æ¸¬è©¦ç©ºæ¨¡å‹åç¨±"""
        with pytest.raises(ValueError) as exc_info:
            self.client.generate(model="", prompt="test", stream=False)
        
        assert "Model '' does not exist" in str(exc_info.value)
            
    def test_none_model_name(self):
        """æ¸¬è©¦ None æ¨¡å‹åç¨±"""
        with pytest.raises(ValueError) as exc_info:
            self.client.generate(model=None, prompt="test", stream=False)
        
        assert "Model 'None' does not exist" in str(exc_info.value)
            
    def test_empty_prompt(self):
        """æ¸¬è©¦ç©ºæç¤º"""
        with patch('ollama_flow.client.OllamaClient._check_model_exists'):
            with patch('requests.Session.request') as mock_request:
                mock_response = Mock()
                mock_response.status_code = 200
                mock_response.json.return_value = {
                    "model": "test_model",
                    "created_at": "2024-01-01T00:00:00Z",
                    "response": "",
                    "done": True
                }
                mock_request.return_value = mock_response
                
                # ç©ºæç¤ºæ‡‰è©²è¢«æ¥å—
                result = self.client.generate(model="test_model", prompt="", stream=False)
                assert result.response == ""
                
    def test_none_prompt(self):
        """æ¸¬è©¦ None æç¤º"""
        with pytest.raises(ValueError) as exc_info:
            self.client.generate(model="test_model", prompt=None, stream=False)
        
        assert "Model 'test_model' does not exist" in str(exc_info.value)
            
    def test_invalid_options_type(self):
        """æ¸¬è©¦ç„¡æ•ˆçš„é¸é …é¡å‹"""
        with pytest.raises(ValueError) as exc_info:
            self.client.generate(
                model="test_model",
                prompt="test",
                options="invalid_options",
                stream=False
            )
        
        assert "Model 'test_model' does not exist" in str(exc_info.value)
            
    def test_empty_messages_list(self):
        """æ¸¬è©¦ç©ºè¨Šæ¯åˆ—è¡¨"""
        with patch('ollama_flow.client.OllamaClient._check_model_exists'):
            with patch('requests.Session.request') as mock_request:
                mock_response = Mock()
                mock_response.status_code = 200
                mock_response.json.return_value = {
            "model": "test_model",
            "created_at": "2024-01-01T00:00:00Z",
            "message": {
                "role": "assistant",
                "content": "Hello"
            },
            "done": True
        }
                mock_request.return_value = mock_response
                
                # ç©ºè¨Šæ¯åˆ—è¡¨æ‡‰è©²è¢«æ¥å—
                result = self.client.chat(model="test_model", messages=[], stream=False)
                assert result.message.content == "Hello"
                
    def test_invalid_message_role(self):
        """æ¸¬è©¦è¨Šæ¯è§’è‰²æ¥å—ä»»ä½•å­—ç¬¦ä¸²"""
        # ChatMessage æ¥å—ä»»ä½•å­—ç¬¦ä¸²ä½œç‚ºè§’è‰²
        message = ChatMessage(role="invalid_role", content="test")
        assert message.role == "invalid_role"
        assert message.content == "test"
            
    def test_missing_message_content(self):
        """æ¸¬è©¦ç¼ºå°‘è¨Šæ¯å…§å®¹"""
        with pytest.raises(ValidationError):
            ChatMessage(role="user")
            
    def test_invalid_embed_input_type(self):
        """æ¸¬è©¦ç„¡æ•ˆçš„åµŒå…¥è¼¸å…¥é¡å‹"""
        with pytest.raises(ValueError) as exc_info:
            self.client.embed(model="test_model", input=123)  # æ‡‰è©²æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨
        
        assert "Model 'test_model' does not exist" in str(exc_info.value)


class TestModelValidation:
    """æ¨¡å‹é©—è­‰æ¸¬è©¦"""
    
    def setup_method(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        self.client = OllamaClient(base_url="http://localhost:11434")
        
    @patch('requests.Session.request')
    def test_model_not_found(self, mock_request):
        """æ¸¬è©¦æ¨¡å‹æœªæ‰¾åˆ°"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "models": [
                {"name": "existing_model", "size": 1000}
            ]
        }
        mock_request.return_value = mock_response
        
        with pytest.raises(ValueError) as exc_info:
            self.client.generate(model="nonexistent_model", prompt="test", stream=False)
            
        assert "Model 'nonexistent_model' does not exist" in str(exc_info.value)
        assert "existing_model" in str(exc_info.value)
        
    @patch('requests.Session.request')
    def test_model_list_api_error(self, mock_request):
        """æ¸¬è©¦æ¨¡å‹åˆ—è¡¨ API éŒ¯èª¤"""
        mock_request.side_effect = ConnectionError("Failed to connect")
        
        with pytest.raises(Exception) as exc_info:
            self.client.list_models()
        
        assert "Failed to get model list" in str(exc_info.value)
            
    @patch('requests.Session.request')
    def test_model_list_empty_response(self, mock_request):
        """æ¸¬è©¦æ¨¡å‹åˆ—è¡¨ç©ºå›æ‡‰"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {"models": []}
        mock_request.return_value = mock_response
        
        with pytest.raises(ValueError) as exc_info:
            self.client.generate(model="any_model", prompt="test", stream=False)
            
        assert "Model 'any_model' does not exist" in str(exc_info.value)
        
    @patch('requests.Session.request')
    def test_model_list_malformed_response(self, mock_request):
        """æ¸¬è©¦æ¨¡å‹åˆ—è¡¨æ ¼å¼éŒ¯èª¤çš„å›æ‡‰"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {"invalid": "structure"}
        mock_request.return_value = mock_response
        
        # æ¨¡å‹åˆ—è¡¨ API æ‡‰è©²æ‹‹å‡ºç•°å¸¸ï¼Œä½†ä¸æ˜¯ KeyError
        # å› ç‚º client.py ä¸­æœ‰ .get("models", []) è™•ç†
        models = self.client.list_models()
        assert models == []  # æ ¼å¼éŒ¯èª¤æ™‚è¿”å›ç©ºåˆ—è¡¨


class TestStreamingErrors:
    """ä¸²æµéŒ¯èª¤æ¸¬è©¦"""
    
    def setup_method(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        self.client = OllamaClient(base_url="http://localhost:11434")
        
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_streaming_connection_error(self, mock_request, mock_check_model):
        """æ¸¬è©¦ä¸²æµé€£æ¥éŒ¯èª¤"""
        mock_request.side_effect = ConnectionError("Connection failed")
        
        with pytest.raises(Exception) as exc_info:
            result = self.client.generate(model="test_model", prompt="test", stream=True)
            list(result)  # å˜—è©¦è®€å–ä¸²æµ
        
        assert "Request failed" in str(exc_info.value)
            
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_streaming_malformed_json(self, mock_request, mock_check_model):
        """æ¸¬è©¦ä¸²æµä¸­çš„æ ¼å¼éŒ¯èª¤ JSON"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.iter_lines.return_value = [
            b'{"response": "Hello", "done": false}',
            b'invalid json line',  # æ ¼å¼éŒ¯èª¤çš„ JSON
            b'{"response": "!", "done": true}'
        ]
        mock_request.return_value = mock_response
        
        result = self.client.generate(model="test_model", prompt="test", stream=True)
        
        # ä¸²æµè™•ç†å™¨æœƒå¿½ç•¥æ ¼å¼éŒ¯èª¤çš„ JSON è¡Œï¼Œç¹¼çºŒè™•ç†æœ‰æ•ˆçš„è¡Œ
        responses = list(result)
        
        # æ‡‰è©²åªåŒ…å«æœ‰æ•ˆçš„ JSON éŸ¿æ‡‰
        assert len(responses) == 2
        assert responses[0]["response"] == "Hello"
        assert responses[1]["response"] == "!"
                
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_streaming_empty_lines(self, mock_request, mock_check_model):
        """æ¸¬è©¦ä¸²æµä¸­çš„ç©ºè¡Œ"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.iter_lines.return_value = [
            b'{"response": "Hello", "done": false}',
            b'',  # ç©ºè¡Œ
            b'{"response": "!", "done": true}'
        ]
        mock_request.return_value = mock_response
        
        result = self.client.generate(model="test_model", prompt="test", stream=True)
        responses = list(result)
        
        # æ‡‰è©²å¿½ç•¥ç©ºè¡Œ
        assert len(responses) == 2
        assert responses[0]["response"] == "Hello"
        assert responses[1]["response"] == "!"
        
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_streaming_incomplete_response(self, mock_request, mock_check_model):
        """æ¸¬è©¦ä¸²æµä¸å®Œæ•´å›æ‡‰"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.iter_lines.return_value = [
            b'{"response": "Hello", "done": false}',
            b'{"response": " world", "done": false}'
            # ç¼ºå°‘ "done": true çš„çµæŸéŸ¿æ‡‰
        ]
        mock_request.return_value = mock_response
        
        result = self.client.generate(model="test_model", prompt="test", stream=True)
        responses = list(result)
        
        # æ‡‰è©²èƒ½å¤ è™•ç†ä¸å®Œæ•´çš„å›æ‡‰
        assert len(responses) == 2
        assert responses[0]["response"] == "Hello"
        assert responses[1]["response"] == " world"


class TestStructuredOutputErrors:
    """çµæ§‹åŒ–è¼¸å‡ºéŒ¯èª¤æ¸¬è©¦"""
    
    def setup_method(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        self.client = OllamaClient(base_url="http://localhost:11434")
        
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_structured_output_invalid_json(self, mock_request, mock_check_model):
        """æ¸¬è©¦çµæ§‹åŒ–è¼¸å‡ºç„¡æ•ˆ JSON"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "model": "test_model",
            "created_at": "2024-01-01T00:00:00Z",
            "response": '{"name": "test", "value": }',  # ç„¡æ•ˆ JSON
            "done": True
        }
        mock_request.return_value = mock_response
        
        result = self.client.generate_structured(
            model="test_model",
            prompt="test",
            schema=SampleTestModel,
            stream=False
        )
        
        with pytest.raises(ValueError) as exc_info:
            self.client.parse_structured_response(result.response, SampleTestModel)
            
        assert "Unable to parse JSON response" in str(exc_info.value)
        
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_structured_output_validation_error(self, mock_request, mock_check_model):
        """æ¸¬è©¦çµæ§‹åŒ–è¼¸å‡ºé©—è­‰éŒ¯èª¤"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "model": "test_model",
            "created_at": "2024-01-01T00:00:00Z",
            "response": '{"name": "test", "value": "not_a_number"}',  # é¡å‹éŒ¯èª¤
            "done": True
        }
        mock_request.return_value = mock_response
        
        result = self.client.generate_structured(
            model="test_model",
            prompt="test",
            schema=SampleTestModel,
            stream=False
        )
        
        with pytest.raises(ValueError) as exc_info:
            self.client.parse_structured_response(result.response, SampleTestModel)
            
        assert "Unable to validate response data" in str(exc_info.value)
        
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_structured_output_missing_fields(self, mock_request, mock_check_model):
        """æ¸¬è©¦çµæ§‹åŒ–è¼¸å‡ºç¼ºå°‘æ¬„ä½"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "model": "test_model",
            "created_at": "2024-01-01T00:00:00Z",
            "response": '{"name": "test"}',  # ç¼ºå°‘ value æ¬„ä½
            "done": True
        }
        mock_request.return_value = mock_response
        
        result = self.client.generate_structured(
            model="test_model",
            prompt="test",
            schema=SampleTestModel,
            stream=False
        )
        
        with pytest.raises(ValueError) as exc_info:
            self.client.parse_structured_response(result.response, SampleTestModel)
            
        assert "Unable to validate response data" in str(exc_info.value)


class TestEdgeCasesAndBoundaries:
    """é‚Šç•Œæƒ…æ³å’Œæ¥µç«¯æƒ…æ³æ¸¬è©¦"""
    
    def setup_method(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        self.client = OllamaClient(base_url="http://localhost:11434")
        
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_very_long_prompt(self, mock_request, mock_check_model):
        """æ¸¬è©¦éå¸¸é•·çš„æç¤º"""
        long_prompt = "A" * 10000  # 10KB çš„æç¤º
        
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "model": "test_model",
            "created_at": "2024-01-01T00:00:00Z",
            "response": "Response to long prompt",
            "done": True
        }
        mock_request.return_value = mock_response
        
        result = self.client.generate(
            model="test_model",
            prompt=long_prompt,
            stream=False
        )
        
        assert result.response == "Response to long prompt"
        
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_unicode_content(self, mock_request, mock_check_model):
        """æ¸¬è©¦ Unicode å…§å®¹"""
        unicode_prompt = "ä½ å¥½ä¸–ç•Œ ğŸŒ Ã©moji test ğŸš€"
        
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "model": "test_model",
            "created_at": "2024-01-01T00:00:00Z",
            "response": "Unicode å›æ‡‰ âœ¨",
            "done": True
        }
        mock_request.return_value = mock_response
        
        result = self.client.generate(
            model="test_model",
            prompt=unicode_prompt,
            stream=False
        )
        
        assert result.response == "Unicode å›æ‡‰ âœ¨"
        
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_special_characters_in_prompt(self, mock_request, mock_check_model):
        """æ¸¬è©¦æç¤ºä¸­çš„ç‰¹æ®Šå­—ç¬¦"""
        special_prompt = 'Test with "quotes" and \n newlines and \t tabs'
        
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "model": "test_model",
            "created_at": "2024-01-01T00:00:00Z",
            "response": "Handled special characters",
            "done": True
        }
        mock_request.return_value = mock_response
        
        result = self.client.generate(
            model="test_model",
            prompt=special_prompt,
            stream=False
        )
        
        assert result.response == "Handled special characters"
        
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_multiple_consecutive_calls(self, mock_request, mock_check_model):
        """æ¸¬è©¦å¤šæ¬¡é€£çºŒèª¿ç”¨"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "model": "test_model",
            "created_at": "2024-01-01T00:00:00Z",
            "response": "Response",
            "done": True
        }
        mock_request.return_value = mock_response
        
        # é€²è¡Œå¤šæ¬¡é€£çºŒèª¿ç”¨
        for i in range(10):
            result = self.client.generate(
                model="test_model",
                prompt=f"Test {i}",
                stream=False
            )
            assert result.response == "Response"
            
    def test_context_manager_exception_handling(self):
        """æ¸¬è©¦ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç•°å¸¸è™•ç†"""
        with patch('requests.Session.close') as mock_close:
            try:
                with OllamaClient() as client:
                    raise ValueError("Test exception")
            except ValueError:
                pass
            
            # ç¢ºèªå³ä½¿ç™¼ç”Ÿç•°å¸¸ä¹Ÿæœƒé—œé–‰æœƒè©±
            mock_close.assert_called_once()
            
    def test_client_with_invalid_base_url(self):
        """æ¸¬è©¦ç„¡æ•ˆçš„åŸºç¤ URL"""
        client = OllamaClient(base_url="invalid-url")
        
        with patch('requests.Session.request') as mock_request:
            mock_request.side_effect = ConnectionError("Invalid URL")
            
            with pytest.raises(Exception) as exc_info:
                client.generate(model="test_model", prompt="test", stream=False)
            
            assert "Failed to get model list" in str(exc_info.value)
                
    def test_client_with_very_short_timeout(self):
        """æ¸¬è©¦éå¸¸çŸ­çš„è¶…æ™‚æ™‚é–“"""
        client = OllamaClient(timeout=0.001)  # 1ms è¶…æ™‚
        
        with patch('requests.Session.request') as mock_request:
            mock_request.side_effect = Timeout("Request timed out")
            
            with pytest.raises(Exception) as exc_info:
                client.generate(model="test_model", prompt="test", stream=False)
            
            assert "Failed to get model list" in str(exc_info.value)
                
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_empty_embedding_response(self, mock_request, mock_check_model):
        """æ¸¬è©¦ç©ºåµŒå…¥å›æ‡‰"""
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "model": "test_model",
            "embeddings": []
        }
        mock_request.return_value = mock_response
        
        result = self.client.embed(model="test_model", input="test")
        assert len(result.embeddings) == 0
        
    @patch('ollama_flow.client.OllamaClient._check_model_exists')
    @patch('requests.Session.request')
    def test_extremely_large_embedding_dimension(self, mock_request, mock_check_model):
        """æ¸¬è©¦æ¥µå¤§ç¶­åº¦çš„åµŒå…¥"""
        # å‰µå»ºä¸€å€‹éå¸¸å¤§çš„åµŒå…¥å‘é‡
        large_embedding = [0.1] * 10000  # 10k ç¶­åº¦
        
        mock_response = Mock()
        mock_response.status_code = 200
        mock_response.json.return_value = {
            "model": "test_model",
            "embeddings": [large_embedding]
        }
        mock_request.return_value = mock_response
        
        result = self.client.embed(model="test_model", input="test")
        assert len(result.embeddings[0]) == 10000 