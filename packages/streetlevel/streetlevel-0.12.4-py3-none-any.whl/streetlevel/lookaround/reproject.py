import math
from typing import List

from PIL import Image
from equilib import Equi2Equi
import torch
from torchvision import transforms

from streetlevel.lookaround.panorama import CameraMetadata

_equi2equi = Equi2Equi(mode="bilinear", z_down=True)
_device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
_to_tensor = transforms.Compose([transforms.ToTensor()])
_to_pil = transforms.Compose([transforms.ToPILImage()])


def to_equirectangular(
    faces: List[Image.Image], camera_metadata: List[CameraMetadata]
) -> Image.Image:
    """
    Reprojects the faces of a Look Around panorama to a single equirectangular image. The center of the
    returned image is the inverse direction of travel (meaning you're looking backwards).

    Note that this method is *very* slow. On my machine, a full resolution image (zoom 0, 16384Ã—8192) takes
    about 50 seconds to convert.

    **PyTorch must be installed** to call this function. Due to its size and differing CUDA versions,
    it is not installed automatically alongside the other dependencies of this library.

    :param faces: The faces of the panorama as PIL images.
    :param camera_metadata: The camera metadata of the faces.
    :return: The reprojected panorama as PIL image.
    """
    full_width = round(faces[0].width * (1024 / 5632)) * 16
    full_height = full_width // 2

    stitched = Image.new("RGB", (full_width, full_height))

    for faceIndex in range(5, -1, -1):
        if faceIndex > 3:
            projected = _project_top_or_bottom_face(
                faces[faceIndex], camera_metadata[faceIndex], full_width, full_height
            )
            stitched.paste(projected, (0, 0), projected)
        else:
            _paste_side_face(
                faces[faceIndex],
                camera_metadata[faceIndex],
                full_width,
                full_height,
                stitched,
            )
    return stitched


def _project_top_or_bottom_face(
    face: Image.Image,
    camera_metadata: CameraMetadata,
    full_width: int,
    full_height: int,
) -> Image.Image:
    input_img = Image.new("RGBA", (full_width, full_height), (0, 0, 0, 0))

    phi_length = camera_metadata.lens_projection.fov_s
    theta_length = camera_metadata.lens_projection.fov_h
    face_width = phi_length * (full_height / math.pi)
    face_height = theta_length * (full_height / math.pi)
    x = (full_width - face_width) / 2
    y = (full_height - face_height) / 2

    scaled_img = face.resize((math.ceil(face_width), math.ceil(face_height)))
    input_img.paste(scaled_img, box=(math.ceil(x), math.ceil(y)))

    input_tensor = _to_tensor(input_img).to(_device)
    reprojected_tensor = _equi2equi(
        input_tensor,
        {
            "yaw": -camera_metadata.position.yaw,
            "pitch": camera_metadata.position.pitch,
            "roll": camera_metadata.position.roll,
        },
    )
    reprojected_tensor = reprojected_tensor.to("cpu")
    reprojected_img = _to_pil(reprojected_tensor)
    return reprojected_img


def _paste_side_face(
    face: Image.Image,
    camera_metadata: CameraMetadata,
    full_width: int,
    full_height: int,
    stitched: Image.Image,
) -> None:
    phi_start = (
        math.pi
        + camera_metadata.position.yaw
        - (camera_metadata.lens_projection.fov_s / 2)
    )
    if phi_start < 0:
        phi_start += 2 * math.pi
    theta_start = (
        (math.pi / 2)
        - (camera_metadata.lens_projection.fov_h / 2)
        - camera_metadata.lens_projection.cy
    )
    phi_length = camera_metadata.lens_projection.fov_s
    theta_length = camera_metadata.lens_projection.fov_h
    face_width = phi_length * (full_height / math.pi)
    face_height = theta_length * (full_height / math.pi)
    x = phi_start * (full_height / math.pi)
    y = theta_start * (full_height / math.pi)

    scaled_img = face.resize((math.ceil(face_width), math.ceil(face_height)))
    stitched.paste(scaled_img, (math.ceil(x), math.ceil(y)))
    # front face wraps around
    if x + face.width > full_width:
        stitched.paste(scaled_img, (math.ceil(x - full_width), math.ceil(y)))
