Metadata-Version: 2.4
Name: raglab_easygenius
Version: 0.1.0
Summary: A modular RAG library with embeddings and vector store support
Author: Jay & Abhishek
Author-email: Jay & Abhishek <your.email@example.com>
License: MIT
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: sentence-transformers>=2.2.2
Requires-Dist: qdrant-client>=1.3.0
Requires-Dist: faiss-cpu; sys_platform != "win32"
Requires-Dist: openai>=1.0.0
Requires-Dist: google-generativeai>=0.3.1
Requires-Dist: pyyaml>=6.0
Dynamic: author
Dynamic: requires-python

# ğŸ§  MyRAGProject

**Now with interactive setup!**

- On first use, you'll be prompted to choose your embedding model (HuggingFace or Gemini) and vector database (Qdrant or FAISS).
- The setup wizard will create a `.env` file for your configuration and install only the dependencies you need.
- Supports Gemini API key and Qdrant port via `.env`.

---

## ğŸ“¦ Features

- ğŸ” Smart chunking of input documents
- ğŸ¤– Embedding generation via HuggingFace
- ğŸ§  Vector storage using Qdrant
- ğŸ’¬ Ready for question-answering and search
- ğŸš€ Modular and easy to extend

---

## ğŸ—‚ï¸ Folder Structure

myragproject/
â”œâ”€â”€ main.py
â”œâ”€â”€ data/
â”‚ â””â”€â”€ sample.txt
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ config.py
â”‚ â””â”€â”€ ingest.py
â”œâ”€â”€ raglib/
â”‚ â”œâ”€â”€ chunking/
â”‚ â”‚ â””â”€â”€ smart_chunker.py
â”‚ â”œâ”€â”€ embeddings/
â”‚ â”‚ â””â”€â”€ huggingface.py
â”‚ â””â”€â”€ vector_stores/
â”‚ â””â”€â”€ qdrant_store.py

yaml
Copy
Edit

---

## ğŸ”§ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/your-username/myragproject.git
cd myragproject
2. Install dependencies
bash
Copy
Edit
pip install -r requirements.txt
Or manually install:

bash
Copy
Edit
pip install sentence-transformers qdrant-client requests
3. Start Qdrant (vector DB)
bash
Copy
Edit
docker run -p 6333:6333 -v qdrant_data:/qdrant/storage qdrant/qdrant
This ensures persistent vector storage.

4. Add your document
Place a .txt file inside the data/ folder, e.g.:

bash
Copy
Edit
data/sample.txt
ğŸš€ Run the RAG Ingest Pipeline
bash
Copy
Edit
python main.py
It will:

Read the file

Split it into chunks

Generate embeddings

Store in Qdrant with payloads

ğŸ“– Example Output
bash
Copy
Edit
ğŸ“„ Starting ingestion for: data/sample.txt
ğŸ§© Created 4 chunks
ğŸ”¢ Generated embeddings
âœ… Stored 4 points in Qdrant.
âœ… Embeddings stored successfully in Qdrant.
ğŸ” Coming Soon
â“ Ask questions and retrieve top relevant chunks

ğŸ“š Support for PDFs and multiple file types

ğŸ§ª FastAPI-based chatbot API

ğŸ§  Tech Stack
Python 3.10+

HuggingFace (sentence-transformers)

Qdrant vector store

Docker (for Qdrant server)

ğŸ§© Credits
Built with â¤ï¸ by [Abhishek]

Inspired by modern RAG systems like LangChain, LlamaIndex

ğŸ“„ License
MIT License

yaml
Copy
Edit

---

## âœ… To Use It Now

Just create a `README.md` file in your root folder and paste the above content.

---

Would you like me to generate:

- `requirements.txt` for you?
- Add FastAPI interface?
- Publish this to GitHub with a badge?

Letâ€™s make this production-ready ğŸš€

